{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Documentation Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "base_path = Path(r\"~\\OneDrive - Queen's University\\Python\\Projects\\EclipseRelated\\SQL Graphs\").expanduser()\n",
    "sys.path.append(str(base_path))\n",
    "\n",
    "#sectionary_path = base_path / 'sectionary'\n",
    "#sys.path.append(sectionary_path)\n",
    "#table_gen_path = base_path / r'References\\DB References\\Table Generators'\n",
    "#sys.path.append(table_gen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "from typing import  List, Union\n",
    "from pickle import load, dump\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "\n",
    "from true_iterable import true_iterable\n",
    "from sectionary.text_reader import FixedWidthParser, define_fixed_width_parser\n",
    "from sectionary.text_reader import trim_items, drop_blanks, to_dataframe\n",
    "from sectionary.sections import Section, SectionBreak, ProcessingMethods, Rule\n",
    "from sectionary.sections import Trigger\n",
    "from sectionary.buffered_iterator import BufferedIterator, BufferedIteratorEOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Varian DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_types():\n",
    "    PKL_DIR = Path.cwd() / '..' / 'Raw Tables'\n",
    "    data_type_pkl_file = PKL_DIR / 'Data Type.pkl'\n",
    "\n",
    "    file = open(str(data_type_pkl_file), 'rb')\n",
    "    data_type_lookup = load(file)\n",
    "    file.close()\n",
    "    return data_type_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the DataType definition table into a dictionary that links type name with category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_type_dict():   \n",
    "    data_types = get_data_types().reset_index()\n",
    "    # Get the two datatype groups\n",
    "    data_types.columns = ['VDT', 'MSQL_DT']\n",
    "    # Convert to a dictionary look up of category\n",
    "    data_types = data_types.T.stack().reset_index(level=0)\n",
    "    data_types.columns = ['Category', 'DataType']\n",
    "    data_types.set_index('DataType', inplace=True)\n",
    "    return data_types.to_dict()['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Line Break text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_lines(lines: List[str])->str:\n",
    "    brk_text = [\n",
    "        'System Database Reference Guide',\n",
    "        'VDT Name to Microsoft SQL Datatype',\n",
    "        'Abbreviations for Table and Column Names',\n",
    "        'variansystem Database Overview',\n",
    "        'Varian System Database Reference Guide',\n",
    "        '(poster only)',\n",
    "        '(continued)',\n",
    "        'ARIA modules installed.',\n",
    "        'This page is intentionally blank'\n",
    "        ]\n",
    "    for line in lines:\n",
    "        if any(drop_text in line \n",
    "               for drop_text in brk_text):\n",
    "            continue\n",
    "        else:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove lines based on regular expressions\n",
    "1. Lines that end in a number (page number).\n",
    "2. Lines containing spaces and just the text _Name_ \n",
    "(_View Column Name_ wrapped to the next line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_lines_re(lines: List[str])->str:\n",
    "    # convert single string to one element list of strings\n",
    "    re_list = [\n",
    "        ' +[0-9]+$',  # Lines ending in a number\n",
    "        #'^[ ]+Name$'  # Lines containing spaces and just the text Name\n",
    "        ]\n",
    "    for line in lines:\n",
    "        # Replace invalid UTF code with black circle\n",
    "        # line = line.replace('\\uf06e', u'\\u25cf')\n",
    "        if any(re.search(test_re, line) is not None\n",
    "               for test_re in re_list):\n",
    "            continue\n",
    "        else:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Row Text\n",
    "1. Remove the spaces around KeyType annotation.\n",
    "2. Fix the UserDefAttrib column name(s)\n",
    "    ```\n",
    "    UserDefAttrib01 \n",
    "           to       \n",
    "    UserDefAttrib16 \n",
    "    ```\n",
    "3. Fix the single instance of comma separated KeyTypes\n",
    "4. Add _ to a single instance of Data Type\n",
    "4. Correct case of a single instance of Data Type\n",
    "5. Remove spacing before _ in a single instance of Data Type\n",
    "5. Replace - with _ in a single instance of Data Type\n",
    "4. Add extra row when datatype is _image_, because it only uses one row for a column definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row_text(table_data_list):\n",
    "    for row in table_data_list:\n",
    "    # Drop spaces around keytypes\n",
    "        if ' (' in row:\n",
    "            row = row.replace(' (', '(') \n",
    "            row = ' ' + row\n",
    "        # re-label the UserDefAttrib01 column\n",
    "        row = row.replace('UserDefAttrib01     ', 'UserDefAttrib[01-16]')\n",
    "        row = row.replace('       to           ', '                    ')\n",
    "        row = row.replace('UserDefAttrib16     ', '                    ')\n",
    "        # replace comma seperated key type codes with the standard brackets\n",
    "        row = row.replace('(FK, IE1)', '(FK)(IE1)')\n",
    "        # Add _ to Data Type\n",
    "        row = row.replace('VDT_MODALITY NOT ', 'VDT_MODALITY_NOT_')\n",
    "        # remove spacing before _ in Data Type\n",
    "        row = row.replace('VDT_FLAG_TRUE _', 'VDT_FLAG_TRUE_')        \n",
    "        # Correct DataType Name case\n",
    "        row = row.replace('VDT_Name', 'VDT_NAME')        \n",
    "        # Replace - with _\n",
    "        row = row.replace('VDT_FLAG_FALSE-DEFAULT', 'VDT_FLAG_FALSE_DEFAULT')\n",
    "        # Add an extra line when type is image (only one line for a column def)\n",
    "        if row.endswith('image'):\n",
    "            yield row\n",
    "            yield ''\n",
    "            continue\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Chapter Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter data extraction process:\n",
    "1. Get all text between Chapter 4 and 14.\n",
    "> `raw_text` -> `remaining_lines`\n",
    "3. Extract all text starting just after the next chapter title line.\n",
    "> `remaining_lines` -> `next_chapter` -> `remaining_lines`.\n",
    "3. Get the name of the zone from the chapter title.\n",
    "> (as found by `next_chapter`)\n",
    "1. Extract text for the current chapter starting at the beginning of the text selected in 2. and ending just before the next next chapter title line.(`remaining_lines` -> `this_chapter` -> `chapter_lines`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All chapters\n",
    "> Selects the section of raw text containing the chapters of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chapters = Section(\n",
    "    start_section=SectionBreak('CHAPTER 4', break_offset='Before'), \n",
    "    end_section=SectionBreak('Chapter 14', break_offset='Before')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define **Next** chapter section\n",
    "> Collect all chapter contents starting right after the chapter title line.\n",
    "- Start just after the chapter title.\n",
    "- Continue to end of text\n",
    "- Remove page headers & footers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression for chapter titles\n",
    "- Looks for the word `Chapter` followed by numbers 4 thru 99.\n",
    "- Capture the chapter title which follows the chapter number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_loc = re.compile(\n",
    "    '^ +'          # Spaces\n",
    "    'Chapter '     # Chapter Text\n",
    "    '(?:'          # Begin non-capture group\n",
    "    '[4-9]'        # Chapters 4 thru 9\n",
    "    '|'            # or\n",
    "    '[1-9][0-9]'   # Chapters 10 and up\n",
    "    ')'            # End non-capture group\n",
    "    ' +'           # Blank spaces\n",
    "    '(.+)$'        # The rest of the text on the line\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter processing methods:\n",
    "- Remove page headers & footers\n",
    "- Apply misc. text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove page headers & footers\n",
    "next_ch_proc = ProcessingMethods([drop_lines, drop_lines_re, clean_row_text])\n",
    "\n",
    "next_chapter = Section(\n",
    "    start_section=SectionBreak(chapter_loc, break_offset='After'), \n",
    "    end_section=None,\n",
    "    processor=next_ch_proc\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the zone label from the chapter title\n",
    "- The chapter title is _captured_ by the chapter_loc regular expression and \n",
    "can be accessed with `next_chapter.context['Event'].groups()[0]`\n",
    "- The text `Zone Tables` or just `Zone` is removed.\n",
    "- Starting and ending spaces are removed\n",
    "- The end result is assumed to be the name of the zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zone_label(ch_section):\n",
    "    chapter_title = ch_section.context['Event'].groups()[0]\n",
    "    zone_label = chapter_title.replace('Zone Tables','').strip()\n",
    "    zone_label = zone_label.replace('Zone','').strip()\n",
    "    return zone_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define **This** chapter section\n",
    "> Returns the text for the current chapter\n",
    "- Start with beginning of text.\n",
    "- End just before next chapter title.\n",
    "- No Text processing is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _this_ chapter section definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_chapter = Section(\n",
    "    start_section=None, \n",
    "    end_section=SectionBreak(chapter_loc, break_offset='before')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read a chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chapter(remaining_lines):\n",
    "    remaining_lines = next_chapter.read(remaining_lines)\n",
    "    if remaining_lines:\n",
    "        zone = get_zone_label(next_chapter)\n",
    "        chapter_lines = this_chapter.read(remaining_lines)\n",
    "    else:\n",
    "        chapter_lines = []\n",
    "        zone = ''\n",
    "    return remaining_lines, chapter_lines, zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Table Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make A regular expression for Table headers\n",
    "- Starts with 10-20 Spaces.\n",
    "- Capture the table name:\n",
    "    - Begins with a capital letter or \"vv_\".\n",
    "    - Contains no spaces or period for the rest of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_loc = re.compile(''.join([\n",
    "    '^',           # Start of line\n",
    "    ' {10,20}',    # between 10 and 20 Spaces\n",
    "    '('            # Start of capture group\n",
    "    '([A-Z]|vv_)'  # Begins with a capital letter or \"vv_\"\n",
    "    '[^ .]+'       # Text with no spaces or period (for rest of line)\n",
    "    ')'            # End of capture group\n",
    "    '$'            # End of the line\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Section Definition\n",
    "> Returns text starting with the next table\n",
    "- Start after the next Table name (as defined by `table_loc`)\n",
    "- Continue to the end (of the chapter)\n",
    "- No text processing is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_section = Section(\n",
    "    start_section=SectionBreak(table_loc, break_offset='After'), \n",
    "    end_section=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Table Name from the table section\n",
    "- The table name is _captured_ by the table_loc regular expression and can be \n",
    "accessed with `table_section.context['Event'].groups()[0]`\n",
    "- Starting and ending spaces are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_name(tbl_section):\n",
    "    if tbl_section.context['Event']:\n",
    "        table_name = tbl_section.context['Event'].groups()[0]\n",
    "        table_name = table_name.strip()\n",
    "    else:\n",
    "        table_name = ''    \n",
    "    return table_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the table description text (Description section)\n",
    "> The table description is a single paragraph immediately after the \n",
    "table name.<p>\n",
    "Obtained by:<p> `table_description = desc_section.read(chapter_lines)`\n",
    "\n",
    "- Start at the beginning of the table text\n",
    "- Continue until reaching a line that starts with more than 44 spaces.\n",
    "- Text processing:\n",
    "    1. Remove spaces at the beginning and end of each row.\n",
    "    2. Combine rows to form a single string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_row(row):\n",
    "    return row.strip()\n",
    "desc_proc = ProcessingMethods([trim_row])  # Remove leading and trailing spaces\n",
    "\n",
    "def merged_desc(rows):\n",
    "    return ' '.join(rows)\n",
    "\n",
    "desc_section = Section(\n",
    "    start_section=None, \n",
    "    end_section=SectionBreak(' '*44, break_offset='Before'),\n",
    "    processor=desc_proc, aggregate=merged_desc\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read table information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_info(chapter_lines, zone):\n",
    "    chapter_lines = table_section.read(chapter_lines)\n",
    "    if chapter_lines:\n",
    "        table_name = get_table_name(table_section)\n",
    "        table_description = desc_section.read(chapter_lines)\n",
    "        table_info = {\n",
    "            'Zone': zone,\n",
    "            'TableName': table_name,\n",
    "            'TableDescription': table_description\n",
    "            }\n",
    "    else:\n",
    "        table_info = {}\n",
    "    return chapter_lines, table_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Table's Column Section\n",
    "### Remove table header text\n",
    "> Table header contains either:\n",
    "\n",
    "> - Column Name\n",
    "> - View Column\n",
    "\n",
    "> If header is found return a blank string, otherwise return the original row.\n",
    "\n",
    "### Column Section\n",
    "> Returns text containing the column descriptions\n",
    "- Start just after the Table Header\n",
    "- Continue to just before the next table\n",
    "- Table headers and blank lines are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_header = Rule(['Column Name', 'View Column'],\n",
    "                         pass_method='Blank',\n",
    "                         fail_method='Original')\n",
    "\n",
    "col_proc = ProcessingMethods([\n",
    "     drop_table_header,  # Remove table header text (repeats at beginning of page)\n",
    "     drop_blanks         # Remove lines where all columns are empty.\n",
    "    ])\n",
    "\n",
    "tbl_columns = Section(\n",
    "    start_section=SectionBreak(['Column Name', 'View Column'], \n",
    "                               break_offset='After'), \n",
    "    end_section=SectionBreak(table_loc, break_offset='Before'),\n",
    "    processor=col_proc\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Data Types\n",
    "> Find DataType names at the end of description text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_search(row, data_types):    \n",
    "    desc_txt = row.get('DescTxt','')\n",
    "    if isinstance(desc_txt, str):\n",
    "        for data_type, category in data_types.items():\n",
    "            # Remove 'image' as a searchable data type \n",
    "            # (it is a word in its own right)\n",
    "            if data_type == 'image':\n",
    "                continue\n",
    "            # Add space in front so that we don't find partial words\n",
    "            test_text = ' ' + data_type\n",
    "            if str(desc_txt).endswith(test_text):\n",
    "                idx = desc_txt.rfind(test_text)\n",
    "                row[category] = desc_txt[idx:]\n",
    "                row['DescTxt'] = desc_txt[:idx]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All Tables in All Chapters\n",
    "### Chapter data extraction process:\n",
    "1. Get all text between Chapter 4 and 14.\n",
    "2. For each chapter:\n",
    "    1. Get the name of the zone from the chapter title.\n",
    "    2. Extract all text starting just after the next chapter title line.\n",
    "    3. Extract text for the current chapter starting at the beginning of the text selected in 2. and ending just before the next next chapter title line.\n",
    "    4. For each table in the chapter:\n",
    "        1. Return text starting with the next table\n",
    "        2. Get the table Name and description\n",
    "        3. Extract the column description text\n",
    "        4. Add Zone and Table Name to the beginning of each row\n",
    "3. Build the Table description DataFrame\n",
    "4. Create a list of column descriptions for each column in all chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chapters(raw_lines):\n",
    "    table_desc_list = list()\n",
    "    table_data_list = list()\n",
    "    table_ref_tmpl = '{zone:25}{table_name:30}'\n",
    "    remaining_lines = all_chapters.read(raw_lines)\n",
    "    while remaining_lines:\n",
    "        remaining_lines, chapter_lines, zone =  read_chapter(remaining_lines)\n",
    "        while chapter_lines:\n",
    "            chapter_lines, table_info = get_table_info(chapter_lines, zone)\n",
    "            if chapter_lines:\n",
    "                table_data = tbl_columns.read(chapter_lines)                \n",
    "                table_ref = table_ref_tmpl.format(\n",
    "                    zone=table_info['Zone'],\n",
    "                    table_name=table_info['TableName']\n",
    "                    )\n",
    "                combined_table_data = [table_ref + row for row in table_data]\n",
    "                table_desc_list.append(table_info)\n",
    "                table_data_list.extend(combined_table_data)\n",
    "    table_descriptions = pd.DataFrame(table_desc_list)\n",
    "    return table_descriptions, table_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract a Column Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column locator regular expression\n",
    "- allow for 2 to 20 Spaces at the beginning of the line.\n",
    "- ColumnName is the sequence of all subsequent non-space characters\n",
    "- ColumnName is followed by at least one space\n",
    "- DescTxt contains the extracted beginning of the description text.\n",
    "- DescTxt begins with at least one non-space character, followed by all \n",
    "remaining characters in the extracted line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_loc = re.compile(\n",
    "    # Initial spaces\n",
    "    '^'                # Start of line\n",
    "    # StartSpace  \n",
    "    '(?P<StartSpace>'  # beginning of StartSpace group\n",
    "    ' {2,20}'          # 2 to 20 Spaces\n",
    "    ')'                # End of StartSpace group  \n",
    "      \n",
    "    # ColumnName  \n",
    "    '(?P<ColumnName>'  # beginning of ColumnName group\n",
    "    '[^ ]+'            # all non-space characters\n",
    "    ')?'               # End of optional ColumnName group\n",
    "  \n",
    "    # GapSpace  (Space between Values)\n",
    "    '(?P<GapSpace>'  # beginning of GapSpace group\n",
    "    ' +'               # At least one space\n",
    "    ')'                # End of GapSpace group\n",
    "                \n",
    "    # Some ColumnDescription text\n",
    "    '(?P<DescTxt>'     # beginning of DescTxt group\n",
    "    '[^ ]+'            # at least one non-space characters\n",
    "    '.*'               # all remaining characters\n",
    "    ')?'               # End of optional DescTxt group\n",
    "    \n",
    "    # End of Line  \n",
    "    '$'                # End of line\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataType regular expression\n",
    "\n",
    "1. Column Description (DescTxt)\n",
    "- All characters from the start of the line until next section is found (non-greedy)\n",
    "2. An arbitrary number of spaces\n",
    "3. DataType group\n",
    "- DataType can be either VDT or MSQL_DT \n",
    "- VDT  \n",
    "    - Group must be preceded by at least 2 spaces\n",
    "    - Contains any number of capital letters, numbers, symbols: _ ) (\n",
    "- MSQL_DT  \n",
    "    - Group must be preceded by at least 2 spaces\n",
    "    - Starts with a letter followed by a lowercase letter\n",
    "    - All remaining text in the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_loc = re.compile(\n",
    "    # Initial spaces\n",
    "    '^'             # Start of line\n",
    "    # DescTxt  \n",
    "    '(?P<DescTxt>'  # beginning of ColumnDescription group\n",
    "    '.+?'           # all characters until next section is found (non-greedy)\n",
    "    ')?'            # End of optional ColumnDescription group\n",
    "      \n",
    "    # Space between Values  \n",
    "    ' *'            # Arbitrary number of Spaces\n",
    "      \n",
    "    # DataType can be either VDT or MSQL_DT  \n",
    "    '('             # beginning of DataType group\n",
    "    # VDT  \n",
    "    '(?P<VDT>'      # beginning of VDT group\n",
    "    '(?<=  )'       # Group must be preceded by at least 2 spaces\n",
    "    '[A-Z_0-9)()]+' # capitals numbers and \"-)(\"\n",
    "    ')'             # End of VDT group\n",
    "    \n",
    "    '|'             # OR    \n",
    "    # MSQL_DT  \n",
    "    '(?P<MSQL_DT>'  # beginning of MSQL_DT group\n",
    "    '(?<=  )'       # Group must be preceded by at least 2 spaces\n",
    "    '[A-Za-z]'      # Starts with a letter\n",
    "    '[a-z]'         # followed by a lowercase letter\n",
    "    '.+'            # remaining text in line\n",
    "    ')'             # End of MSQL_DT group\n",
    "\n",
    "    ')?'            # End of optional DataType group\n",
    "      \n",
    "    # End of Line  \n",
    "    '$'             # End of line\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Values from Each Row\n",
    "1. Use positions to get _Zone_ and _TableName_\n",
    "2. Use `col_loc` to get _ColumnName_ and part of _Description_\n",
    "3. Use `typ_match` to get _VDT_, _MSQL_DT_ and part of _Description_\n",
    "4. Combine _Description_ parts\n",
    "6. Calculate _DescriptionOffset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_data(table_data_iter):\n",
    "    def get_table_dict(info_txt):\n",
    "        zone = info_txt[:25].strip()\n",
    "        table_name = info_txt[25:].strip()\n",
    "        table_dict = {\n",
    "            'Zone': zone,\n",
    "            'TableName': table_name\n",
    "            }\n",
    "        return table_dict\n",
    "    \n",
    "    def get_col_match(col_row):\n",
    "        col_match = col_loc.match(col_row)\n",
    "        if col_match:\n",
    "            match_result = col_match.groupdict(default='')     \n",
    "        else:\n",
    "            match_result = {}\n",
    "        return match_result\n",
    "    \n",
    "    def get_type_match(typ_row, data_types):\n",
    "        typ_match = type_loc.match(typ_row)\n",
    "        if typ_match:\n",
    "            match_result = typ_match.groupdict(default='')\n",
    "            final_match_result = type_search(match_result, data_types)        \n",
    "        else:\n",
    "            final_match_result = {}\n",
    "        return final_match_result\n",
    "\n",
    "    try:\n",
    "        row = next(table_data_iter)\n",
    "    except BufferedIteratorEOF:\n",
    "        return {}\n",
    "    if not row:\n",
    "        return {}\n",
    "    row_dict = get_table_dict(row[0])\n",
    "    if len(row) > 1:\n",
    "        col_data = get_col_match(row[1])\n",
    "        row_dict['ColumnName'] = col_data['ColumnName']\n",
    "        row_dict['Description'] = [col_data['DescTxt']]\n",
    "        row_dict['DescriptionOffset'] = [len(col_data['DescTxt'])]           \n",
    "        if len(row) > 2:\n",
    "            type_data = get_type_match(row[2], data_types)\n",
    "            row_dict['VDT'] = type_data['VDT']\n",
    "            row_dict['MSQL_DT'] = type_data['MSQL_DT']\n",
    "            row_dict['Description'] = [''.join([col_data['DescTxt'],\n",
    "                                                type_data['DescTxt']])]\n",
    "    return row_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Type Word Wrap\n",
    "1. Merge current type text with next row type text\n",
    "2. If resulting merge is not blank:\n",
    "    - If True:  Check if resulting merge is a valid type:\n",
    "       - If True:  Return resulting merge an new type text\n",
    "       - Otherwise:  flag _New Column_\n",
    "    - Otherwise:   original type text (blank) is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_types(row_dict, next_row_dict, data_types):\n",
    "    def get_type(row_dict, type_category):\n",
    "        tp = row_dict.get(type_category, '')\n",
    "        tp = tp.strip()\n",
    "        return tp\n",
    "\n",
    "    def merge_type(row_dict, next_row_dict, type_category, data_types):\n",
    "        # Treat type_data as a word wrap of one data type name\n",
    "        type_data = [get_type(row_dict, type_category),\n",
    "                     get_type(next_row_dict, type_category)]           \n",
    "        type_text = ''.join(type_data)\n",
    "        \n",
    "        # If type_text is blank return type_text\n",
    "        if not type_text:            \n",
    "            return type_text\n",
    "        \n",
    "        # If type_text is a valid data type in its category return type_text\n",
    "        for data_type, category in data_types.items():            \n",
    "            if ((type_text.lower() in data_type.lower()) & \n",
    "                (type_category.lower() in category.lower())):\n",
    "                return type_text\n",
    "            \n",
    "        # If type_text is not a valid data type check whether it may be the end \n",
    "        # of the column name by testing for ColumnName text\n",
    "        if not next_row_dict['ColumnName']:\n",
    "                # If ColumnName is blank, treat type_data as two data types \n",
    "                # and join with a comma and space\n",
    "                type_text = ', '.join(type_data)\n",
    "                return type_text\n",
    "        \n",
    "        # If ColumnName is not blank, assume that the end of the column name \n",
    "        # has been reached and return None\n",
    "        return None\n",
    "    \n",
    "    new_column = False\n",
    "    vdt = merge_type(row_dict, next_row_dict, 'VDT', data_types)\n",
    "    if vdt is not None:\n",
    "        row_dict['VDT'] = vdt\n",
    "    else:\n",
    "        new_column = True\n",
    "    msql = merge_type(row_dict, next_row_dict, 'MSQL_DT', data_types)\n",
    "    if msql is not None:\n",
    "        row_dict['MSQL_DT'] = msql   \n",
    "    else:\n",
    "        new_column = True\n",
    "    return row_dict, new_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get full column definition\n",
    "1. Check for end of table_data_iter \n",
    "2. Check for end of table\n",
    "3. Check for end of column<p>\n",
    "    _Start of Column_<p>\n",
    "    1. Start with<p>\n",
    "        `end_of_name = False`\n",
    "    2. Read rows until<p>\n",
    "    \t`not next_row_dict['ColumnName']`\n",
    "    3. Set<p>\n",
    "    \t`end_of_name = True`\n",
    "    4. Continue to read rows until\n",
    "    \t- `next_row_dict['ColumnName']`\n",
    "\t\tor\n",
    "\t\t- Invalid datatype word wrap\n",
    "    5. Set<p>\n",
    "    \t`table_data_iter.backup()`<p>\n",
    "\n",
    "    _End of Column_<p>\n",
    "\n",
    "4. Merge column rows to form column definition dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_def(table_data_iter):\n",
    "    row_dict = get_row_data(table_data_iter)\n",
    "    this_table = row_dict.get('TableName', '')\n",
    "    end_of_name = False\n",
    "    while True:    \n",
    "        next_row_dict = get_row_data(table_data_iter)\n",
    "        # Check for end of table_data_iter \n",
    "        if not next_row_dict:\n",
    "            break\n",
    "        # Check for end of table\n",
    "        if next_row_dict['TableName'] not in this_table:\n",
    "            table_data_iter.backup()\n",
    "            break\n",
    "        # Check for end of column\n",
    "        if not next_row_dict['ColumnName']:\n",
    "            end_of_name = True   # Finished ColumnName word wrap\n",
    "        else:\n",
    "            if end_of_name:   # Starting new ColumnName\n",
    "                table_data_iter.backup()\n",
    "                break            \n",
    "        row_dict, new_column = check_data_types(row_dict, next_row_dict, \n",
    "                                                data_types)\n",
    "        # Check for end of column indicated by invalid datatype word wrap\n",
    "        if new_column:\n",
    "            table_data_iter.backup()\n",
    "            break      \n",
    "        # if made it to here then still part of same column definition        \n",
    "        row_dict['ColumnName'] = ''.join([row_dict['ColumnName'],\n",
    "                                        next_row_dict['ColumnName']])\n",
    "        row_dict['Description'].extend(next_row_dict['Description'])\n",
    "        row_dict['DescriptionOffset'].extend(next_row_dict['DescriptionOffset'])\n",
    "    return row_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract KeyTypes\n",
    "1. Use a regular expression to identify Key Types in the column name.\n",
    "2. If one or more Key Types are found:\n",
    "    1. Update the column name\n",
    "    1. Put commas between multiple Key Types\n",
    "    2. Remove Brackets\n",
    "    3. Set the KeyType value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column KeyType Regular Expression\n",
    "> KeyType identification (Possibly more than one)\n",
    "\n",
    "- Each KeyType code begins with \"(\" and ends with \")\"\n",
    "- Usually a space between multiple KeyType codes\n",
    "- Possible KeyType codes are:\n",
    "         \n",
    "|Symbol|Meaning|\n",
    "|------|-------|\n",
    "|(PK)|Primary Key|\n",
    "|(FK)|Foreign Key|\n",
    "|(AK#)|Alternate Key|\n",
    "|(IE#)|Inversion Entry|\n",
    "\n",
    "**Note:** _#_ indicates a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_loc = re.compile(\n",
    "    '^'                # Start of line\n",
    "    # ColumnName  \n",
    "    '(?P<ColumnName>'  # beginning of ColumnName group\n",
    "    '[^ (]+'           # all non-space and non-'(' characters\n",
    "    ')?'               # End of optional ColumnName group\n",
    "    '(?P<KeyType>'               # beginning of optional KeyType group\n",
    "    '('                          # Beginning of keyType    \n",
    "    '\\('                         # KeyType code begins with a \"(\"\n",
    "    '(PK|FK|A[KE][0-9]?|IE[0-9]?)'  # Possible KeyType codes\n",
    "    '\\)'                         # Each KeyType code ends with a \")\"\n",
    "    ')+'                         # Possibly more than one KeyType Code\n",
    "    ')?'                         # End of optional KeyType group \n",
    "    # End of Line  \n",
    "    '$'                          # End of line\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_type(column_def):\n",
    "    key_match = key_loc.match(column_def['ColumnName'])\n",
    "    if not key_match:\n",
    "        return column_def\n",
    "    name_dict = key_match.groupdict(default='')\n",
    "    # Remove Brackets and put commas between multiple types\n",
    "    name_dict['KeyType'] = name_dict['KeyType'].replace(')(',', ')\n",
    "    name_dict['KeyType'] = name_dict['KeyType'].replace('(','').replace(')','')\n",
    "    column_def.update(name_dict)\n",
    "    return column_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Column Description formatting\n",
    "1. Replace original bullet symbols with line breaks and Excel friendly bullets symbols\n",
    "2. Add line breaks after \":\"\n",
    "3. Convert double line breaks to single line breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_description(column_def):\n",
    "    clean_lines = [line.strip() for line in column_def['Description']]    \n",
    "    merged_text = ' '.join(clean_lines)\n",
    "    bullet_break_text = merged_text.replace('\\uf06e', chr(10) + u'\\u25cf')\n",
    "    colon_break_text = bullet_break_text.replace(':', ':' + chr(10))\n",
    "    dbl_break_text = colon_break_text.replace(''.join([chr(10),' ',chr(10)]), \n",
    "                                              chr(10))\n",
    "    if dbl_break_text.endswith('\\n'):\n",
    "        dbl_break_text = dbl_break_text[:-1]    \n",
    "    column_def['Description'] = dbl_break_text\n",
    "    return column_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Parse the file\n",
    "1. Get Raw Text\n",
    "2. Generate the Column Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Raw Text\n",
    "1. Read the text file\n",
    "2. Extract the desired chapters\n",
    "3. Break each row into 3 regions for analysis\n",
    "4. prepare to iterate through the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file name\n",
    "TEXT_DIR = Path.cwd() / '..' / 'Documentation'\n",
    "#text_file_name = 'Varian System Database Reference Guide V13.6.txt'\n",
    "text_file_name = 'Varian System Database Reference Guide V13.6 Edited.txt'\n",
    "text_file_path = TEXT_DIR / text_file_name\n",
    "\n",
    "# Read the text file\n",
    "raw_text = text_file_path.read_text(encoding='utf8', errors='ignore')\n",
    "# Convert to a list of lines\n",
    "raw_lines = raw_text.splitlines()\n",
    "\n",
    "# Select the desires chaper region\n",
    "table_descriptions, table_data_list = read_chapters(raw_lines)\n",
    "data_types = get_data_type_dict()  # For matching with known datatypes\n",
    "\n",
    "# Split each line into 3 parts and iterate through them\n",
    "row_sections = define_fixed_width_parser(locations=[55, 110])\n",
    "table_data_iter = BufferedIterator(row_sections(table_data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Column Table\n",
    "1. Parse the table and column text\n",
    "2. Extract Key Types from the column names\n",
    "3. Merge and format column description lines\n",
    "4. Convert to a DataFrame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = list()\n",
    "while True:\n",
    "    column_def = get_column_def(table_data_iter)\n",
    "    if not column_def:\n",
    "        break\n",
    "    column_def = get_key_type(column_def)\n",
    "    column_def = merge_description(column_def)\n",
    "    column_list.append(column_def)\n",
    "\n",
    "column_table = pd.DataFrame(column_list)\n",
    "column_table.drop('DescriptionOffset', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c6be8",
   "metadata": {},
   "source": [
    "# Save the Table and Column Descriptions\n",
    "- Save as `.pkl` file \n",
    "- Save as an Excel Spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the paths for saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL_DIR = Path.cwd() / '..' / 'Raw Tables'\n",
    "DATA_DIR = Path.cwd() / '..' / 'Raw Tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c547b32",
   "metadata": {},
   "source": [
    "#### Make pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6451a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = PKL_DIR / 'Table Descriptions.pkl'\n",
    "file = open(str(pickle_file), 'wb')\n",
    "dump(table_descriptions, file)\n",
    "file.close()\n",
    "\n",
    "pickle_file = PKL_DIR / 'Column Descriptions.pkl'\n",
    "file = open(str(pickle_file), 'wb')\n",
    "dump(column_table, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c547b32",
   "metadata": {},
   "source": [
    "#### Make spreadsheet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to spreadsheet\n",
    "spreadsheet_file = DATA_DIR / 'Table Descriptions.xlsx'\n",
    "xw.view(table_descriptions)\n",
    "workbook = xw.books.active\n",
    "workbook.sheets.active.name = 'Table Descriptions'\n",
    "workbook.save(spreadsheet_file)\n",
    "\n",
    "spreadsheet_file = DATA_DIR / 'Column Descriptions.xlsx'\n",
    "xw.view(column_table)\n",
    "workbook = xw.books.active\n",
    "workbook.sheets.active.name = 'Column Descriptions'\n",
    "workbook.save(spreadsheet_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66ef33868397d4b3ba585aec6a96f4069dc5c8f4bfb13ad07430863a61fdf935"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('variandb_relations': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
