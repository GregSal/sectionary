{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Example: Output from Windows Dir command\n",
    "This tutorial demonstrates the main features of the Sectionary package with a simple example; parsing the output of the Windows `DIR` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Standard Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Useful Third Party Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Sectionary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(r'../src/sectionary') \n",
    "\n",
    "import text_reader as tp\n",
    "from sections import Rule, RuleSet, SectionBreak, ProcessingMethods, Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## The Sample `Dir` Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The Windows `dir` command displays a list of a directory's files and subdirectories.  \n",
    "It's output will be used to showcase some of the features of the *sectionary* package.\n",
    "\n",
    "Adding switches (options) to the `dir` command control what it displays and the format of the output.\n",
    "In thses examples we will be using the command line:\n",
    "\n",
    "`DIR \"Test Dir Structure\" /S /N /-C /T:W >  \"test_DIR_Data.txt\"`\n",
    "\n",
    "| Switch | Description                                                                                              |\n",
    "|--------|----------------------------------------------------------------------------------------------------------|\n",
    "| /S     | Lists every occurrence of the specified file name within the specified directory and all subdirectories. |\n",
    "| /N     | Displays a long list format with file names on the far right of the screen.                              |\n",
    "| /-C    | Hides the thousand separator in file sizes.                                                              |\n",
    "| /T:W   | Specifies which time field to display as \"Last written\".                                                 |\n",
    "| >      | Redirect the output to the specified file.                                                               |\n",
    "\n",
    "For more information, see [DIR Command Syntax](https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_file = Path.cwd() / 'examples' / 'test_DIR_Data.txt'\n",
    "dir_text = test_file.read_text().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### `Dir` Output Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The first 20 lines of the diretory listing are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Volume in drive C is Windows\n",
      "\t  Volume Serial Number is DAE7-D5BA\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\n",
      "\t \n",
      "\t 2021-12-27  03:33 PM    <DIR>          .\n",
      "\t 2021-12-27  03:33 PM    <DIR>          ..\n",
      "\t 2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "\t 2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "\t 2016-02-25  09:59 PM                 3 TestFile1.txt\n",
      "\t 2016-02-15  06:46 PM                 7 TestFile2.rtf\n",
      "\t 2016-02-15  06:47 PM                 0 TestFile3.docx\n",
      "\t 2016-04-21  01:06 PM              3491 xcopy.txt\n",
      "\t                4 File(s)           3501 bytes\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\\Dir1\n",
      "\t \n",
      "\t 2021-12-27  04:03 PM    <DIR>          .\n",
      "\t 2021-12-27  04:03 PM    <DIR>          ..\n",
      "\t 2016-02-15  06:48 PM                 0 File in Dir One.txt\n"
     ]
    }
   ],
   "source": [
    "for line in dir_text[0:20]:\n",
    "    print('\\t', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We want to ignore the first two lines (the *header section*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Volume in drive C is Windows\n",
      "\t  Volume Serial Number is DAE7-D5BA\n"
     ]
    }
   ],
   "source": [
    "for line in dir_text[0:2]:\n",
    "    print('\\t', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "After this come multiple Folder sections something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Directory of c:\\users\\ ... \\Test Dir Structure\n",
      "\n",
      "2021-12-27  03:33 PM    <DIR>          .\n",
      "2021-12-27  03:33 PM    <DIR>          ..\n",
      "2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "               4 File(s)           3501 bytes\n"
     ]
    }
   ],
   "source": [
    "print(dir_text[3][0:23], '...', dir_text[3][-19:])\n",
    "print()\n",
    "for line in dir_text[5:9]:\n",
    "    print(line)\n",
    "print(dir_text[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Define a Section Based on start and end identifiers:\n",
    "\n",
    "The start and end of the folder listing can be identified by key phrases:\n",
    "- The section start is identified by the text '*Directory of*'\n",
    "- The section end is identified by the text '*File(s)*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', end_section='File(s)')\n",
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SectionBreak objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "`dir_section.read(dir_text)` returned the first folder listing in *dir_text*.\n",
    "However, it is missing the final line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               4 File(s)           3501 bytes\n"
     ]
    }
   ],
   "source": [
    "print(dir_text[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "To include this line, we need to define the end_setion to end *After* the specified text.  We include this information by explicitly creating a `SectionBreak` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'))\n",
    "\n",
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through multiple sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "dir_text is a list so `dir_section.read(dir_text)` starts over at the beginning each time it is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "By creating an iterator from *dir_text* `dir_text_iter = iter(dir_text)` \n",
    "(representing a text stream source) \n",
    "successive calls to `dir_section.read(dir_text_iter)` \n",
    "will return the next directory group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_text_iter = iter(dir_text)\n",
    "dir_section.read(dir_text_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure\\\\Dir1',\n",
       " '',\n",
       " '2021-12-27  04:03 PM    <DIR>          .',\n",
       " '2021-12-27  04:03 PM    <DIR>          ..',\n",
       " '2016-02-15  06:48 PM                 0 File in Dir One.txt',\n",
       " '2021-12-27  03:45 PM    <DIR>          SubFolder1',\n",
       " '2021-12-27  03:45 PM    <DIR>          SubFolder2',\n",
       " '               1 File(s)              0 bytes']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section.read(dir_text_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *DONE TO HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#print(Section.__doc__)\n",
    "#print(SectionBreak.__init__.__doc__)\n",
    "#print(Section.__init__.__doc__)\n",
    "#print(ProcessingMethods.__doc__)\n",
    "#print(ProcessingMethods.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ProcessingMethods.__init__.__doc__\n",
    "Applies a series of functions to a supplied sequence of items.\n",
    "\n",
    "        Processing functions should accept one the following argument sets:\n",
    "            func(item)\n",
    "            func(item, ** context)\n",
    "            func(item, context)\n",
    "            func(item, [other(s),] ** context)\n",
    "\n",
    "        Arguments:\n",
    "            processing_methods (ProcessGroup): The sequence of Processes\n",
    "                (functions, generator functions, Rules, and/or RuleSets) to be\n",
    "                applied to the section source.\n",
    "            name (str): Reference label for the processing method.\n",
    "                Defaults to 'Processor'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ProcessingMethods.__doc__\n",
    "Applies a series of functions to a supplied sequence of items.\n",
    "\n",
    "    Processing Methods combines a series of functions, generator functions,\n",
    "    Rules, and/or Rule Sets (Processes) to produce a single generator function.\n",
    "    The generator function will iterate through a supplied source of items\n",
    "    returning the final processed item. The output type of each Process must\n",
    "    match the expected input type of the next Process in the series.  No\n",
    "    validation tests are done on this.\n",
    "\n",
    "    A Process applied to a Source (a sequence of SourceItems) results in\n",
    "    a sequence of ProcessedItems.  The relation between SourceItems and\n",
    "    ProcessedItems is not necessarily 1:1.\n",
    "       1 SourceItem ≠1 ProcessedItem;\n",
    "    \t  • 1 SourceItem → 1 ProcessedItem\n",
    "    \t  • 1 SourceItem → 2+ ProcessedItems\n",
    "    \t  • 2+ SourceItems → 1 ProcessedItem\n",
    "\n",
    "    Generator functions are used when multiple input items are\n",
    "    required to generate an output item, or when one SourceItem results in\n",
    "    multiple ProcessedItems. In general, regular functions are used when there\n",
    "    is a one-to-one correspondence between input item and output item.  RuleSets\n",
    "    are used when the function that should be applied to the SourceItem(s)\n",
    "    depends on the result of one or more tests (Triggers).  Individual Rules can\n",
    "    be used when only a single Trigger is required (by using both the Pass and\n",
    "    Fail methods of the Rule) or to modify some of the SourceItems while leaving\n",
    "    others unchanged (by setting the Fail method to 'Original').  For Rules or\n",
    "    RuleSets it is important that the output is of the same type regardless of\n",
    "    whether the Trigger(s) pass or fail.\n",
    "\n",
    "    Processing functions should accept one the following argument sets:\n",
    "        func(item)\n",
    "        func(item, ** context)\n",
    "        func(item, context)\n",
    "        func(item, [other(s),] ** context)\n",
    "\n",
    "    Arguments:\n",
    "        processing_methods (ProcessGroup): The sequence of Processes (functions,\n",
    "            generator functions, Rules, and/or RuleSets) to be applied to a\n",
    "            source.\n",
    "        name (str): Reference label for the processing method.\n",
    "            Defaults to 'Processor'\n",
    "\n",
    "    Methods:\n",
    "        process(self, item, context)->RuleResult:\n",
    "        reader(self, buffered_source, context):\n",
    "        read(self, buffered_source, context):\n",
    "            a generator function, accepting a source text stream\n",
    "                and yielding the processed text. Defaults to None, which sets\n",
    "                a basic csv parser.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Section.__doc__\n",
    "Defines a continuous portion of a text stream or other iterable.\n",
    "\n",
    "    A section definition may include:\n",
    "        ○ Starting and ending break points.\n",
    "        ○ Processing instructions.\n",
    "        ○ An aggregation method.\n",
    "\n",
    "    A Section instance is created by defining one or more of these components.\n",
    "    Once a section has been defined, it can be applied to an iterator using:\n",
    "        section.read(source)\n",
    "        Where\n",
    "            source is any iterable supplying the text lines to be parsed.\n",
    "\n",
    "    section.read, the primary method has the following steps:\n",
    "        1. Iterate through the text source, checking for the start of the\n",
    "            section (optional).\n",
    "        2. Continue to iterate through the text source, applying the defined\n",
    "            processing rules to each line, while checking for the end of the\n",
    "            section.\n",
    "        3. Apply an aggregating function to the processed text to convert it\n",
    "            to the desired output format.\n",
    "\n",
    "    section.scan and section.process are alternate methods.\n",
    "        section.scan returns a generator that starts at the beginning of the\n",
    "            section and iterates through to the end of the section without\n",
    "            applying any processing or aggregation.\n",
    "\n",
    "        section.process returns a generator that starts at the beginning of\n",
    "            the section and iterates through to the end of the section\n",
    "            applying the defined processing, but omitting the aggregation.\n",
    "\n",
    "    Attributes:\n",
    "            section_name (str): A reference name for the section instance.\n",
    "            keep_partial (bool): In the case where the reader is\n",
    "                composed of one or more subsections and the main section ends\n",
    "                before the subsections end. If keep_partial is true the partial\n",
    "                subsection(s) will be returned, otherwise they will be dropped.\n",
    "            scan_status (str): Indicates section reading progress. It is useful\n",
    "                for providing user feedback when the section reading process\n",
    "                is lengthy.  scan_status Will contain one of the following\n",
    "                text strings:\n",
    "                   'Not Started'\n",
    "                   'At the start of section {section_name}'\n",
    "                   'Scan In Progress'\n",
    "                   'Break Triggered'\n",
    "                   'Scan Complete'\n",
    "            context (Dict[str, Any]): Break point information and any\n",
    "                additional information to be passed to and from break point,\n",
    "                processing and aggregation methods. This is the primary method\n",
    "                for different reading stages to pass contextual information.\n",
    "                When a section boundary is encountered (including sub-sections)\n",
    "                two items will be added to the context dictionary:\n",
    "                    'Break': (str): The name of the Trigger instance that\n",
    "                        activated the boundary condition.\n",
    "\n",
    "                    'Event' (bool, str, re.match): Information on the\n",
    "                        boundary condition returned by the Trigger instance.\n",
    "                            If Trigger always passes, 'Event' will be True.\n",
    "                            If Trigger matched a string, bool, 'Event' will\n",
    "                                be the matching string.\n",
    "\n",
    "                            If Trigger matched a regular expression, 'Event'\n",
    "                                will be the resulting re.match object.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SectionBreak.__init__.__doc__\n",
    "Defines trigger and offset for a Boundary point.\n",
    "\n",
    "        Arguments:\n",
    "            sentinel (TriggerOptions): Object(s) used to generate the\n",
    "                conditional definition.\n",
    "            location (str, optional):  A sentinel modifier that applies to str\n",
    "                or re.Pattern types of sentinels. For other sentinel types it\n",
    "                is ignored. One of  ['IN', 'START', 'END', 'FULL', None].\n",
    "                Default is None, which is treated as 'IN'\n",
    "\n",
    "            See Trigger class for more information on the sentinel and event\n",
    "            arguments.\n",
    "\n",
    "            break_offset (int, str, optional): The number of Source items\n",
    "                before (negative) or after (positive) between the item that\n",
    "                causes a trigger event and the boundary.  offset can also be\n",
    "                one of\n",
    "                    'After' =  0, or\n",
    "                    'Before' = -1\n",
    "                Defaults to 'Before'.\n",
    "            name (str, optional): A reference label for the Boundary."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Section.__init__.__doc__\n",
    "Creates an Section instance that defines a continuous portion of a\n",
    "        text stream to be processed in a specific way.\n",
    "\n",
    "        Arguments:\n",
    "            start_section (BreakOptions, optional): The SectionBreak(s) used\n",
    "                to identify the location of the start of the section. Defaults\n",
    "                to None, indicating the section begins with the first text\n",
    "                line in the iterator.\n",
    "            end_section (BreakOptions, optional): The SectionBreak(s) used\n",
    "                to identify the location of the end of the section. Defaults\n",
    "                to None, indicating the section ends with the last text line\n",
    "                in the iterator.\n",
    "            processor (ProcessMethodOptions, optional): Instructions for\n",
    "                processing and the section items.  A function or list of\n",
    "                functions to be applied to each item from the source sequence\n",
    "                that is identified as part of the section.  If processor is a\n",
    "                list of functions, the function will be applied in list order,\n",
    "                with the input of the function being the output of the previous\n",
    "                function in the list. See ProcessingMethods for more details on\n",
    "                valid processor functions.  If processor is None (the default),\n",
    "                the the section items are returned unmodified.\n",
    "            subsections (SectionOptions, optional): a Section instance,\n",
    "                or a list of Section instances contained within the section\n",
    "                being defined.\n",
    "            aggregate (AggregateCallableOptions, optional): A function used to\n",
    "                collect and format, the processor output into a single object.\n",
    "                Defaults to None, which returns a list of the processor output.\n",
    "            section_name (str, optional): A label to be applied to the section.\n",
    "                Defaults to 'Section'.\n",
    "            keep_partial (bool, optional): In the case where the reader is\n",
    "                composed of one or more subsections and the main section ends\n",
    "                before the subsections end. If keep_partial is true the partial\n",
    "                subsection(s) will be returned, otherwise they will be dropped.\n",
    "                Defaults to False.\n",
    "            end_on_first_item (bool, optional): If True, the item that triggers\n",
    "                the start of a section may also trigger the end of the section.\n",
    "                If False, the first item in the section will not be tested for\n",
    "                an end breakpoint. This is useful in cases where both\n",
    "                start_section and end_section might undesirably trigger on the\n",
    "                same line, resulting in an empty section.  Defaults to False.\n",
    "        Returns:\n",
    "            New Section.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Processing\n",
    "\n",
    "Once identified, a section's content can be *processed* before being returned.\n",
    "Text processing usually involves parsing text lines to identify and extract the \n",
    "desired information.\n",
    "\n",
    "Automatic processing of the items in a section's content is specified with the \n",
    "processor argument in the `Section` definition. If the processor argument is not \n",
    "given or is `None` the items in the section are returned as-is.(ProcessMethodOptions, optional): Instructions for\n",
    "                processing and the section items.  processor can be None, in\n",
    "                which case the section will use the default SectionProcessor,\n",
    "                it can be a SectionProcessor instance, a Section instance, or a\n",
    "                list of Section instances.\n",
    " by supplying the section with an \n",
    "`Aggregate` method.  The `aggregate` argument takes an *Aggregate* function; one\n",
    "that combines the section sequence into a single object.\n",
    "\n",
    "#%% Context Type\n",
    "# Context Provides a way to pass information between sections.\n",
    "# Context can be used to pass additional parameters to functions.\n",
    "\n",
    "\n",
    "#%% Relevant Callable Type definitions for Process and Rule functions.\n",
    "# Sentinel and Process Functions\n",
    "# Sentinel and Process Functions can function that can act on a SourceItem\n",
    "# provided the function signature is one of the following:\n",
    "#   Callable[[SourceItem], ProcessedItem]\n",
    "#   Callable[[SourceItem, ContextType], ProcessedItem]\n",
    "#   Callable[[SourceItem, ...], ProcessedItem]\n",
    "#       Where ... represents keyword arguments\n",
    "\n",
    "ContextType = Union[Dict[str, Any], None]\n",
    "ProcessFunc = Callable[[SourceItem, ContextType], ProcessedItems]\n",
    "ProcessMethods = Union[ProcessFunc, \"Rule\", \"RuleSet\"]\n",
    "ProcessCallableOptions = Union[ProcessFunc,\n",
    "                               Callable[[SourceItem], ProcessedItems],\n",
    "                               Callable[..., ProcessedItems]]\n",
    "ProcessMethodOptions = Union[str, ProcessCallableOptions, None]\n",
    "ProcessGroup = Union[ProcessMethodOptions, List[ProcessMethodOptions]]\n",
    "\n",
    "#%% Input and output Type Definitions\n",
    "SourceItem = TypeVar('SourceItem')\n",
    "Source = Iterable[SourceItem]\n",
    "# SourceOptions can be single SourceItem or an iterable of SourceItems.\n",
    "SourceOptions = Union[SourceItem, Source]\n",
    "# 1 or more ProcessMethods applied to SourceItems result in ProcessedItems\n",
    "#   1 SourceItem ≠1 ProcessedItem;\n",
    "#\t  • 1 SourceItem → 1 ProcessedItem\n",
    "#\t  • 1 SourceItem → 2+ ProcessedItems\n",
    "#\t  • 2+ SourceItems → 1 ProcessedItem;\n",
    "ProcessedItem = TypeVar('ProcessedItem')\n",
    "ProcessedList = List[ProcessedItem]\n",
    "ProcessOutput = Union[ProcessedItem, ProcessedList]\n",
    "ProcessedItemGen = Generator[ProcessedItem, None, None]\n",
    "ProcessedItems = Union[ProcessedItem, ProcessedItemGen]\n",
    "\n",
    "    Valid Action names depends on the method type:\n",
    "        Process Type:\n",
    "            'Original': return the original item supplied.\n",
    "            'Blank': return ''  (an empty string).\n",
    "            'None': return None.\n",
    "        Rule Type:\n",
    "            'Original': return the original item supplied.\n",
    "            'Blank': return ''  (an empty string).\n",
    "            'None': return None.\n",
    "            'Value': return the self.event.test_value object.\n",
    "            'Name': return the self.event.test_name object.\n",
    "            \n",
    "\n",
    "            processor (ProcessMethodOptions, optional): Instructions for\n",
    "                processing and the section items.  processor can be None, in\n",
    "                which case the section will use the default SectionProcessor,\n",
    "                it can be a SectionProcessor instance, a Section instance, or a\n",
    "                list of Section instances.\n",
    "\n",
    "\n",
    "\n",
    "#### Aggregate Functions\n",
    "Aggregate function are functions that can act on a sequence to combine them in \n",
    "some form.  The simplest aggregate function (and also the default) is the \n",
    "built-in list command.\n",
    "\n",
    "The aggregate function has one required positional argument, the sequence to be \n",
    "aggregated.  In addition, the function may contain a second positional argument,\n",
    "a *context* dictionary.  The *context* dictionary will be discussed in a more\n",
    "detail in a later section.  Additional keyword arguments may also be included.  \n",
    "If the keyword matches with a key in the section's *context*, The corresponding \n",
    "*context* value will be supplied.  Otherwise the keyword argument will be \n",
    "ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Directory Listing Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Path\n",
    "- The directory path line begins with the text *Directory of*:\n",
    "> `Directory of c:\\users\\...\\Test Dir Structure`\n",
    "- Extract the directory name from the full path:\n",
    "    1. Split the path at the last '\\'. \n",
    "    2. Keep the right hand part after the split.<br>\n",
    "    `text_line.rsplit('\\\\', 1)[1]`\n",
    "- Return a tab delimited line with:\n",
    "    - *Folder Name:* before the tab and \n",
    "    - The directory name after the tab\n",
    "  \n",
    "`output_line = 'Folder Name:\\t' + dir_line.rsplit('\\\\', 1)[1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Files\n",
    "- The last line in the listing gives the number of files in the directory.\n",
    "- That line contains the text *File(s)*:\n",
    "> `\t                4 File(s)           3501 bytes`\n",
    "- Extract the number of files from the beginning of the line:\n",
    "    1. Strip off the initial white space.\n",
    "    2. Split the remaining text after the first space\n",
    "    3. Keep the left hand part before the split.<br>\n",
    "    `text_line.strip().split(' ', 1)[0]`    \n",
    "- Return a tab delimited line with:\n",
    "    - An initial tab\n",
    "    - The text *Number of Files:* followed by another tab\n",
    "    - The extracted number of files.\n",
    "\n",
    "`output_line = 'Number of Files:\\t' + dir_line.strip().split(' ', 1)[0]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subdirectories\n",
    "- Lines containing a directory listing are indicated with the text *\\<DIR\\>*\n",
    "> `2021-12-27  04:03 PM    <DIR>          Dir1`\n",
    "- The name of the subdirectory begins at text column 36<br>\n",
    "    `text_line[36:]`    \n",
    "- Return a tab delimited line with:\n",
    "    - An initial tab\n",
    "    - The text *Subdirectory:* followed by another tab\n",
    "    - The extracted name of the subdirectory.\n",
    "\n",
    "`output_line = '\\tSubdirectory:\\t' + dir_line[36:]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files\n",
    "- The remaining lines are assumed to contain file information.\n",
    "- `\t 2016-02-25  09:59 PM                 3 TestFile1.txt`\n",
    "- The name of the file begins at text column 36<br>\n",
    "    `text_line[36:]`    \n",
    "- Return a tab delimited line with:\n",
    "    - An initial tab\n",
    "    - The text *File:* followed by another tab\n",
    "    - The extracted name of the file.\n",
    "\n",
    "`output_line = '\\tFile:\\t\\t' + dir_line[36:]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t  Directory of c:\\users\\...\\Test Dir Structure\n",
    "\t \n",
    "\t 2021-12-27  03:33 PM    <DIR>          .\n",
    "\t 2021-12-27  03:33 PM    <DIR>          ..\n",
    "\t 2021-12-27  04:03 PM    <DIR>          Dir1\n",
    "\t 2021-12-27  05:27 PM    <DIR>          Dir2\n",
    "\t 2016-02-25  09:59 PM                 3 TestFile1.txt\n",
    "\t 2016-02-15  06:46 PM                 7 TestFile2.rtf\n",
    "\t 2016-02-15  06:47 PM                 0 TestFile3.docx\n",
    "\t 2016-04-21  01:06 PM              3491 xcopy.txt\n",
    "\t                4 File(s)           3501 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> For the directory line, extract the directory name from the full path:\n",
    "`'Folder Name:\\t' + dir_line.rsplit('\\\\', 1)[1]`\n",
    "\n",
    "> Get the number of files in the directory:\n",
    "`'\\tNumber of Files:\\t' + dir_line.strip().split(' ', 1)[0]`\n",
    "\n",
    "> Identify subdirectories:\n",
    "`'\\tSubdirectory:\\t' + dir_line[36:]`\n",
    "\n",
    "> Identify files:\n",
    "`'\\tFile:\\t' + dir_line[36:]`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(dir_line):\n",
    "    # Get the directory name\n",
    "    if 'Directory of' in dir_line:\n",
    "        output_line = 'Folder Name:\\t' + dir_line.rsplit('\\\\', 1)[1]\n",
    "    # Label the subdirectories\n",
    "    elif '<DIR>' in dir_line:\n",
    "        output_line = '\\tSubdirectory:\\t' + dir_line[36:]\n",
    "    # Label the file counts\n",
    "    elif 'File(s)' in dir_line:\n",
    "        output_line = 'Number of Files:\\t' + dir_line.strip().split(' ', 1)[0]\n",
    "    # Label the files\n",
    "    else:\n",
    "        output_line = '\\tFile:\\t\\t' + dir_line[36:]\n",
    "    return output_line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Name:\tTest Dir Structure\n",
      "\tFile:\t\t\n",
      "\tSubdirectory:\t   .\n",
      "\tSubdirectory:\t   ..\n",
      "\tSubdirectory:\t   Dir1\n",
      "\tSubdirectory:\t   Dir2\n",
      "\tFile:\t\t 3 TestFile1.txt\n",
      "\tFile:\t\t 7 TestFile2.rtf\n",
      "\tFile:\t\t 0 TestFile3.docx\n",
      "\tFile:\t\t91 xcopy.txt\n",
      "Number of Files:\t4\n"
     ]
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'),\n",
    "                      processor=[process_directory])\n",
    "\n",
    "output = dir_section.read(dir_text)\n",
    "for line in output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule and RuleSets\n",
    "Instead of having one function `process_directory()` that manages all possible \n",
    "text lines in the section, the function can be broken down into parts by \n",
    "defining *Rules*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_name_split(line):\n",
    "    return ['Folder Name:', line.rsplit('\\\\', 1)[1]]\n",
    "dir_name_rule = Rule('Directory of', pass_method=dir_name_split)\n",
    "\n",
    "def file_count_split(line):\n",
    "    return ['Number of Files:', line.strip().split(' ', 1)[0]]\n",
    "file_count_rule = Rule('File(s)', pass_method=file_count_split)\n",
    "\n",
    "def subfolder(line):\n",
    "    return ['Subdirectory:', line[36:]]\n",
    "subfolder_rule = Rule('<DIR>', pass_method=subfolder)\n",
    "\n",
    "def file(line):\n",
    "    return ['File:' + line[36:]]\n",
    "\n",
    "dir_process = RuleSet([dir_name_rule, file_count_rule, subfolder_rule], \n",
    "                      default=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Folder Name:', 'Test Dir Structure']\n",
      "['File:']\n",
      "['Subdirectory:', '   .']\n",
      "['Subdirectory:', '   ..']\n",
      "['Subdirectory:', '   Dir1']\n",
      "['Subdirectory:', '   Dir2']\n",
      "['File: 3 TestFile1.txt']\n",
      "['File: 7 TestFile2.rtf']\n",
      "['File: 0 TestFile3.docx']\n",
      "['File:91 xcopy.txt']\n",
      "['Number of Files:', '4']\n"
     ]
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'),\n",
    "                      processor=[dir_process])\n",
    "\n",
    "output = dir_section.read(dir_text)\n",
    "for line in output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Folder Name:', 'Test Dir Structure']\n",
      "['File:']\n",
      "['Subdirectory:', '   .']\n",
      "['Subdirectory:', '   ..']\n",
      "['Subdirectory:', '   Dir1']\n",
      "['Subdirectory:', '   Dir2']\n",
      "['File: 3 TestFile1.txt']\n",
      "['File: 7 TestFile2.rtf']\n",
      "['File: 0 TestFile3.docx']\n",
      "['File:91 xcopy.txt']\n",
      "['Number of Files:', '4']\n"
     ]
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'),\n",
    "                      processor=ProcessingMethods([dir_process]))\n",
    "\n",
    "output = dir_section.read(dir_text)\n",
    "for line in output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def dir_name_split(line):\n",
    "    # Get the directory name\n",
    "    if 'Directory of' in line:\n",
    "        return ['Folder Name:', line.rsplit('\\\\', 1)[1]]\n",
    "    return line\n",
    "\n",
    "def subfolder(line):\n",
    "    # Label the subdirectories\n",
    "    if '<DIR>' in line:\n",
    "        return ['Subdirectory:', line[36:]]\n",
    "    return line\n",
    "\n",
    "def file_count_split(line):\n",
    "    # Label the file counts\n",
    "    if 'File(s)' in line:\n",
    "        return ['Number of Files:', line.strip().split(' ', 1)[0]]\n",
    "    return line\n",
    "\n",
    "def file(line):\n",
    "    # Label the files\n",
    "    return ['File:' + line[36:]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Aggregates\n",
    "\n",
    "A section's content can be summarized by supplying the section with an \n",
    "`Aggregate` method.  The `aggregate` argument takes an *Aggregate* function; one\n",
    "that combines the section sequence into a single object.\n",
    "\n",
    "#### Aggregate Functions\n",
    "Aggregate function are functions that can act on a sequence to combine them in \n",
    "some form.  The simplest aggregate function (and also the default) is the \n",
    "built-in list command.\n",
    "\n",
    "The aggregate function has one required positional argument, the sequence to be \n",
    "aggregated.  In addition, the function may contain a second positional argument,\n",
    "a *context* dictionary.  The *context* dictionary will be discussed in a more\n",
    "detail in a later section.  Additional keyword arguments may also be included.  \n",
    "If the keyword matches with a key in the section's *context*, The corresponding \n",
    "*context* value will be supplied.  Otherwise the keyword argument will be \n",
    "ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column index\n",
      "0000000000111111111122222222223333333333444444444455555555556666666666777777777788888888889999999999\n",
      "0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789\n",
      "2016-02-25  09:59 PM                 3 TestFile1.txt\n"
     ]
    }
   ],
   "source": [
    "print('column index')\n",
    "print(''.join(str(i)*10 for i in range(10)))\n",
    "print(''.join(str(i) for i in range(10))*10)\n",
    "print(dir_text[9])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**The DIR output has the following structure:**\n",
    "    \n",
    "    Header Section:\n",
    "         Volume in drive C has no label.\n",
    "         Volume Serial Number is 56DB-14A7\n",
    "\n",
    "Multiple Folder sections ... \n",
    "    \n",
    "    Summary Section:\n",
    "         Total Files Listed:\n",
    "                  11 File(s)          72507 bytes\n",
    "                  23 Dir(s)     63927545856 bytes free\n",
    "\n",
    "Each Folder section has the following line types:\n",
    "    \n",
    "    Directory Label:\n",
    "         Directory of C:\\Test Dir Structure\n",
    "    Directory listing:\n",
    "        2021-06-18  14:54    <DIR>          Dir1\n",
    "    File listing:\n",
    "        2016-02-25  22:59                 3 TestFile1.txt\n",
    "    File Count:\n",
    "               4 File(s)           3501 bytes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% Regex Parsing patterns\n",
    "# File Count and summary:\n",
    "     #          1 File(s)          59904 bytes\n",
    "     #         23 Dir(s)     63927545856 bytes free\n",
    "folder_summary_pt = re.compile(\n",
    "    '(?P<files>'       # beginning of files string group\n",
    "    '[0-9]+'           # Integer number of files\n",
    "    ')'                # end of files string group\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<type>'        # beginning of type string group\n",
    "    'File|Dir'         # \"File\" or \" Dir\" text\n",
    "    ')'                # end of type string group\n",
    "    '\\\\(s\\\\)'          # \"(s)\" text\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<size>'        # beginning of size string group\n",
    "    '[0-9]+'           # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    ' bytes'           # \"bytes\" text\n",
    "    )\n",
    "date_pattern = tp.build_date_re(compile_re=False)\n",
    "file_listing_pt = re.compile(\n",
    "    f'{date_pattern}'  # Insert date pattern\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<size>'        # beginning of size string group\n",
    "    '[0-9]+'           # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    ' '                # Single space\n",
    "    '(?P<filename>'    # beginning of filename string group\n",
    "    '.*'               # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    '$'                # end of string\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% Line Parsing Functions\n",
    "# Directory Label Rule\n",
    "\n",
    "def extract_directory(line: str, event, *args,\n",
    "                    context=None, **kwargs) -> List[List[str]]:\n",
    "    '''Extract Directory path from folder header.\n",
    "    '''\n",
    "    full_dir = line.replace('Directory of', '').strip()\n",
    "    return [full_dir]\n",
    "\n",
    "\n",
    "dir_header_rule = Rule(\n",
    "    name='Dir Header Rule',\n",
    "    sentinel='Directory of ',\n",
    "    pass_method=extract_directory\n",
    "    )\n",
    "\n",
    "\n",
    "# skip <DIR>\n",
    "def blank_line(*args, **kwargs) -> List[List[str]]:\n",
    "    return [['']]\n",
    "\n",
    "\n",
    "skip_dir_rule = Rule(\n",
    "    name='Skip <DIR> Rule',\n",
    "    sentinel=' <DIR> ',\n",
    "    pass_method='Blank'\n",
    "    )\n",
    "skip_totals_rule = Rule(\n",
    "    name='Skip Total Files Header Rule',\n",
    "    sentinel='Total Files Listed:',\n",
    "    pass_method='Blank'\n",
    "    )\n",
    "\n",
    "\n",
    "# Regular file listings\n",
    "def file_parse(line: str, event, *args, **kwargs) -> List[List[str]]:\n",
    "    '''Break file data into three columns containing Filename, Date, Size.\n",
    "\n",
    "    Typical file is:\n",
    "        2016-02-25  22:59     3 TestFile1.txt\n",
    "    File line is parsed using a regular expression with 3 named groups.\n",
    "    Output for the example above is:\n",
    "        [[TestFile1.txt , 2016-02-25  22:59, 3]]\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be parsed.\n",
    "        event (re.match): The results of the trigger test on the line.\n",
    "            Contains 3 named groups: ['date', 'size', 'filename'].\n",
    "        *args & **kwargs: Catch unused extra parameters passed to file_parse.\n",
    "\n",
    "    Returns:\n",
    "        tp.ParseResults: A one-item list containing the parsed file\n",
    "            information as a 3-item tuple:\n",
    "                [(filename: str, date: str, file size: int)].\n",
    "    '''\n",
    "    file_line_parts = event.test_value.groupdict(default='')\n",
    "    parsed_line = tuple([\n",
    "        file_line_parts['filename'],\n",
    "        tp.make_date_time_string(event),\n",
    "        int(file_line_parts['size'])\n",
    "        ])\n",
    "    return parsed_line\n",
    "\n",
    "\n",
    "# Regular File Parsing Rule\n",
    "file_listing_rule = Rule(file_listing_pt, pass_method=file_parse,\n",
    "                            name='Files_rule')\n",
    "\n",
    "\n",
    "# File Count Parsing Rule\n",
    "def file_count_parse(line: str, event, *args, **kwargs) -> List[List[str]]:\n",
    "    '''Break file data into two rows containing:\n",
    "           Number of files, & Directory size.\n",
    "\n",
    "    Output has the following format:\n",
    "        ['Number of files', file count value: int]\n",
    "        ['Directory Size', directory size value: int]\n",
    "\n",
    "    Typical line is:\n",
    "        4 File(s)           3501 bytes\n",
    "    File count is parsed using a regular expression with 2 named groups.\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be parsed.\n",
    "        event (re.match): The results of the trigger test size the line.\n",
    "            Contains 3 named groups: ['files', 'type', 'size'].\n",
    "        *args & **kwargs: Catch unused extra parameters passed to file_parse.\n",
    "\n",
    "    Returns:\n",
    "        tp.ParseResults: The parsed file information.\n",
    "            The parsed file information consists of three lines with the\n",
    "            following format:\n",
    "                'Number of files', file count value: int\n",
    "                'Directory Size', directory size value: int\n",
    "    '''\n",
    "    file_count_parts = event.groupdict(default='')\n",
    "    # Manage case where bytes free is given:\n",
    "    # 23 Dir(s)     63927545856 bytes free\n",
    "    if line.strip().endswith('free'):\n",
    "        file_count_parts['size_label'] = 'Free Space'\n",
    "    else:\n",
    "        file_count_parts['size_label'] = 'Size'\n",
    "    parsed_line_template = ''.join([\n",
    "        'Number of {type}s, {files}\\n',\n",
    "        'Directory {size_label}, {size}'\n",
    "        ])\n",
    "    parsed_line_str = parsed_line_template.format(**file_count_parts)\n",
    "    parsed_line = [new_line.split(',')\n",
    "                   for new_line in parsed_line_str.splitlines()]\n",
    "    return parsed_line\n",
    "file_count_rule = Rule(folder_summary_pt, pass_method=file_count_parse,\n",
    "                          name='Files_rule')\n",
    "\n",
    "\n",
    "skip_file_count_rule = Rule(\n",
    "    name='Skip File(s) Rule',\n",
    "    sentinel=folder_summary_pt,\n",
    "    pass_method='Blank'\n",
    "    )\n",
    "\n",
    "\n",
    "# Files / DIRs Parse\n",
    "def make_files_rule() -> Rule:\n",
    "    '''If  File(s) or  Dir(s) extract # files & size\n",
    "        '''\n",
    "    def files_total_parse(line, event, *args, **kwargs) -> List[List[str]]:\n",
    "        '''Break file counts into three columns containing:\n",
    "           Type (File or Dir), Count, Size.\n",
    "\n",
    "        The line:\n",
    "               11 File(s)          72507 bytes\n",
    "        Results in:\n",
    "            [('File', 11, 3501)]\n",
    "        The line:\n",
    "           23 Dir(s)     63927545856 bytes free\n",
    "        Results in:\n",
    "            [('Dir', 23, 3501)]\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be parsed.\n",
    "        event (re.match): The results of the trigger test on the line.\n",
    "            Contains 3 named groups: ['type', 'files', 'size'].\n",
    "        *args & **kwargs: Catch unused extra parameters passed to file_parse.\n",
    "\n",
    "    Returns:\n",
    "        tp.ParseResults: A one-item list containing the parsed file count\n",
    "            information as a 3-item tuple:\n",
    "                [(Type: str (File or Dir), Count: int, Size: int)].\n",
    "        '''\n",
    "        files_dict = event.test_value.groupdict(default='')\n",
    "        parsed_line = tuple([\n",
    "            files_dict[\"type\"],\n",
    "            files_dict[\"files\"],\n",
    "            files_dict[\"size\"]\n",
    "            ])\n",
    "        return [parsed_line]\n",
    "\n",
    "    files_total_rule = Rule(folder_summary_pt,\n",
    "                               pass_method=files_total_parse,\n",
    "                               name='Files_Total_rule')\n",
    "    return files_total_rule\n",
    "\n",
    "\n",
    "default_csv = tp.define_csv_parser('dir_files', delimiter=':',\n",
    "                                       skipinitialspace=True)\n",
    "\n",
    "\n",
    "#%% Line Processing\n",
    "def print_lines(parsed_list):\n",
    "    output = list()\n",
    "    for item in parsed_list:\n",
    "        pprint(item)\n",
    "        output.append(item)\n",
    "    return output\n",
    "\n",
    "\n",
    "def to_folder_dict(folder_list):\n",
    "    '''Combine folder info into dictionary.\n",
    "    '''\n",
    "    # TODO separate directory info from file info\n",
    "    #The first line in the folder list is the directory path\n",
    "    directory = ''\n",
    "    if folder_list:\n",
    "        d_list = folder_list[0]\n",
    "        if d_list:\n",
    "            directory = d_list[0]\n",
    "    folder_dict = {'Directory': directory}\n",
    "    for folder_info in folder_list[1:]:\n",
    "        filename, date, file_size = folder_info\n",
    "        full_path = '\\\\'.join([directory, filename])\n",
    "        file_parts = filename.rsplit('.', 1)\n",
    "        if len(file_parts) > 1:\n",
    "            extension = file_parts[1]\n",
    "        else:\n",
    "            extension = ''\n",
    "        folder_dict = {\n",
    "            'Path': full_path,\n",
    "            'Directory': directory,\n",
    "            'Filename': filename,\n",
    "            'Extension': extension,\n",
    "            'Date': date,\n",
    "            'Size': file_size\n",
    "            }\n",
    "    return folder_dict\n",
    "\n",
    "\n",
    "def make_files_table(dir_gen):\n",
    "    '''Combine folder info dictionaries into Pandas DataFrame.\n",
    "    '''\n",
    "    list_of_folders = list(dir_gen)\n",
    "    files_table = pd.DataFrame(list_of_folders)\n",
    "    files_table.set_index('Path')\n",
    "    return files_table\n",
    "\n",
    "\n",
    "#%% Reader definitions\n",
    "default_parser = tp.define_csv_parser('dir_files', delimiter=':',\n",
    "                                       skipinitialspace=True)\n",
    "heading_reader = ProcessingMethods([\n",
    "    default_parser,\n",
    "    tp.trim_items\n",
    "    ])\n",
    "folder_reader = ProcessingMethods([\n",
    "    RuleSet([skip_dir_rule, file_listing_rule, dir_header_rule,\n",
    "             skip_file_count_rule], default=default_parser),\n",
    "    tp.drop_blanks\n",
    "    ])\n",
    "summary_reader = ProcessingMethods([\n",
    "    RuleSet([file_count_rule, skip_totals_rule], default=default_parser),\n",
    "    tp.drop_blanks\n",
    "    ])\n",
    "\n",
    "\n",
    "#%% SectionBreak definitions\n",
    "folder_start = SectionBreak(\n",
    "    name='Start of Folder', sentinel='Directory of', break_offset='Before')\n",
    "folder_end = SectionBreak(name='End of Folder',sentinel=folder_summary_pt,\n",
    "                             break_offset='After')\n",
    "summary_start = SectionBreak(sentinel='Total Files Listed:',\n",
    "                                name='Start of DIR Summary', break_offset='Before')\n",
    "\n",
    "\n",
    "#%% Section definitions\n",
    "header_section = Section(\n",
    "    section_name='Header',\n",
    "    start_section=None,\n",
    "    end_section=folder_start,\n",
    "    processor=heading_reader,\n",
    "    aggregate=print_lines\n",
    "    )\n",
    "folder_section = Section(\n",
    "    section_name='Folder',\n",
    "    start_section=folder_start,\n",
    "    end_section=folder_end,\n",
    "    processor=folder_reader,\n",
    "    aggregate=to_folder_dict\n",
    "    )\n",
    "all_folder_section = Section(\n",
    "    section_name='All Folders',\n",
    "    start_section=folder_start,\n",
    "    end_section=summary_start,\n",
    "    processor=[folder_section],\n",
    "    aggregate=make_files_table\n",
    "    )\n",
    "summary_section = Section(\n",
    "    section_name='Summary',\n",
    "    start_section=summary_start,\n",
    "    end_section=None,\n",
    "    processor=summary_reader,\n",
    "    aggregate=tp.to_dict\n",
    "    )\n",
    "\n",
    "\n",
    "#%% Main Iteration\n",
    "def main():\n",
    "    # Test File\n",
    "    base_path = Path.cwd() / 'examples'\n",
    "    test_file = base_path / 'test_DIR_Data.txt'\n",
    "\n",
    "    # Call Primary routine\n",
    "    context = {\n",
    "        'File Name': test_file.name,\n",
    "        'File Path': test_file.parent,\n",
    "        'top_dir': str(base_path),\n",
    "        'tree_name': 'Test folder Tree'\n",
    "        }\n",
    "\n",
    "    source = tp.file_reader(test_file)\n",
    "    file_info = all_folder_section.read(source, context)\n",
    "    #summary = summary_section.read(source, **context)\n",
    "\n",
    "    # Output  Data\n",
    "    xw.view(file_info)\n",
    "    print('done')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('column index')\n",
    "print(''.join(str(i)*10 for i in range(10)))\n",
    "print(''.join(str(i) for i in range(10))*10)\n",
    "print(dir_text[9])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a =dir_text[3]\n",
    "a.index('\\\\')\n",
    "a.rsplit('\\\\', 1)\n",
    "#'Folder Name:\\t' + a.rsplit('\\\\', 1)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60a1f208f299629c0c5615e2cc619a90192052a9831bd288ceae6c3a09c71508"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('Standard': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
