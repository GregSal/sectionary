{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Example: Output from Windows Dir command\n",
    "This tutorial demonstrates the main features of the Sectionary package with a simple example; parsing the output of the Windows `DIR` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Standard Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Useful Third Party Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Sectionary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#sys.path.append(r'../src/sectionary') \n",
    "\n",
    "import text_reader as tp\n",
    "from sections import Rule, RuleSet, SectionBreak, ProcessingMethods, Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## The Sample `Dir` Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The Windows `dir` command displays a list of a directory's files and subdirectories.  \n",
    "It's output will be used to showcase some of the features of the *sectionary* package.\n",
    "\n",
    "Adding switches (options) to the `dir` command control what it displays and the format of the output.\n",
    "In thses examples we will be using the command line:\n",
    "\n",
    "`DIR \"Test Dir Structure\" /S /N /-C /T:W >  \"test_DIR_Data.txt\"`\n",
    "\n",
    "| Switch | Description                                                                                              |\n",
    "|--------|----------------------------------------------------------------------------------------------------------|\n",
    "| /S     | Lists every occurrence of the specified file name within the specified directory and all subdirectories. |\n",
    "| /N     | Displays a long list format with file names on the far right of the screen.                              |\n",
    "| /-C    | Hides the thousand separator in file sizes.                                                              |\n",
    "| /T:W   | Specifies which time field to display as \"Last written\".                                                 |\n",
    "| >      | Redirect the output to the specified file.                                                               |\n",
    "\n",
    "For more information, see [DIR Command Syntax](https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_file = Path.cwd() / 'examples' / 'test_DIR_Data.txt'\n",
    "dir_text = test_file.read_text().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### `Dir` Output Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The first 20 lines of the diretory listing are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Volume in drive C is Windows\n",
      "\t  Volume Serial Number is DAE7-D5BA\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\n",
      "\t \n",
      "\t 2021-12-27  03:33 PM    <DIR>          .\n",
      "\t 2021-12-27  03:33 PM    <DIR>          ..\n",
      "\t 2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "\t 2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "\t 2016-02-25  09:59 PM                 3 TestFile1.txt\n",
      "\t 2016-02-15  06:46 PM                 7 TestFile2.rtf\n",
      "\t 2016-02-15  06:47 PM                 0 TestFile3.docx\n",
      "\t 2016-04-21  01:06 PM              3491 xcopy.txt\n",
      "\t                4 File(s)           3501 bytes\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\\Dir1\n",
      "\t \n",
      "\t 2021-12-27  04:03 PM    <DIR>          .\n",
      "\t 2021-12-27  04:03 PM    <DIR>          ..\n",
      "\t 2016-02-15  06:48 PM                 0 File in Dir One.txt\n"
     ]
    }
   ],
   "source": [
    "for line in dir_text[0:20]:\n",
    "    print('\\t', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We want to ignore the first two lines (the *header section*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Volume in drive C is Windows\n",
      "\t  Volume Serial Number is DAE7-D5BA\n"
     ]
    }
   ],
   "source": [
    "for line in dir_text[0:2]:\n",
    "    print('\\t', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "After this come multiple Folder sections something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Directory of c:\\users\\ ... \\Test Dir Structure\n",
      "\n",
      "2021-12-27  03:33 PM    <DIR>          .\n",
      "2021-12-27  03:33 PM    <DIR>          ..\n",
      "2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "               4 File(s)           3501 bytes\n"
     ]
    }
   ],
   "source": [
    "print(dir_text[3][0:23], '...', dir_text[3][-19:])\n",
    "print()\n",
    "for line in dir_text[5:9]:\n",
    "    print(line)\n",
    "print(dir_text[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Define a Section Based on start and end identifiers:\n",
    "\n",
    "The start and end of the folder listing can be identified by key phrases:\n",
    "- The section start is identified by the text '*Directory of*'\n",
    "- The section end is identified by the text '*File(s)*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', end_section='File(s)')\n",
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SectionBreak objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "`dir_section.read(dir_text)` returned the first folder listing in *dir_text*.\n",
    "However, it is missing the final line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               4 File(s)           3501 bytes\n"
     ]
    }
   ],
   "source": [
    "print(dir_text[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "To include this line, we need to define the end_setion to end *After* the specified text.  We include this information by explicitly creating a `SectionBreak` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'))\n",
    "\n",
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through multiple sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "dir_text is a list so `dir_section.read(dir_text)` starts over at the beginning each time it is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section.read(dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "By creating an iterator from *dir_text* `dir_text_iter = iter(dir_text)` \n",
    "(representing a text stream source) \n",
    "successive calls to `dir_section.read(dir_text_iter)` \n",
    "will return the next directory group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure',\n",
       " '',\n",
       " '2021-12-27  03:33 PM    <DIR>          .',\n",
       " '2021-12-27  03:33 PM    <DIR>          ..',\n",
       " '2021-12-27  04:03 PM    <DIR>          Dir1',\n",
       " '2021-12-27  05:27 PM    <DIR>          Dir2',\n",
       " '2016-02-25  09:59 PM                 3 TestFile1.txt',\n",
       " '2016-02-15  06:46 PM                 7 TestFile2.rtf',\n",
       " '2016-02-15  06:47 PM                 0 TestFile3.docx',\n",
       " '2016-04-21  01:06 PM              3491 xcopy.txt',\n",
       " '               4 File(s)           3501 bytes']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_text_iter = iter(dir_text)\n",
    "dir_section.read(dir_text_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Directory of c:\\\\users\\\\...\\\\Test Dir Structure\\\\Dir1',\n",
       " '',\n",
       " '2021-12-27  04:03 PM    <DIR>          .',\n",
       " '2021-12-27  04:03 PM    <DIR>          ..',\n",
       " '2016-02-15  06:48 PM                 0 File in Dir One.txt',\n",
       " '2021-12-27  03:45 PM    <DIR>          SubFolder1',\n",
       " '2021-12-27  03:45 PM    <DIR>          SubFolder2',\n",
       " '               1 File(s)              0 bytes']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_section.read(dir_text_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Processing\n",
    "\n",
    "Once identified, a section's content can be *processed* before being returned.\n",
    "Automatic processing of the items in a section's content is specified with the \n",
    "*processor* argument in the *Section* definition. \n",
    "\n",
    "The *processor* argument takes a list of functions, *Rules*, or *RuleSets*. If \n",
    "the processor argument is not given or is `None` the items in the section are \n",
    "returned as-is.  *Rules* and *RuleSets* will be discussed in the next section.\n",
    "\n",
    "Processor functions have one required positional argument, the item to be \n",
    "processed.  In addition, the function may contain a second positional argument,\n",
    "a *context* dictionary.  The *context* dictionary will be discussed in a more\n",
    "detail in a later section.  Additional keyword arguments may also be included.  \n",
    "If the keyword matches with a key in the section's *context*, The corresponding \n",
    "*context* value will be supplied.  Otherwise the keyword argument will be \n",
    "ignored.\n",
    "\n",
    "The functions will be applied in list order with the input of the function being \n",
    "the output from the previous function.  This means that the expected input type \n",
    "of a processor function should be able to handle all possible output types from \n",
    "the previous function in the list.\n",
    "\n",
    "Processor functions may also be generator functions, in which case the required \n",
    "positional argument is the sequence to iterate over.  This can be useful if the \n",
    "processing involves skipping items or merging of multiple items.  Examples of \n",
    "this will be given in a separate tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Directory Listing Parts\n",
    "There are 4 different text line types in a directory listing section as we have \n",
    "defined it.  \n",
    "1. The directory path\n",
    "2. Subdirectory listings\n",
    "3. File listings\n",
    "4. number of flies\n",
    "\n",
    "Here we will write simple functions for each line type and a single processor \n",
    "function to handle all 4 types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Path\n",
    "- The directory path line begins with the text *Directory of*:\n",
    "> `Directory of c:\\users\\...\\Test Dir Structure`\n",
    "- Extract the directory name from the full path:\n",
    "    1. Split the path at the last '\\'. \n",
    "    2. Keep the right hand part after the split.<br>\n",
    "    `text_line.rsplit('\\\\', 1)[1]`\n",
    "- Return a tab delimited line with:\n",
    "    - *Folder Name:* before the tab and \n",
    "    - The directory name after the tab\n",
    "  \n",
    "`output_line = 'Folder Name:\\t' + dir_line.rsplit('\\\\', 1)[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_name_split(dir_line):\n",
    "    output_line = 'Folder Name:\\t' + dir_line.rsplit('\\\\', 1)[1]\n",
    "    return output_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Files\n",
    "- The last line in the listing gives the number of files in the directory.\n",
    "- That line contains the text *File(s)*:\n",
    "> `\t                4 File(s)           3501 bytes`\n",
    "- Extract the number of files from the beginning of the line:\n",
    "    1. Strip off the initial white space.\n",
    "    2. Split the remaining text after the first space\n",
    "    3. Keep the left hand part before the split.<br>\n",
    "    `text_line.strip().split(' ', 1)[0]`    \n",
    "- Return a tab delimited line with:\n",
    "    - An initial tab\n",
    "    - The text *Number of Files:* followed by another tab\n",
    "    - The extracted number of files.\n",
    "\n",
    "`output_line = 'Number of Files:\\t' + dir_line.strip().split(' ', 1)[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_count_split(dir_line):\n",
    "    output_line = 'Number of Files:\\t' + dir_line.strip().split(' ', 1)[0]\n",
    "    return output_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subdirectories\n",
    "- Lines containing a directory listing are indicated with the text *\\<DIR\\>*\n",
    "> `2021-12-27  04:03 PM    <DIR>          Dir1`\n",
    "- The name of the subdirectory begins at text column 36<br>\n",
    "    `text_line[36:]`    \n",
    "- Return a tab delimited line with:\n",
    "    - An initial tab\n",
    "    - The text *Subdirectory:* followed by another tab\n",
    "    - The extracted name of the subdirectory.\n",
    "\n",
    "`output_line = '\\tSubdirectory:\\t' + dir_line[36:]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfolder_name(dir_line):\n",
    "    output_line = '\\tSubdirectory:\\t' + dir_line[36:]\n",
    "    return output_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files\n",
    "- The remaining lines are assumed to contain file information.\n",
    "- `\t 2016-02-25  09:59 PM                 3 TestFile1.txt`\n",
    "- The name of the file begins at text column 36<br>\n",
    "    `text_line[36:]`    \n",
    "- Return a tab delimited line with:\n",
    "    - An initial tab\n",
    "    - The text *File:* followed by another tab\n",
    "    - The extracted name of the file.\n",
    "\n",
    "`output_line = '\\tFile:\\t\\t' + dir_line[36:]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(dir_line):\n",
    "    output_line = '\\tFile:\\t\\t' + dir_line[36:]\n",
    "    return output_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Directory Function\n",
    "Combine the above functions into one function that checks for the appropriate line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(dir_line):\n",
    "    # Get the directory name\n",
    "    if 'Directory of' in dir_line:\n",
    "        output_line = dir_name_split(dir_line)\n",
    "    # Label the subdirectories\n",
    "    elif '<DIR>' in dir_line:\n",
    "        output_line = get_subfolder_name(dir_line)\n",
    "    # Label the file counts\n",
    "    elif 'File(s)' in dir_line:\n",
    "        output_line = file_count_split(dir_line)\n",
    "    # Label the files\n",
    "    else:\n",
    "        output_line = get_file_name(dir_line)\n",
    "    return output_line "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Dir Section Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Name:\tTest Dir Structure\n",
      "\tFile:\t\t\n",
      "\tSubdirectory:\t   .\n",
      "\tSubdirectory:\t   ..\n",
      "\tSubdirectory:\t   Dir1\n",
      "\tSubdirectory:\t   Dir2\n",
      "\tFile:\t\t 3 TestFile1.txt\n",
      "\tFile:\t\t 7 TestFile2.rtf\n",
      "\tFile:\t\t 0 TestFile3.docx\n",
      "\tFile:\t\t91 xcopy.txt\n",
      "Number of Files:\t4\n"
     ]
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of',\n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'),\n",
    "                      processor=[process_directory])\n",
    "\n",
    "output = dir_section.read(dir_text)\n",
    "for line in output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule and RuleSets\n",
    "Instead of having one function `process_directory()` that manages all possible \n",
    "text lines in the section, the function can be broken down into parts by \n",
    "defining *Rules*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules\n",
    "Rules define an action to take on an item depending on the result of a test.\n",
    "\n",
    "A *Rule* definition has two parts:\n",
    "1. Trigger:\n",
    "   > Defines the test to be applied to the source item\n",
    "   > Trigger related arguments:\n",
    "   > - sentinel\n",
    "   >   - For string items, sentinel can be a string or compiled regular expression.\n",
    "   > - location\n",
    "   >   - A sentinel modifier that applies to str or re.Pattern types of sentinels. One of  ['IN', 'START', 'END', 'FULL', None]. Default is None, which is treated as 'IN'\n",
    "\n",
    "2. Action\n",
    "   > Defines the actions to take depending on the Trigger outcome.\n",
    "   > Action related arguments:\n",
    "   > - pass_method\n",
    "   > - fail_method\n",
    "   >\n",
    "   > Both take functions, or the name of standard actions to be implemented if the test passes or fails respectively.\n",
    "   >\n",
    "   > The pass_method and fail_method functions can be simple process functions, with one positional argument and additional keyword arguments. The functions can also contain a second positional argument *event* which allows the function to access information about the test results.  This is particularly useful when the sentinel is a regular expression.\n",
    "   >\n",
    "   > pass_method and fail_method can also be a string with the name of one of the standard actions.  The most common are:\n",
    "   > - 'Original': return the item being.\n",
    "   > - 'None': return None\n",
    "   > - 'Blank': return ''  (an empty string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RuleSets\n",
    "RuleSets combine related Rules to provide multiple choices for actions.\n",
    "\n",
    "- A Rule Set takes A sequence of Rules and a default method.\n",
    "- Each Rule in the sequence will be applied to the input until One of the rules triggers. At that point The sequence ends.  \n",
    "- If no Rule triggers then the default method is applied.  \n",
    "- Each of the Rules (and the default) should expect the same input type and should produce the same output type.  \n",
    "- The default_method can be any valid process function or standard action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Triggers*, *TriggerEvent*, *Rules* and *RuleSets* will be covered in more detail in a separate tutorial.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Process Directory Function into Rules\n",
    "The process_directory function consists of a set of `if` statements which each call a different function.  Each `if` statement can be converted into is own rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the directory name\n",
    "```\n",
    "if 'Directory of' in dir_line:\n",
    "    output_line = dir_name_split(dir_line)\n",
    "```\n",
    "**Becomes the Rule:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_rule = Rule('Directory of', pass_method=dir_name_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label the subdirectories\n",
    "```\n",
    "elif '<DIR>' in dir_line:\n",
    "    output_line = get_subfolder_name(dir_line)\n",
    "```\n",
    "**Becomes the Rule:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_rule = Rule('<DIR>', pass_method=get_subfolder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label the file counts\n",
    "```\n",
    "elif 'File(s)' in dir_line:\n",
    "    output_line = file_count_split(dir_line)\n",
    "```\n",
    "**Becomes the Rule:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count_rule = Rule('File(s)', pass_method=file_count_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label the files\n",
    "```\n",
    "else:\n",
    "    output_line = get_file_name(dir_line)\n",
    "\n",
    "```\n",
    "This is not converted into a rule because there is no conditional.  Instead it becaomes the default method for a *RuleSet*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_process = RuleSet([dir_name_rule, subfolder_rule, file_count_rule], \n",
    "                      default=get_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Dir Section Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Name:\tTest Dir Structure\n",
      "\tFile:\t\t\n",
      "\tSubdirectory:\t   .\n",
      "\tSubdirectory:\t   ..\n",
      "\tSubdirectory:\t   Dir1\n",
      "\tSubdirectory:\t   Dir2\n",
      "\tFile:\t\t 3 TestFile1.txt\n",
      "\tFile:\t\t 7 TestFile2.rtf\n",
      "\tFile:\t\t 0 TestFile3.docx\n",
      "\tFile:\t\t91 xcopy.txt\n",
      "Number of Files:\t4\n"
     ]
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'),\n",
    "                      processor=[dir_process])\n",
    "\n",
    "output = dir_section.read(dir_text)\n",
    "for line in output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *DONE TO HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Volume in drive C is Windows\n",
      "\t  Volume Serial Number is DAE7-D5BA\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\n",
      "\t \n",
      "\t 2021-12-27  03:33 PM    <DIR>          .\n",
      "\t 2021-12-27  03:33 PM    <DIR>          ..\n",
      "\t 2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "\t 2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "\t 2016-02-25  09:59 PM                 3 TestFile1.txt\n",
      "\t 2016-02-15  06:46 PM                 7 TestFile2.rtf\n",
      "\t 2016-02-15  06:47 PM                 0 TestFile3.docx\n",
      "\t 2016-04-21  01:06 PM              3491 xcopy.txt\n",
      "\t                4 File(s)           3501 bytes\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\\Dir1\n",
      "\t \n",
      "\t 2021-12-27  04:03 PM    <DIR>          .\n",
      "\t 2021-12-27  04:03 PM    <DIR>          ..\n",
      "\t 2016-02-15  06:48 PM                 0 File in Dir One.txt\n"
     ]
    }
   ],
   "source": [
    "for line in dir_text[0:20]:\n",
    "    print('\\t', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column index\n",
      "00000000001111111111222222222233333333334444444444555555555566666666667777777777\n",
      "01234567890123456789012345678901234567890123456789012345678901234567890123456789\n",
      "2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "2016-04-21  01:06 PM              3491 xcopy.txt\n"
     ]
    }
   ],
   "source": [
    "print('column index')\n",
    "print(''.join(str(i)*10 for i in range(8)))\n",
    "print(''.join(str(i) for i in range(10))*8)\n",
    "print(dir_text[8])\n",
    "print(dir_text[12]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-04-21  01:06 PM', '          ', '    3491 ', 'xcopy.txt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tp.FixedWidthParser(locations=[20,30,39])\n",
    "a.parse(dir_text[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object FixedWidthParser.parser at 0x00000203D1DEE6D0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tp.define_fixed_width_parser(locations=[20,30,39])\n",
    "b(dir_text[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2021-12-27  05:27 PM', '    <DIR> ', '         ', 'Dir2']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(b(dir_text[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def dir_name_split(dir_line):\n",
    "    output_dict = {'Folder Name': dir_line.rsplit('\\\\', 1)[1]}\n",
    "    return output_dict\n",
    "def file_count_split(dir_line):\n",
    "    output_dict = {'Number of Files': dir_line.strip().split(' ', 1)[0]}\n",
    "    return output_dict\n",
    "def get_subfolder_name(dir_line):\n",
    "    output_dict = {'Subdirectory': dir_line[36:]}\n",
    "    return output_dict\n",
    "def get_file_name(dir_line):\n",
    "    output_dict = {'File': dir_line[36:]}\n",
    "    return output_dict\n",
    "\n",
    "# Define Rules\n",
    "dir_name_rule = Rule('Directory of', pass_method=dir_name_split)\n",
    "subfolder_rule = Rule('<DIR>', pass_method=get_subfolder_name)\n",
    "file_count_rule = Rule('File(s)', pass_method=file_count_split)\n",
    "\n",
    "#Define Rule Set\n",
    "dir_process = RuleSet([dir_name_rule, subfolder_rule, file_count_rule], \n",
    "                      default=get_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#print(Section.__doc__)\n",
    "#print(SectionBreak.__init__.__doc__)\n",
    "#print(Section.__init__.__doc__)\n",
    "#print(ProcessingMethods.__doc__)\n",
    "#print(ProcessingMethods.__init__.__doc__)\n",
    "#print(Rule.__doc__)\n",
    "#print(Rule.__init__.__doc__)\n",
    "#print(RuleSet.__doc__)\n",
    "#print(RuleSet.__init__.__doc__)\n",
    "\n",
    "#from sections import Trigger, TriggerEvent\n",
    "#print(Trigger.__doc__)\n",
    "#print(Trigger.__init__.__doc__)\n",
    "#print(TriggerEvent.__doc__)\n",
    "#print(TriggerEvent.__init__.__doc__)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Trigger.__doc__\n",
    "Test definition for evaluating a source item.\n",
    "\n",
    "    A trigger is formed by a conditional definition to be applied to source\n",
    "    items.  The conditional definition is generated from one of the following\n",
    "    sentinel types:\n",
    "\n",
    "        None:   A place holder conditional that will never pass.\n",
    "\n",
    "        bool:   A conditional that will either always pass or always fail.\n",
    "\n",
    "        int:    A conditional that will pass after being called the specified\n",
    "                number of times. -- Not Yet Implemented.\n",
    "\n",
    "        str or List[str]:\n",
    "                A conditional that will pass if the item being tested matches\n",
    "                with the string (or with any of the strings in the list).  The\n",
    "                location attribute dictates the type of match required.\n",
    "\n",
    "        re.Pattern or List[re.Pattern]:  Compiled regular expression pattern(s)\n",
    "            A conditional that will pass if the pattern (or one of the patterns\n",
    "            in the list) successfully matches in the item being tested. The\n",
    "            location attribute dictates the type of regular expression match\n",
    "            required. Regular Expression patterns must be compiled with\n",
    "            re.compile(string) to distinguish them from plain text sentinels.\n",
    "\n",
    "        Callable or List[Callable]:\n",
    "                A conditional that will pass if the sentinel function (or one\n",
    "                of the functions in the list) returns a non-blank\n",
    "                (None, '', []) value when applied to the item being tested.\n",
    "\n",
    "    The location argument is a sentinel modifier that applies to str or\n",
    "        re.Pattern types of sentinels. location can be one of:\n",
    "            location    str test                    re.Pattern test\n",
    "              IN      sentinel in item            sentinel.search(item)\n",
    "              START   item.startswith(sentinel)   sentinel.match(item)\n",
    "              END     item.endswith(sentinel),    NotImplementedError\n",
    "              FULL    sentinel == item            sentinel.fullmatch(item)\n",
    "\n",
    "    When a test is applied, the event property is updated based on whether the\n",
    "        test passes and the type of test.\n",
    "\n",
    "        If the test fails:\n",
    "            event -> None.\n",
    "\n",
    "        If the test passes:\n",
    "            sentinel Type                   event Type\n",
    "\n",
    "            bool (True)                     bool (True)\n",
    "\n",
    "            int:                            int: the integer value of the\n",
    "                                                sentinel.\n",
    "\n",
    "            str or List[str]                str: the specific string in the\n",
    "                                                list that caused the pass.\n",
    "\n",
    "            re.Pattern or List[re.Pattern]  re.match: the match object\n",
    "                                                generated by applying the\n",
    "                                                pattern to the item.\n",
    "\n",
    "            Callable or List[Callable]      Any: The return value of the\n",
    "                                                successful function.\n",
    "\n",
    "    If the supplied sentinel is a list of strings, compiled regular expressions\n",
    "    or functions, the trigger will step through each sentinel element in the\n",
    "    list, evaluating them against the supplied item to test.  When a test\n",
    "    passes, no additional items in the list will be tested.\n",
    "\n",
    "    Attributes:\n",
    "            sentinel (None, bool, int, str, re.Pattern, Callable, or\n",
    "                      List[str], List[re.Pattern], List[Callable]): The\n",
    "                object(s) used to generate the conditional definition.\n",
    "\n",
    "                Note: int type sentinel is not yet implemented.\n",
    "\n",
    "            name (str, optional): A reference label for the Trigger.\n",
    "                A reference name for the section instance.\n",
    "\n",
    "            event (TriggerEvent): Information resulting from applying the test.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Trigger.__init__.__doc__\n",
    "Define test(s) that signal a trigger event.\n",
    "\n",
    "        Arguments:\n",
    "            name (str, optional): A reference label for the Trigger.\n",
    "            sentinel (TriggerOptions): Object(s) used to generate the\n",
    "                conditional definition.\n",
    "                Note: int type sentinel is not yet implemented.\n",
    "            location (str, optional):  A sentinel modifier that applies to str\n",
    "                or re.Pattern types of sentinels. For other sentinel types it\n",
    "                is ignored. One of  ['IN', 'START', 'END', 'FULL', None].\n",
    "                Default is None, which is treated as 'IN'\n",
    "                if sentinel is a string type:\n",
    "                    location == 'IN' -> sentinel in line,\n",
    "                    location == 'START' -> line.startswith(sentinel), in line,\n",
    "                    location == 'END' -> line.endswith(sentinel),\n",
    "                    location == 'FULL' -> sentinel == line.\n",
    "                if sentinel is a Regular Expression type:\n",
    "                    location == 'IN' -> sentinel.search(line),\n",
    "                    location == 'START' -> sentinel.match(line),\n",
    "                    location == 'FULL' -> sentinel.fullmatch(line),\n",
    "                    location == 'END' -> raise NotImplementedError."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TriggerEvent.__doc__\n",
    "Trigger test result information.\n",
    "\n",
    "    Attributes:\n",
    "        trigger_name (str): The name of the trigger the test is associated\n",
    "            with.\n",
    "        test_passed (bool): True if one of the applied tests passed; otherwise\n",
    "            False.\n",
    "        test_name (str): Label describing the passed text. Defaults to ''.\n",
    "            The test name type depends on sentinel_type:\n",
    "            type(sentinel)      test_name\n",
    "              None                'None'\n",
    "              bool                str(sentinel)\n",
    "              int                 str(sentinel)\n",
    "              str                 sentinel\n",
    "              List[str]           The sentinel item triggering the event\n",
    "              re.Pattern          sentinel.pattern\n",
    "              List[re.Pattern]    sentinel.pattern for the triggering item.\n",
    "              Callable            sentinel.__name__\n",
    "              List[Callable]      sentinel.__name__ for the triggering item.\n",
    "        test_value (EventType): Information resulting from applying the test.\n",
    "            The test_value object type depends on sentinel_type:\n",
    "                type(sentinel)      type(test_value)\n",
    "                  None                bool = False\n",
    "                  bool                bool\n",
    "                  int                 int = sentinel\n",
    "                  str                 str = sentinel\n",
    "                  List[str]           str = one of sentinel items\n",
    "                  re.Pattern          re.match\n",
    "                  List[re.Pattern]    re.match\n",
    "                  Callable            CallableResult\n",
    "                  List[Callable]      CallableResult"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rule.__doc__\n",
    "Defines action to take on an item depending on the result of a test.\n",
    "\n",
    "    A Rule is a subclass of Trigger, with two additional attributes and\n",
    "    related methods:\n",
    "        pass_method RuleMethod: The method to apply if the test passes.\n",
    "        fail_method RuleMethod: The method to apply if the test fails.\n",
    "\n",
    "    An additional default_method class attribute defines the action to assign\n",
    "    for undefined pass or fail methods.\n",
    "\n",
    "    Both pass_method and fail_method should have one of the following\n",
    "    argument signatures:\n",
    "        rule_method(item: SourceItem)\n",
    "        rule_method(item: SourceItem, ** context)\n",
    "        rule_method(item: SourceItem, event: TriggerEvent)\n",
    "        rule_method(item: SourceItem, event: TriggerEvent, **context)\n",
    "        rule_method(item: SourceItem, event: TriggerEvent, context)\n",
    "\n",
    "    Both pass_method and fail_method should return the same data type. No\n",
    "    checking is done to validate this.\n",
    "\n",
    "    In addition to a callable, the pass, fail and default attributes can be\n",
    "    the names of standard actions:\n",
    "        'Original': return the item being.\n",
    "        'Event': return the self.event object.\n",
    "        'Value': return the self.event.test_value object.\n",
    "        'Name': return the self.event.test_name object.\n",
    "        'None': return None\n",
    "        'Blank': return ''  (an empty string)\n",
    "\n",
    "    Attributes:\n",
    "        sentinel (None, bool, int, str, re.Pattern, Callable, or\n",
    "                  List[str], List[re.Pattern], List[Callable]): the object(s)\n",
    "            used to generate the conditional definition.\n",
    "        event (TriggerEvent): Information resulting from applying the test.\n",
    "        name (str): A text label for the rule.\n",
    "        pass_method (Callable, str, optional): The method to apply if the test\n",
    "            passes.\n",
    "        fail_method (Callable, str, optional): The method to apply if the test\n",
    "            fails.\n",
    "    ClassLevelAttribute:\n",
    "        default_method (Callable, str, optional): The method to use as the\n",
    "            pass or fail method if not specified defaults to 'Original'.\n",
    "    See Trigger class for more information on the sentinel and event attributes.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rule.__init__.__doc__\n",
    "Apply a method based on trigger test result.\n",
    "\n",
    "        Arguments:\n",
    "            sentinel (TriggerOptions): Object(s) used to generate the\n",
    "                conditional definition.\n",
    "            location (str, optional):  A sentinel modifier that applies to str\n",
    "                or re.Pattern types of sentinels. For other sentinel types it\n",
    "                is ignored. One of  ['IN', 'START', 'END', 'FULL', None].\n",
    "                Default is None, which is treated as 'IN'\n",
    "\n",
    "            See Trigger class for more information on the sentinel and event\n",
    "            arguments.\n",
    "\n",
    "            name (str, optional): A reference label for the Rule.\n",
    "\n",
    "            pass_method (RuleMethodOptions): A function, or the name of a\n",
    "                standard action to be implemented if the test passes on the\n",
    "                supplied item.\n",
    "            fail_method (RuleMethodOptions): A function, or the name of a\n",
    "                standard action to be implemented if the test fails on the\n",
    "                supplied item.\n",
    "\n",
    "        Both pass_method and fail_method should have one of the following\n",
    "        argument signatures:\n",
    "                rule_method(item: SourceItem)\n",
    "                rule_method(item: SourceItem, **context)\n",
    "                rule_method(item: SourceItem, event: TriggerEvent)\n",
    "                rule_method(item: SourceItem, event: TriggerEvent, **context)\n",
    "                rule_method(item: SourceItem, event: TriggerEvent, context)\n",
    "        Instead of a callable, pass_method and fail_method can be the name of a\n",
    "        standard actions:\n",
    "                'Original': return the item being.\n",
    "                'Event': return the self.event object.\n",
    "                'Value': return the self.event.test_value object.\n",
    "                'Name': return the self.event.test_name object.\n",
    "                'None': return None\n",
    "                'Blank': return ''  (an empty string)\n",
    "        Both pass_method and fail_method should return the same data type. No\n",
    "        checking is done to validate this.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RuleSet.__doc__\n",
    "Combines related Rules to provide multiple choices for actions.\n",
    "\n",
    "    A Rule Set takes A sequence of Rules and a default method each Rule in the\n",
    "    sequence will be applied to the input until One of the rules triggers. At\n",
    "    that point The sequence ends.  if no Rule triggers then the default method\n",
    "    is applied.  Each of the Rules (and the default) should expect the same\n",
    "    input type and should produce the same output type.\n",
    "\n",
    "    The default_method should have one of the following argument signatures:\n",
    "        rule_method(item: SourceItem)\n",
    "        rule_method(item: SourceItem, context)\n",
    "\n",
    "    The default_method can also be the names of a standard action:\n",
    "        'Original': return the item being.\n",
    "        'None': return None\n",
    "        'Blank': return ''  (an empty string)\n",
    "\n",
    "    All Rules in the RuleSet Should expect the same input data type and should\n",
    "    return the same data type. No checking is done to validate this.  The\n",
    "    return type from the default method should also match that of the Rules.\n",
    "\n",
    "    Attributes:\n",
    "        rule_seq (List[Rule]): The Rules to apply to the supplied object. The\n",
    "        result on only one of the Rules will be returned (the first one to\n",
    "        pass).  If none of the Rules pass, the output from the default method\n",
    "        will be returned.\n",
    "\n",
    "        default_method (ProcessFunc): The method to apply if none of the Rules\n",
    "            pass.\n",
    "        name (str): A text label for the rule set.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RuleSet.__init__.__doc__\n",
    "Apply a sequence of Rules, stopping with the first Rule to pass.\n",
    "\n",
    "        A RuleSet is a combination of Rules that expect similar input and\n",
    "        produce similar output. The rules are applied one-by-one to the input\n",
    "        object, stopping a rule passes. The output from that rule is returned\n",
    "        and all of the remaining rules in the set are skipped.\n",
    "\n",
    "        A default_method attribute defines the action to take if none of the\n",
    "        Rules in the set pass.\n",
    "\n",
    "        Arguments:\n",
    "            rule_list (List[Rule]): A list of rules to apply in the order\n",
    "                they are to be applied.\n",
    "            default (ProcessMethodOptions):  The method to apply if none of the\n",
    "                Rules pass. The default_method should have one of the\n",
    "                following argument signatures:\n",
    "                    rule_method(item: SourceItem)\n",
    "                    rule_method(item: SourceItem, context)\n",
    "                Or be the names of a standard action:\n",
    "                    'Original': return the item being.\n",
    "                    'Event': return the self.event object.\n",
    "                    'None': return None\n",
    "                    'Blank': return ''  (an empty string)\n",
    "                Defaults to 'None'.\n",
    "            name (str, optional): A reference label for the RuleSet.\n",
    "\n",
    "        All Rules in the RuleSet Should expect the same input data type and\n",
    "        should return the same data type. No checking is done to validate this.\n",
    "        The return type from the default method should also match that of the\n",
    "        Rules.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ProcessingMethods.__init__.__doc__\n",
    "Applies a series of functions to a supplied sequence of items.\n",
    "\n",
    "        Processing functions should accept one the following argument sets:\n",
    "            func(item)\n",
    "            func(item, ** context)\n",
    "            func(item, context)\n",
    "            func(item, [other(s),] ** context)\n",
    "\n",
    "        Arguments:\n",
    "            processing_methods (ProcessGroup): The sequence of Processes\n",
    "                (functions, generator functions, Rules, and/or RuleSets) to be\n",
    "                applied to the section source.\n",
    "            name (str): Reference label for the processing method.\n",
    "                Defaults to 'Processor'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ProcessingMethods.__doc__\n",
    "Applies a series of functions to a supplied sequence of items.\n",
    "\n",
    "    Processing Methods combines a series of functions, generator functions,\n",
    "    Rules, and/or Rule Sets (Processes) to produce a single generator function.\n",
    "    The generator function will iterate through a supplied source of items\n",
    "    returning the final processed item. The output type of each Process must\n",
    "    match the expected input type of the next Process in the series.  No\n",
    "    validation tests are done on this.\n",
    "\n",
    "    A Process applied to a Source (a sequence of SourceItems) results in\n",
    "    a sequence of ProcessedItems.  The relation between SourceItems and\n",
    "    ProcessedItems is not necessarily 1:1.\n",
    "       1 SourceItem ≠1 ProcessedItem;\n",
    "    \t  • 1 SourceItem → 1 ProcessedItem\n",
    "    \t  • 1 SourceItem → 2+ ProcessedItems\n",
    "    \t  • 2+ SourceItems → 1 ProcessedItem\n",
    "\n",
    "    Generator functions are used when multiple input items are\n",
    "    required to generate an output item, or when one SourceItem results in\n",
    "    multiple ProcessedItems. In general, regular functions are used when there\n",
    "    is a one-to-one correspondence between input item and output item.  RuleSets\n",
    "    are used when the function that should be applied to the SourceItem(s)\n",
    "    depends on the result of one or more tests (Triggers).  Individual Rules can\n",
    "    be used when only a single Trigger is required (by using both the Pass and\n",
    "    Fail methods of the Rule) or to modify some of the SourceItems while leaving\n",
    "    others unchanged (by setting the Fail method to 'Original').  For Rules or\n",
    "    RuleSets it is important that the output is of the same type regardless of\n",
    "    whether the Trigger(s) pass or fail.\n",
    "\n",
    "    Processing functions should accept one the following argument sets:\n",
    "        func(item)\n",
    "        func(item, ** context)\n",
    "        func(item, context)\n",
    "        func(item, [other(s),] ** context)\n",
    "\n",
    "    Arguments:\n",
    "        processing_methods (ProcessGroup): The sequence of Processes (functions,\n",
    "            generator functions, Rules, and/or RuleSets) to be applied to a\n",
    "            source.\n",
    "        name (str): Reference label for the processing method.\n",
    "            Defaults to 'Processor'\n",
    "\n",
    "    Methods:\n",
    "        process(self, item, context)->RuleResult:\n",
    "        reader(self, buffered_source, context):\n",
    "        read(self, buffered_source, context):\n",
    "            a generator function, accepting a source text stream\n",
    "                and yielding the processed text. Defaults to None, which sets\n",
    "                a basic csv parser.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Section.__doc__\n",
    "Defines a continuous portion of a text stream or other iterable.\n",
    "\n",
    "    A section definition may include:\n",
    "        ○ Starting and ending break points.\n",
    "        ○ Processing instructions.\n",
    "        ○ An aggregation method.\n",
    "\n",
    "    A Section instance is created by defining one or more of these components.\n",
    "    Once a section has been defined, it can be applied to an iterator using:\n",
    "        section.read(source)\n",
    "        Where\n",
    "            source is any iterable supplying the text lines to be parsed.\n",
    "\n",
    "    section.read, the primary method has the following steps:\n",
    "        1. Iterate through the text source, checking for the start of the\n",
    "            section (optional).\n",
    "        2. Continue to iterate through the text source, applying the defined\n",
    "            processing rules to each line, while checking for the end of the\n",
    "            section.\n",
    "        3. Apply an aggregating function to the processed text to convert it\n",
    "            to the desired output format.\n",
    "\n",
    "    section.scan and section.process are alternate methods.\n",
    "        section.scan returns a generator that starts at the beginning of the\n",
    "            section and iterates through to the end of the section without\n",
    "            applying any processing or aggregation.\n",
    "\n",
    "        section.process returns a generator that starts at the beginning of\n",
    "            the section and iterates through to the end of the section\n",
    "            applying the defined processing, but omitting the aggregation.\n",
    "\n",
    "    Attributes:\n",
    "            section_name (str): A reference name for the section instance.\n",
    "            keep_partial (bool): In the case where the reader is\n",
    "                composed of one or more subsections and the main section ends\n",
    "                before the subsections end. If keep_partial is true the partial\n",
    "                subsection(s) will be returned, otherwise they will be dropped.\n",
    "            scan_status (str): Indicates section reading progress. It is useful\n",
    "                for providing user feedback when the section reading process\n",
    "                is lengthy.  scan_status Will contain one of the following\n",
    "                text strings:\n",
    "                   'Not Started'\n",
    "                   'At the start of section {section_name}'\n",
    "                   'Scan In Progress'\n",
    "                   'Break Triggered'\n",
    "                   'Scan Complete'\n",
    "            context (Dict[str, Any]): Break point information and any\n",
    "                additional information to be passed to and from break point,\n",
    "                processing and aggregation methods. This is the primary method\n",
    "                for different reading stages to pass contextual information.\n",
    "                When a section boundary is encountered (including sub-sections)\n",
    "                two items will be added to the context dictionary:\n",
    "                    'Break': (str): The name of the Trigger instance that\n",
    "                        activated the boundary condition.\n",
    "\n",
    "                    'Event' (bool, str, re.match): Information on the\n",
    "                        boundary condition returned by the Trigger instance.\n",
    "                            If Trigger always passes, 'Event' will be True.\n",
    "                            If Trigger matched a string, bool, 'Event' will\n",
    "                                be the matching string.\n",
    "\n",
    "                            If Trigger matched a regular expression, 'Event'\n",
    "                                will be the resulting re.match object.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SectionBreak.__init__.__doc__\n",
    "Defines trigger and offset for a Boundary point.\n",
    "\n",
    "        Arguments:\n",
    "            sentinel (TriggerOptions): Object(s) used to generate the\n",
    "                conditional definition.\n",
    "            location (str, optional):  A sentinel modifier that applies to str\n",
    "                or re.Pattern types of sentinels. For other sentinel types it\n",
    "                is ignored. One of  ['IN', 'START', 'END', 'FULL', None].\n",
    "                Default is None, which is treated as 'IN'\n",
    "\n",
    "            See Trigger class for more information on the sentinel and event\n",
    "            arguments.\n",
    "\n",
    "            break_offset (int, str, optional): The number of Source items\n",
    "                before (negative) or after (positive) between the item that\n",
    "                causes a trigger event and the boundary.  offset can also be\n",
    "                one of\n",
    "                    'After' =  0, or\n",
    "                    'Before' = -1\n",
    "                Defaults to 'Before'.\n",
    "            name (str, optional): A reference label for the Boundary."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Section.__init__.__doc__\n",
    "Creates an Section instance that defines a continuous portion of a\n",
    "        text stream to be processed in a specific way.\n",
    "\n",
    "        Arguments:\n",
    "            start_section (BreakOptions, optional): The SectionBreak(s) used\n",
    "                to identify the location of the start of the section. Defaults\n",
    "                to None, indicating the section begins with the first text\n",
    "                line in the iterator.\n",
    "            end_section (BreakOptions, optional): The SectionBreak(s) used\n",
    "                to identify the location of the end of the section. Defaults\n",
    "                to None, indicating the section ends with the last text line\n",
    "                in the iterator.\n",
    "            processor (ProcessMethodOptions, optional): Instructions for\n",
    "                processing and the section items.  A function or list of\n",
    "                functions to be applied to each item from the source sequence\n",
    "                that is identified as part of the section.  If processor is a\n",
    "                list of functions, the function will be applied in list order,\n",
    "                with the input of the function being the output of the previous\n",
    "                function in the list. See ProcessingMethods for more details on\n",
    "                valid processor functions.  If processor is None (the default),\n",
    "                the the section items are returned unmodified.\n",
    "            subsections (SectionOptions, optional): a Section instance,\n",
    "                or a list of Section instances contained within the section\n",
    "                being defined.\n",
    "            aggregate (AggregateCallableOptions, optional): A function used to\n",
    "                collect and format, the processor output into a single object.\n",
    "                Defaults to None, which returns a list of the processor output.\n",
    "            section_name (str, optional): A label to be applied to the section.\n",
    "                Defaults to 'Section'.\n",
    "            keep_partial (bool, optional): In the case where the reader is\n",
    "                composed of one or more subsections and the main section ends\n",
    "                before the subsections end. If keep_partial is true the partial\n",
    "                subsection(s) will be returned, otherwise they will be dropped.\n",
    "                Defaults to False.\n",
    "            end_on_first_item (bool, optional): If True, the item that triggers\n",
    "                the start of a section may also trigger the end of the section.\n",
    "                If False, the first item in the section will not be tested for\n",
    "                an end breakpoint. This is useful in cases where both\n",
    "                start_section and end_section might undesirably trigger on the\n",
    "                same line, resulting in an empty section.  Defaults to False.\n",
    "        Returns:\n",
    "            New Section.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Folder Name:', 'Test Dir Structure']\n",
      "['File:']\n",
      "['Subdirectory:', '   .']\n",
      "['Subdirectory:', '   ..']\n",
      "['Subdirectory:', '   Dir1']\n",
      "['Subdirectory:', '   Dir2']\n",
      "['File: 3 TestFile1.txt']\n",
      "['File: 7 TestFile2.rtf']\n",
      "['File: 0 TestFile3.docx']\n",
      "['File:91 xcopy.txt']\n",
      "['Number of Files:', '4']\n"
     ]
    }
   ],
   "source": [
    "dir_section = Section(start_section='Directory of', \n",
    "                      end_section=SectionBreak('File(s)', break_offset='After'),\n",
    "                      processor=ProcessingMethods([dir_process]))\n",
    "\n",
    "output = dir_section.read(dir_text)\n",
    "for line in output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Aggregates\n",
    "\n",
    "A section's content can be summarized by supplying the section with an \n",
    "`Aggregate` method.  The `aggregate` argument takes an *Aggregate* function; one\n",
    "that combines the section sequence into a single object.\n",
    "\n",
    "#### Aggregate Functions\n",
    "Aggregate function are functions that can act on a sequence to combine them in \n",
    "some form.  The simplest aggregate function (and also the default) is the \n",
    "built-in list command.\n",
    "\n",
    "The aggregate function has one required positional argument, the sequence to be \n",
    "aggregated.  In addition, the function may contain a second positional argument,\n",
    "a *context* dictionary.  The *context* dictionary will be discussed in a more\n",
    "detail in a later section.  Additional keyword arguments may also be included.  \n",
    "If the keyword matches with a key in the section's *context*, The corresponding \n",
    "*context* value will be supplied.  Otherwise the keyword argument will be \n",
    "ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column index\n",
      "0000000000111111111122222222223333333333444444444455555555556666666666777777777788888888889999999999\n",
      "0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789\n",
      "2016-02-25  09:59 PM                 3 TestFile1.txt\n"
     ]
    }
   ],
   "source": [
    "print('column index')\n",
    "print(''.join(str(i)*10 for i in range(10)))\n",
    "print(''.join(str(i) for i in range(10))*10)\n",
    "print(dir_text[9])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**The DIR output has the following structure:**\n",
    "    \n",
    "    Header Section:\n",
    "         Volume in drive C has no label.\n",
    "         Volume Serial Number is 56DB-14A7\n",
    "\n",
    "Multiple Folder sections ... \n",
    "    \n",
    "    Summary Section:\n",
    "         Total Files Listed:\n",
    "                  11 File(s)          72507 bytes\n",
    "                  23 Dir(s)     63927545856 bytes free\n",
    "\n",
    "Each Folder section has the following line types:\n",
    "    \n",
    "    Directory Label:\n",
    "         Directory of C:\\Test Dir Structure\n",
    "    Directory listing:\n",
    "        2021-06-18  14:54    <DIR>          Dir1\n",
    "    File listing:\n",
    "        2016-02-25  22:59                 3 TestFile1.txt\n",
    "    File Count:\n",
    "               4 File(s)           3501 bytes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% Regex Parsing patterns\n",
    "# File Count and summary:\n",
    "     #          1 File(s)          59904 bytes\n",
    "     #         23 Dir(s)     63927545856 bytes free\n",
    "folder_summary_pt = re.compile(\n",
    "    '(?P<files>'       # beginning of files string group\n",
    "    '[0-9]+'           # Integer number of files\n",
    "    ')'                # end of files string group\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<type>'        # beginning of type string group\n",
    "    'File|Dir'         # \"File\" or \" Dir\" text\n",
    "    ')'                # end of type string group\n",
    "    '\\\\(s\\\\)'          # \"(s)\" text\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<size>'        # beginning of size string group\n",
    "    '[0-9]+'           # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    ' bytes'           # \"bytes\" text\n",
    "    )\n",
    "date_pattern = tp.build_date_re(compile_re=False)\n",
    "file_listing_pt = re.compile(\n",
    "    f'{date_pattern}'  # Insert date pattern\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<size>'        # beginning of size string group\n",
    "    '[0-9]+'           # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    ' '                # Single space\n",
    "    '(?P<filename>'    # beginning of filename string group\n",
    "    '.*'               # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    '$'                # end of string\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% Line Parsing Functions\n",
    "# Directory Label Rule\n",
    "\n",
    "def extract_directory(line: str, event, *args,\n",
    "                    context=None, **kwargs) -> List[List[str]]:\n",
    "    '''Extract Directory path from folder header.\n",
    "    '''\n",
    "    full_dir = line.replace('Directory of', '').strip()\n",
    "    return [full_dir]\n",
    "\n",
    "\n",
    "dir_header_rule = Rule(\n",
    "    name='Dir Header Rule',\n",
    "    sentinel='Directory of ',\n",
    "    pass_method=extract_directory\n",
    "    )\n",
    "\n",
    "\n",
    "# skip <DIR>\n",
    "def blank_line(*args, **kwargs) -> List[List[str]]:\n",
    "    return [['']]\n",
    "\n",
    "\n",
    "skip_dir_rule = Rule(\n",
    "    name='Skip <DIR> Rule',\n",
    "    sentinel=' <DIR> ',\n",
    "    pass_method='Blank'\n",
    "    )\n",
    "skip_totals_rule = Rule(\n",
    "    name='Skip Total Files Header Rule',\n",
    "    sentinel='Total Files Listed:',\n",
    "    pass_method='Blank'\n",
    "    )\n",
    "\n",
    "\n",
    "# Regular file listings\n",
    "def file_parse(line: str, event, *args, **kwargs) -> List[List[str]]:\n",
    "    '''Break file data into three columns containing Filename, Date, Size.\n",
    "\n",
    "    Typical file is:\n",
    "        2016-02-25  22:59     3 TestFile1.txt\n",
    "    File line is parsed using a regular expression with 3 named groups.\n",
    "    Output for the example above is:\n",
    "        [[TestFile1.txt , 2016-02-25  22:59, 3]]\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be parsed.\n",
    "        event (re.match): The results of the trigger test on the line.\n",
    "            Contains 3 named groups: ['date', 'size', 'filename'].\n",
    "        *args & **kwargs: Catch unused extra parameters passed to file_parse.\n",
    "\n",
    "    Returns:\n",
    "        tp.ParseResults: A one-item list containing the parsed file\n",
    "            information as a 3-item tuple:\n",
    "                [(filename: str, date: str, file size: int)].\n",
    "    '''\n",
    "    file_line_parts = event.test_value.groupdict(default='')\n",
    "    parsed_line = tuple([\n",
    "        file_line_parts['filename'],\n",
    "        tp.make_date_time_string(event),\n",
    "        int(file_line_parts['size'])\n",
    "        ])\n",
    "    return parsed_line\n",
    "\n",
    "\n",
    "# Regular File Parsing Rule\n",
    "file_listing_rule = Rule(file_listing_pt, pass_method=file_parse,\n",
    "                            name='Files_rule')\n",
    "\n",
    "\n",
    "# File Count Parsing Rule\n",
    "def file_count_parse(line: str, event, *args, **kwargs) -> List[List[str]]:\n",
    "    '''Break file data into two rows containing:\n",
    "           Number of files, & Directory size.\n",
    "\n",
    "    Output has the following format:\n",
    "        ['Number of files', file count value: int]\n",
    "        ['Directory Size', directory size value: int]\n",
    "\n",
    "    Typical line is:\n",
    "        4 File(s)           3501 bytes\n",
    "    File count is parsed using a regular expression with 2 named groups.\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be parsed.\n",
    "        event (re.match): The results of the trigger test size the line.\n",
    "            Contains 3 named groups: ['files', 'type', 'size'].\n",
    "        *args & **kwargs: Catch unused extra parameters passed to file_parse.\n",
    "\n",
    "    Returns:\n",
    "        tp.ParseResults: The parsed file information.\n",
    "            The parsed file information consists of three lines with the\n",
    "            following format:\n",
    "                'Number of files', file count value: int\n",
    "                'Directory Size', directory size value: int\n",
    "    '''\n",
    "    file_count_parts = event.groupdict(default='')\n",
    "    # Manage case where bytes free is given:\n",
    "    # 23 Dir(s)     63927545856 bytes free\n",
    "    if line.strip().endswith('free'):\n",
    "        file_count_parts['size_label'] = 'Free Space'\n",
    "    else:\n",
    "        file_count_parts['size_label'] = 'Size'\n",
    "    parsed_line_template = ''.join([\n",
    "        'Number of {type}s, {files}\\n',\n",
    "        'Directory {size_label}, {size}'\n",
    "        ])\n",
    "    parsed_line_str = parsed_line_template.format(**file_count_parts)\n",
    "    parsed_line = [new_line.split(',')\n",
    "                   for new_line in parsed_line_str.splitlines()]\n",
    "    return parsed_line\n",
    "file_count_rule = Rule(folder_summary_pt, pass_method=file_count_parse,\n",
    "                          name='Files_rule')\n",
    "\n",
    "\n",
    "skip_file_count_rule = Rule(\n",
    "    name='Skip File(s) Rule',\n",
    "    sentinel=folder_summary_pt,\n",
    "    pass_method='Blank'\n",
    "    )\n",
    "\n",
    "\n",
    "# Files / DIRs Parse\n",
    "def make_files_rule() -> Rule:\n",
    "    '''If  File(s) or  Dir(s) extract # files & size\n",
    "        '''\n",
    "    def files_total_parse(line, event, *args, **kwargs) -> List[List[str]]:\n",
    "        '''Break file counts into three columns containing:\n",
    "           Type (File or Dir), Count, Size.\n",
    "\n",
    "        The line:\n",
    "               11 File(s)          72507 bytes\n",
    "        Results in:\n",
    "            [('File', 11, 3501)]\n",
    "        The line:\n",
    "           23 Dir(s)     63927545856 bytes free\n",
    "        Results in:\n",
    "            [('Dir', 23, 3501)]\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be parsed.\n",
    "        event (re.match): The results of the trigger test on the line.\n",
    "            Contains 3 named groups: ['type', 'files', 'size'].\n",
    "        *args & **kwargs: Catch unused extra parameters passed to file_parse.\n",
    "\n",
    "    Returns:\n",
    "        tp.ParseResults: A one-item list containing the parsed file count\n",
    "            information as a 3-item tuple:\n",
    "                [(Type: str (File or Dir), Count: int, Size: int)].\n",
    "        '''\n",
    "        files_dict = event.test_value.groupdict(default='')\n",
    "        parsed_line = tuple([\n",
    "            files_dict[\"type\"],\n",
    "            files_dict[\"files\"],\n",
    "            files_dict[\"size\"]\n",
    "            ])\n",
    "        return [parsed_line]\n",
    "\n",
    "    files_total_rule = Rule(folder_summary_pt,\n",
    "                               pass_method=files_total_parse,\n",
    "                               name='Files_Total_rule')\n",
    "    return files_total_rule\n",
    "\n",
    "\n",
    "default_csv = tp.define_csv_parser('dir_files', delimiter=':',\n",
    "                                       skipinitialspace=True)\n",
    "\n",
    "\n",
    "#%% Line Processing\n",
    "def print_lines(parsed_list):\n",
    "    output = list()\n",
    "    for item in parsed_list:\n",
    "        pprint(item)\n",
    "        output.append(item)\n",
    "    return output\n",
    "\n",
    "\n",
    "def to_folder_dict(folder_list):\n",
    "    '''Combine folder info into dictionary.\n",
    "    '''\n",
    "    # TODO separate directory info from file info\n",
    "    #The first line in the folder list is the directory path\n",
    "    directory = ''\n",
    "    if folder_list:\n",
    "        d_list = folder_list[0]\n",
    "        if d_list:\n",
    "            directory = d_list[0]\n",
    "    folder_dict = {'Directory': directory}\n",
    "    for folder_info in folder_list[1:]:\n",
    "        filename, date, file_size = folder_info\n",
    "        full_path = '\\\\'.join([directory, filename])\n",
    "        file_parts = filename.rsplit('.', 1)\n",
    "        if len(file_parts) > 1:\n",
    "            extension = file_parts[1]\n",
    "        else:\n",
    "            extension = ''\n",
    "        folder_dict = {\n",
    "            'Path': full_path,\n",
    "            'Directory': directory,\n",
    "            'Filename': filename,\n",
    "            'Extension': extension,\n",
    "            'Date': date,\n",
    "            'Size': file_size\n",
    "            }\n",
    "    return folder_dict\n",
    "\n",
    "\n",
    "def make_files_table(dir_gen):\n",
    "    '''Combine folder info dictionaries into Pandas DataFrame.\n",
    "    '''\n",
    "    list_of_folders = list(dir_gen)\n",
    "    files_table = pd.DataFrame(list_of_folders)\n",
    "    files_table.set_index('Path')\n",
    "    return files_table\n",
    "\n",
    "\n",
    "#%% Reader definitions\n",
    "default_parser = tp.define_csv_parser('dir_files', delimiter=':',\n",
    "                                       skipinitialspace=True)\n",
    "heading_reader = ProcessingMethods([\n",
    "    default_parser,\n",
    "    tp.trim_items\n",
    "    ])\n",
    "folder_reader = ProcessingMethods([\n",
    "    RuleSet([skip_dir_rule, file_listing_rule, dir_header_rule,\n",
    "             skip_file_count_rule], default=default_parser),\n",
    "    tp.drop_blanks\n",
    "    ])\n",
    "summary_reader = ProcessingMethods([\n",
    "    RuleSet([file_count_rule, skip_totals_rule], default=default_parser),\n",
    "    tp.drop_blanks\n",
    "    ])\n",
    "\n",
    "\n",
    "#%% SectionBreak definitions\n",
    "folder_start = SectionBreak(\n",
    "    name='Start of Folder', sentinel='Directory of', break_offset='Before')\n",
    "folder_end = SectionBreak(name='End of Folder',sentinel=folder_summary_pt,\n",
    "                             break_offset='After')\n",
    "summary_start = SectionBreak(sentinel='Total Files Listed:',\n",
    "                                name='Start of DIR Summary', break_offset='Before')\n",
    "\n",
    "\n",
    "#%% Section definitions\n",
    "header_section = Section(\n",
    "    section_name='Header',\n",
    "    start_section=None,\n",
    "    end_section=folder_start,\n",
    "    processor=heading_reader,\n",
    "    aggregate=print_lines\n",
    "    )\n",
    "folder_section = Section(\n",
    "    section_name='Folder',\n",
    "    start_section=folder_start,\n",
    "    end_section=folder_end,\n",
    "    processor=folder_reader,\n",
    "    aggregate=to_folder_dict\n",
    "    )\n",
    "all_folder_section = Section(\n",
    "    section_name='All Folders',\n",
    "    start_section=folder_start,\n",
    "    end_section=summary_start,\n",
    "    processor=[folder_section],\n",
    "    aggregate=make_files_table\n",
    "    )\n",
    "summary_section = Section(\n",
    "    section_name='Summary',\n",
    "    start_section=summary_start,\n",
    "    end_section=None,\n",
    "    processor=summary_reader,\n",
    "    aggregate=tp.to_dict\n",
    "    )\n",
    "\n",
    "\n",
    "#%% Main Iteration\n",
    "def main():\n",
    "    # Test File\n",
    "    base_path = Path.cwd() / 'examples'\n",
    "    test_file = base_path / 'test_DIR_Data.txt'\n",
    "\n",
    "    # Call Primary routine\n",
    "    context = {\n",
    "        'File Name': test_file.name,\n",
    "        'File Path': test_file.parent,\n",
    "        'top_dir': str(base_path),\n",
    "        'tree_name': 'Test folder Tree'\n",
    "        }\n",
    "\n",
    "    source = tp.file_reader(test_file)\n",
    "    file_info = all_folder_section.read(source, context)\n",
    "    #summary = summary_section.read(source, **context)\n",
    "\n",
    "    # Output  Data\n",
    "    xw.view(file_info)\n",
    "    print('done')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('column index')\n",
    "print(''.join(str(i)*10 for i in range(10)))\n",
    "print(''.join(str(i) for i in range(10))*10)\n",
    "print(dir_text[9])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a =dir_text[3]\n",
    "a.index('\\\\')\n",
    "a.rsplit('\\\\', 1)\n",
    "#'Folder Name:\\t' + a.rsplit('\\\\', 1)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60a1f208f299629c0c5615e2cc619a90192052a9831bd288ceae6c3a09c71508"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('Standard': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
