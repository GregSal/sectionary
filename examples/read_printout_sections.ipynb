{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Example Read Plan Printout Sections"]},{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"markdown","metadata":{},"source":["##### Standard Python Modules"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from typing import Tuple, List, Dict, Union, Any\n","from pathlib import Path\n","from pprint import pprint\n","from functools import partial\n","import re"]},{"cell_type":"markdown","metadata":{},"source":["##### Public Modules from Anaconda"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import xlwings as xw"]},{"cell_type":"markdown","metadata":{},"source":["##### Sectionary Specific imports"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import sections as sec\n","import text_reader as tr"]},{"cell_type":"markdown","metadata":{},"source":["## Text Processing Functions"]},{"cell_type":"markdown","metadata":{},"source":["### Split a text string into parts.\n","- The `delimiter=';'` argument tells it to split the string on \";\"s.\n","- The `skipinitialspace=True` argument tells it to strip leading spaces from the\n"," text.\n","\n"," For example:\n"," |Text|Becomes|\n"," |----|-------|\n"," |`'       Course;C1'`|`['Course', 'C1']`]|\n"," |`'Intent;1_PRIMARY'`|`['Intent', '1_PRIMARY']`]|\n"," |`'Plan Id;PELB FB'`|`['Plan Id', 'PELB FB']`]|\n"," |`'Technique;'`|`['Technique']`]|"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dict_parse = tr.define_csv_parser(\n","    delimiter=';',\n","    skipinitialspace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Convert a list of two-item lists to a dictionary.\n","- First item in the sub-list is the key.  The second item is the value.\n","- `default_value=None` will cause one-item sub-lists to be dropped.\n","\n"," For example the text:\n"," ```[\n","    ['Course', 'C1'],\n","    ['Intent', '1_PRIMARY'],\n","    ['Plan Id', 'PELB FB',\n","    ['Technique']\n","    ]```\n","\n","becomes:\n","```{\n","    'Course': 'C1',\n","    'Intent': '1_PRIMARY',\n","    'Plan Id': 'PELB FB'\n","    }```\n","\n","*Note: * `['Technique']` is dropped because it is a single-item list."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["trim_dict = partial(tr.to_dict, default_value=None)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def make_section_dict(parsed_text: List[Tuple[str]], context: Dict[str, Any]):\n","    section_data = tr.to_dict(parsed_text, default_value=None)\n","    section_name = context['Current Section']\n","    section_dict = {section_name: section_data}\n","    return section_dict"]},{"cell_type":"markdown","metadata":{},"source":["### Identify strings containing \"Warning\" text.\n","- a regular expression is used to identify the \"Warning\" text:\n","    - `'(?P<Num>[0-9]+)[. ]+'` Looks for one or more digits followed by a \".\" \n","    and/or spaces.  This is assigned as the \"Num\" group.\n","    - `'WARNING[: ]*'`  The word \"WARNING\", followed by optional \":\" \n","    and/or spaces \n","    - `'(?P<Warning>.*$)'`  The warning text is then the remainder of the \n","    string. This is assigned as the \"Warning\" group.\n","\n","If a match is found returns a *two*-item list: \n","`[\"Num\" group, \"Warning\" group]`.<br>\n","If a match is **not** found returns a *one*-item list: `[Original Text]`.\n","\n","For example:\n","> `'1. WARNING: Plan target volume is different than plan primary reference\n"," point volume.'`\n","\n"," Returns:\n","> `['1', 'Plan target volume is different than plan primary reference\n"," point volume.']`\n","\n","And\n","> `'PhotonAlg; AAA_15606_Golden_Beam'`\n","\n","Returns:\n","> `['PhotonAlg; AAA_15606_Golden_Beam']`\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def get_warning(text_line):\n","    warning_pattern = re.compile(\n","        '(?P<Num>[0-9]+)'   # Warning index as Num group\n","        '[. ]+'             # delimiter and space\n","        'WARNING'           # warning text\n","        '[: ]*'             # delimiter and space\n","        '(?P<Warning>.*$)'  # remaining text in line as Warning group\n","        )\n","    warning_match = warning_pattern.search(text_line)\n","    if warning_match:\n","        indexer = warning_match.group('Num')\n","        warning_text = warning_match.group('Warning')\n","        warning_output = [f'Warning{indexer}', warning_text]\n","    else:\n","        warning_output = [text_line]\n","    return warning_output"]},{"cell_type":"markdown","metadata":{},"source":["### Parse the User origin text line.\n","- The text is expected to have the form of three numbers with 'cm' units \n","contained in brackets.  For example:\n","> `(-1.26cm, 9.95cm, -4.70cm)`\n","- A regular expression is used to parse the \"User Origin\" text:\n","    - `'[^(]+.'` Everything up to and including the first bracket.\n","    - `'(?P<X>[0-9.-]+)'`  The X number group. \n","    - `'[ cm,]*'`  'cm' units, spaces and comma \n","    - `'(?P<Y>[0-9.-]+)'`  The Y number group.\n","    - `'[ cm,]*'`  'cm' units, spaces and comma \n","    - `'(?P<Z>[0-9.-]+)'`  The Z number group.\n","    - `'[ cm,)]*'`  'cm' units, spaces, comma  and end bracket\n","\n","If a match is found, returns four output items, each containing a \n","two-item list:\n","> `[`<br>\n","    `['User Origin', `*The original text line after the '='*`],`<br>\n","    `['Origin X', `*The matched 'X' group*`],`<br>\n","    `['Origin Y', `*The matched 'Y' group*`],`<br>\n","    `['Origin Z', `*The matched 'Z' group*`]`<br>\n","    `]`\n","\n","If a match is **not** found, returns a list containing the original text string \n","split on \";\"s.\n","\n","For example:\n","> `'User Origin;User origin DICOM offset = (-1.26cm, 9.95cm, -4.70cm)'`\n","\n"," Returns:\n","> `[`<br>\n","    `['User Origin', '(-1.26cm, 9.95cm, -4.70cm)'],`<br>\n","    `['Origin X', -1.26],`<br>\n","    `['Origin Y', 9.95],`<br>\n","    `['Origin Z', -4.70]`<br>\n","    `]`\n","\n","And\n","> `'PhotonAlg; AAA_15606_Golden_Beam'`\n","\n","Returns:\n","> `['PhotonAlg', 'AAA_15606_Golden_Beam']`\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_origin(text_line):\n","    origin_pattern = re.compile(\n","        '[^(]+.'           # Everything up to and including the first bracket\n","        '(?P<X>[0-9.-]+)'  # X number group\n","        '[ cm,]*'          # Unit, space and comma\n","        '(?P<Y>[0-9.-]+)'  # Y number group\n","        '[ cm,]*'          # Unit, space and comma\n","        '(?P<Z>[0-9.-]+)'  # Z number group\n","        '[ cm,)]*'         # Unit, space, comma and end bracket\n","        )\n","    origin_match = origin_pattern.search(text_line)\n","    if origin_match:\n","        origin_str = text_line.split('=')[1].strip()\n","        origin = [\n","            ['User Origin', origin_str],\n","            ['Origin X', origin_match.group('X')],\n","            ['Origin Y', origin_match.group('Y')],\n","            ['Origin Z', origin_match.group('Z')]\n","            ]\n","    else:\n","        origin = [text_line.split(';')]\n","    for row in origin:\n","        yield row"]},{"cell_type":"markdown","metadata":{},"source":["### Parse the gantry text line.\n","- The text is expected to have the form of three numbers with 'cm' units \n","contained in brackets. <br>\n","For example:\n","    - `Gantry;0.0 deg to - deg` \n","    <br> or <br>\n","    - `Gantry;181.0 degCW to 179.0 deg`\n","\n","- A regular expression is used to parse the gantry text:\n","    - `'(?P<GantryStart>[0-9.-]+)'` gantry start angle, assigned to \n","    \"GantryStart\".\n","    - `'[ degtoCCW]*'`  Unit, space direction and \"to\" (not captured). \n","    - `'(?P<GantryEnd>[0-9.-]+)'`  Gantry end angle, assigned to \n","    \"GantryEnd\".\n","    - `'[ deg]*'`  'deg' units and space  (not captured).\n","    - `'[ cm,]*'`  'cm' units, spaces and comma \n","\n","If a match is found, returns either one or three output items, each containing a \n","two-item list.<br>\n","> If *GantryEnd* contains `'-'`  (meaning gantry doesn't move), returns:<br>\n","    >> `[['Gantry', `*GantryStart*`]]`\n","\n","> Otherwise (moving gantry), returns:<br>\n","    >> `[`<br>\n","    >> `['Gantry', `*GantryStart*`],`<br>\n","    >> `['GantryStart', `*GantryStart*`],`<br>\n","    >> `['GantryEnd', `*GantryEnd*`],`<br>\n","    >> `]`\n","                \n","If a match is **not** found returns a list containing the original text string \n","split on \";\"s.\n","\n","For example:\n","> `Gantry;0.0 deg to - deg`\n","\n"," Returns:\n","> `[['Gantry', '0.0']]`\n","\n","Or\n","> `Gantry;181.0 degCW to 179.0 deg`\n","\n"," Returns:\n","> `[`<br>\n","> `['Gantry', '181.0'],`<br>\n","> `['GantryStart', '181.0'],`<br>\n","> `['GantryEnd', '179.0'],`<br>\n","> `]`\n","\n","And\n","> `'PhotonAlg; AAA_15606_Golden_Beam'`\n","\n","Returns:\n","> `['PhotonAlg', 'AAA_15606_Golden_Beam']`"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def get_gantry(text_line):\n","    gantry_pattern = re.compile(\n","        '(?P<GantryStart>[0-9.-]+)'  # gantry start group\n","        '[ degtoCCW]*'               # Unit, space direction and \"to\"\n","        '(?P<GantryEnd>[0-9.-]+)'    # gantry start group\n","        '[ deg]*'                    # Unit and space\n","        )\n","    gantry_match = gantry_pattern.search(text_line)\n","    if gantry_match:\n","        gantry_start = gantry_match.group('GantryStart')\n","        gantry_end = gantry_match.group('GantryEnd')\n","        if '-' in gantry_end:\n","            gantry = [\n","                ['Gantry', gantry_start]\n","                ]\n","        else:\n","            gantry = [\n","                ['Gantry', gantry_start],\n","                ['GantryStart', gantry_start],\n","                ['GantryEnd', gantry_end],\n","                ]\n","    else:\n","        gantry = [text_line.split(';')]\n","    for row in gantry:\n","        yield row"]},{"cell_type":"markdown","metadata":{},"source":["### Relabel *\"No Field Normalization\"*\n","Replace lines with text: \n","> *'NO_ISQLAW_NORM'*\n","\n","with processed output:\n","> `norm_line = ['Norm Method', 'No Field Normalization']`"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def clean_norm(text_line):\n","    if 'NO_ISQLAW_NORM' in text_line:\n","        norm_line = ['Norm Method', 'No Field Normalization']\n","    return norm_line"]},{"cell_type":"markdown","metadata":{},"source":["### Drop units from numeric data\n","\n","- A regular expression is used to extract the value portion of a string tha contains a number with units.\n","-   - `'^\\s*'` beginning of string and leading whitespace.\n","    - `'(?P<value>[-+]?\\d+[.]?\\d*)'`  The value group containing optional initial\n","        sign and decimal place with numbers before and/or after.\n","    - `'[ cm,]*'`  'cm' units, spaces and comma \n","    - `'(?P<Y>[0-9.-]+)'`  The Y number group.\n","    - `'\\s*'`  Optional whitespace between value and units.\n","    - `'(?P<unit>[^\\s]*)'`  The units group, which does not contain spaces.\n","    - `'\\s*$'`  Trailing whitespace and end of string\n","\n","\n","\n","If a match is found, returns the value group as a float otherwise return the original text.\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def drop_units(text: str) -> Union[float, str]:\n","    number_value_pattern = re.compile(\n","        # beginning of string and leading whitespace\n","        r'^\\s*'                \n","        # value group contains optional initial sign and decimal place with \n","        # number before and/or after.\n","        r'(?P<value>[-+]?\\d+[.]?\\d*)'    \n","        r'\\s*'              # Optional whitespace between value and units\n","        r'(?P<unit>[^\\s]*)' # units do not contain spaces\n","        r'\\s*'              # drop trailing whitespace\n","        r'$'                # end of string\n","        )\n","    find_num = number_value_pattern.search(text)\n","    if find_num:\n","        value, unit = find_num.groups()\n","        return float(value)\n","    return text\n","\n","\n","def numeric_values(text_row: Tuple[str]) -> Tuple[str, float]:\n","    try:\n","        label, text_value = text_row\n","    except ValueError:\n","        return text_row\n","    numeric_value = drop_units(text_value)\n","    return (label, numeric_value)\n","\n","\n","def numeric_values_list(text_list: List[str]) -> List[Union[str, float]]:\n","    converted_list = [drop_units(text_item) for text_item in text_list]\n","    return converted_list"]},{"cell_type":"markdown","metadata":{},"source":["## Define Plan Printout Sections"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["plan_section = sec.Section(\n","    start_section=None,\n","    end_section='PRESCRIPTION',\n","    processor=[tr.clean_ascii_text, dict_parse, tr.trim_items],\n","    aggregate=make_section_dict,\n","    section_name='Plan')\n","\n","prescription_section = sec.Section(\n","    start_section='PRESCRIPTION',\n","    end_section='IMAGE',\n","    processor=[tr.clean_ascii_text, dict_parse, tr.trim_items,\n","               numeric_values],\n","    aggregate=make_section_dict,\n","    section_name='Prescription')\n","\n","parse_origin = sec.Rule('User Origin', pass_method=get_origin)\n","image_parse = sec.RuleSet([parse_origin], default=dict_parse)\n","image_section = sec.Section(\n","    start_section='IMAGE',\n","    end_section='CALCULATIONS',\n","    processor=[tr.clean_ascii_text, image_parse, tr.trim_items,\n","               numeric_values],\n","    aggregate=make_section_dict,\n","    section_name='Image')\n","\n","parse_warning = sec.Rule('WARNING:', pass_method=get_warning)\n","calculation_parse = sec.RuleSet([parse_warning], default=dict_parse)\n","calculation_section = sec.Section(\n","    start_section='CALCULATIONS',\n","    end_section='WARNINGS',\n","    processor=[tr.clean_ascii_text, image_parse, tr.trim_items,\n","               numeric_values],\n","    aggregate=make_section_dict,\n","    section_name='Calculations')\n","\n","warning_section = sec.Section(\n","    start_section='WARNINGS',\n","    end_section='FIELDS DATA',\n","    processor=[tr.clean_ascii_text, calculation_parse, tr.trim_items,\n","               numeric_values],\n","    aggregate=make_section_dict,\n","    section_name='Warnings')\n","\n","parse_gantry = sec.Rule('G', pass_method=get_gantry, fail_method='Original')\n","no_norm = sec.Rule('NO_ISQLAW_NORM', pass_method=clean_norm)\n","field_parse = sec.RuleSet([parse_gantry, no_norm], default=dict_parse)\n","field_section = sec.Section(\n","    start_section=None,\n","    end_section=['END FIELD'],\n","    processor=[tr.clean_ascii_text, field_parse, tr.trim_items,\n","               numeric_values],\n","    aggregate=trim_dict,\n","    section_name='Field')\n","\n","all_fields_section = sec.Section(\n","    start_section='FIELDS DATA',\n","    end_section='POINTS LOCATIONS',\n","    processor=[tr.clean_ascii_text, field_section],\n","    aggregate=tr.to_dataframe,\n","    section_name='Fields')\n","\n","all_initial_sections = sec.Section(\n","    processor=[plan_section, prescription_section, image_section,\n","                 calculation_section, warning_section],\n","    section_name='PlanCheck')\n","\n","point_location_section = sec.Section(\n","    start_section=sec.SectionBreak('POINTS LOCATIONS', break_offset='after'),\n","    end_section=sec.SectionBreak('FIELD POINTS', break_offset='before'),\n","    processor=[tr.clean_ascii_text, dict_parse, tr.trim_items,\n","               numeric_values],\n","    aggregate=tr.to_dataframe,\n","    section_name='Point Locations')\n","\n","point_dose_section = sec.Section(\n","    start_section=sec.SectionBreak('FIELD POINTS', break_offset='after'),\n","    end_section=sec.SectionBreak('PlanCheck', break_offset='before'),\n","    processor=[tr.clean_ascii_text, dict_parse, tr.trim_items,\n","               numeric_values_list],\n","    aggregate=tr.to_dataframe,\n","    section_name='Point Dose')\n","\n","full_printout_section = sec.Section(\n","    start_section=None,\n","    end_section=sec.SectionBreak('PlanCheck', break_offset='before'),\n","    processor=[all_initial_sections, all_fields_section, \n","                 point_location_section, point_dose_section],\n","    section_name='Full Printout')"]},{"cell_type":"markdown","metadata":{},"source":["## Load the file as a list of strings."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["#base_path = Path(r'\\\\dkphysicspv1\\e$\\Gregs_Work\\Temp\\Plan Checking Temp')\n","#test_file = base_path / PlanCheckText 2022-02-17 12-28-03.txt'\n","\n","base_path = Path.cwd() / 'examples'\n","test_file = base_path / 'PlanCheckText Test.txt'\n","\n","test_text = test_file.read_text().splitlines()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["{'Plan': {'PlanCheck': 'Test 1234567 TestPlan',\n","  'Patient Name': 'Patient, Test',\n","  'Patient Id': '01234567',\n","  'Date Of Birth': 'Jan 1, 1990',\n","  'Sex': 'Yes',\n","  'Primary Oncologist': 'Dr Bob',\n","  'Plan Status': 'Planning Approved',\n","  'Plan Approved On': 'January 1, 2022 12:00:00 AM',\n","  'Approved By': 'Carey Shenfield MD',\n","  'Checking Date': 'January 2, 2022 12:00:00 PM',\n","  'Checked By': 'Bo Derric',\n","  'Is Plan Modified?': '-',\n","  'Valid': 'All MU/Gy values are valid',\n","  'Course': 'C1',\n","  'Intent': '1_PRIMARY',\n","  'Plan Id': 'PELB FB',\n","  'Plan Name': 'PELB FB',\n","  'Plan Intent': 'Curative',\n","  'Technique': ''}}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["plan_section.read(test_text)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["{'Prescription': {'Patient Identifiers': '',\n","  'Patient Name': 'Patient, Test',\n","  'PatientId': 1234567.0,\n","  'Date Of Birth': 'Jan 1, 1990',\n","  'Sex': 'Yes',\n","  'Primary Oncologist': 'Dr Bob',\n","  'Prescription': '',\n","  'Intent': 1.0,\n","  'Prescribed Dose': 4500.0,\n","  'Fractions': 25.0,\n","  'Start Delay': '-',\n","  'Fractions Per Week': '-',\n","  'Fractions Per Day': '-',\n","  'Dose Per Fraction': 180.0,\n","  'Normalization': 101.1,\n","  'Normalization Method': '100.00% covers 97.00% of Target Volume',\n","  'Warning': '',\n","  'Reference Point': '',\n","  'Primary Ref Point': 'PELB',\n","  'Primary Ref Point Dose': 4500.0,\n","  'Primary Ref Point Relative Dose': 100.0,\n","  'Primary Ref Point Dose Per Fraction': 180.0,\n","  'TargetVolume': 'PTV 45'}}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["prescription_section.read(test_text)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["{'Image': {'ImageId': 'PELB FB',\n","  'Image Modality': 'CT',\n","  'ImageSeriesId': 'PELB FB 35687',\n","  'ImageSeriesComment': 'PROSTATE',\n","  'Contrast Exists': '-',\n","  'Imaging Device': 'Philips Big Bore',\n","  'User Origin': '(-1.26cm, 9.95cm, -4.70cm)',\n","  'Origin X': -1.26,\n","  'Origin Y': 9.95,\n","  'Origin Z': -4.7,\n","  'Imaging Orientation': 'Head First-Supine',\n","  'Treatment Orientation': 'Head First-Supine',\n","  'Coordinate System': 'Standard',\n","  'StructureSetId': 'PELB FB'}}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["image_section.read(test_text)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["{'Calculations': {'PhotonAlg': 'AAA_15606_Golden_Beam',\n","  'CalculationGridSizeInCM': 0.25,\n","  'CalculationGridSizeInCMForSRSAndHyperArc': 0.125,\n","  'FieldNormalizationType': '100% to isocenter',\n","  'HeterogeneityCorrection': 'ON',\n","  'Optimizer': 'PO_13623',\n","  'AirCavityCorrection': 'On',\n","  'InhomogeneityCorrection': 'On',\n","  'SmoothX': 40.0,\n","  'SmoothY': 30.0,\n","  'Calculation Medium': 'Inhomogeneity corrected',\n","  'Calculation Method': ''}}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["calculation_section.read(test_text)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["{'Warnings': {'Warning1': 'Plan target volume is different than plan primary reference point volume.'}}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["warning_section.read(test_text)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["{'PlanCheck': 'Test 1234567 TestPlan',\n"," 'Patient Name': 'Patient, Test',\n"," 'Patient Id': 1234567.0,\n"," 'Date Of Birth': 'Jan 1, 1990',\n"," 'Sex': 'Yes',\n"," 'Primary Oncologist': 'Dr Bob',\n"," 'Plan Status': 'Planning Approved',\n"," 'Plan Approved On': 'January 1, 2022 12:00:00 AM',\n"," 'Approved By': 'Carey Shenfield MD',\n"," 'Checking Date': 'January 2, 2022 12:00:00 PM',\n"," 'Checked By': 'Bo Derric',\n"," 'Is Plan Modified?': '-',\n"," 'Valid': 'All MU/Gy values are valid',\n"," 'Course': 'C1',\n"," 'Intent': 1.0,\n"," 'Plan Id': 'PELB FB',\n"," 'Plan Name': 'PELB FB',\n"," 'Plan Intent': 'Curative',\n"," 'Technique': 'STATIC',\n"," 'Patient Identifiers': '',\n"," 'PatientId': 1234567.0,\n"," 'Prescription': '',\n"," 'Gantry': 0.0,\n"," 'GantryStart': 1.0,\n"," 'GantryEnd': '.',\n"," 'Fractions': 25.0,\n"," 'Start Delay': '-',\n"," 'Fractions Per Week': '-',\n"," 'Fractions Per Day': '-',\n"," 'Normalization': 101.1,\n"," 'Normalization Method': '100.00% covers 97.00% of Target Volume',\n"," 'Warning': '',\n"," 'Reference Point': '',\n"," 'Primary Ref Point': 'PELB',\n"," 'Primary Ref Point Relative Dose': 100.0,\n"," 'TargetVolume': 'PTV 45',\n"," 'ImageId': 'PELB FB',\n"," 'Image Modality': 'CT',\n"," 'ImageSeriesId': 'PELB FB 35687',\n"," 'ImageSeriesComment': 'PROSTATE',\n"," 'Contrast Exists': '-',\n"," 'Imaging Device': 'Philips Big Bore',\n"," 'User Origin': 'User origin DICOM offset = (-1.26cm, 9.95cm, -4.70cm)',\n"," 'Imaging Orientation': 'Head First-Supine',\n"," 'Treatment Orientation': 'Head First-Supine',\n"," 'Coordinate System': 'Standard',\n"," 'StructureSetId': 'PELB FB',\n"," 'FieldNormalizationType': '100% to isocenter',\n"," 'HeterogeneityCorrection': 'ON',\n"," 'Optimizer': 'PO_13623',\n"," 'AirCavityCorrection': 'On',\n"," 'InhomogeneityCorrection': 'On',\n"," 'SmoothX': 40.0,\n"," 'SmoothY': 30.0,\n"," 'Calculation Medium': 'Inhomogeneity corrected',\n"," 'Calculation Method': '',\n"," 'FieldId': 'CBCT',\n"," 'FieldName': 'CBCT',\n"," 'Linac': 'TR1',\n"," 'Collimator': 0.0,\n"," 'Couch': 0.0,\n"," 'X': 20.0,\n"," 'Y': 20.0,\n"," 'Iso X': 1.0,\n"," 'Iso Y': -0.5,\n"," 'Iso Z': 2.0,\n"," 'SAD': 100.0,\n"," 'Start SSD': 86.4,\n"," 'Stop SSD': '-',\n"," 'Average SSD': '-',\n"," 'Actual SSD': 86.4,\n"," 'SFED': '-',\n"," 'Virtual SAD X': '-',\n"," 'Virtual SAD Y': '-'}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["field_section.read(test_text)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["[{'Plan': {'PlanCheck': 'Test 1234567 TestPlan',\n","   'Patient Name': 'Patient, Test',\n","   'Patient Id': '01234567',\n","   'Date Of Birth': 'Jan 1, 1990',\n","   'Sex': 'Yes',\n","   'Primary Oncologist': 'Dr Bob',\n","   'Plan Status': 'Planning Approved',\n","   'Plan Approved On': 'January 1, 2022 12:00:00 AM',\n","   'Approved By': 'Carey Shenfield MD',\n","   'Checking Date': 'January 2, 2022 12:00:00 PM',\n","   'Checked By': 'Bo Derric',\n","   'Is Plan Modified?': '-',\n","   'Valid': 'All MU/Gy values are valid',\n","   'Course': 'C1',\n","   'Intent': '1_PRIMARY',\n","   'Plan Id': 'PELB FB',\n","   'Plan Name': 'PELB FB',\n","   'Plan Intent': 'Curative',\n","   'Technique': ''}},\n"," {'Prescription': {'Patient Identifiers': '',\n","   'Patient Name': 'Patient, Test',\n","   'PatientId': 1234567.0,\n","   'Date Of Birth': 'Jan 1, 1990',\n","   'Sex': 'Yes',\n","   'Primary Oncologist': 'Dr Bob',\n","   'Prescription': '',\n","   'Intent': 1.0,\n","   'Prescribed Dose': 4500.0,\n","   'Fractions': 25.0,\n","   'Start Delay': '-',\n","   'Fractions Per Week': '-',\n","   'Fractions Per Day': '-',\n","   'Dose Per Fraction': 180.0,\n","   'Normalization': 101.1,\n","   'Normalization Method': '100.00% covers 97.00% of Target Volume',\n","   'Warning': '',\n","   'Reference Point': '',\n","   'Primary Ref Point': 'PELB',\n","   'Primary Ref Point Dose': 4500.0,\n","   'Primary Ref Point Relative Dose': 100.0,\n","   'Primary Ref Point Dose Per Fraction': 180.0,\n","   'TargetVolume': 'PTV 45'}},\n"," {'Image': {'ImageId': 'PELB FB',\n","   'Image Modality': 'CT',\n","   'ImageSeriesId': 'PELB FB 35687',\n","   'ImageSeriesComment': 'PROSTATE',\n","   'Contrast Exists': '-',\n","   'Imaging Device': 'Philips Big Bore',\n","   'User Origin': '(-1.26cm, 9.95cm, -4.70cm)',\n","   'Origin X': -1.26,\n","   'Origin Y': 9.95,\n","   'Origin Z': -4.7,\n","   'Imaging Orientation': 'Head First-Supine',\n","   'Treatment Orientation': 'Head First-Supine',\n","   'Coordinate System': 'Standard',\n","   'StructureSetId': 'PELB FB'}},\n"," {'Calculations': {'PhotonAlg': 'AAA_15606_Golden_Beam',\n","   'CalculationGridSizeInCM': 0.25,\n","   'CalculationGridSizeInCMForSRSAndHyperArc': 0.125,\n","   'FieldNormalizationType': '100% to isocenter',\n","   'HeterogeneityCorrection': 'ON',\n","   'Optimizer': 'PO_13623',\n","   'AirCavityCorrection': 'On',\n","   'InhomogeneityCorrection': 'On',\n","   'SmoothX': 40.0,\n","   'SmoothY': 30.0,\n","   'Calculation Medium': 'Inhomogeneity corrected',\n","   'Calculation Method': ''}},\n"," {'Warnings': {'Warning1': 'Plan target volume is different than plan primary reference point volume.'}}]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["all_initial_sections.read(test_text)[0]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>FieldId</th>\n","      <td>KV AP PELB</td>\n","      <td>KV RL PELB</td>\n","      <td>KV LL PELB</td>\n","      <td>CW</td>\n","      <td>CCW</td>\n","    </tr>\n","    <tr>\n","      <th>FieldName</th>\n","      <td>KV AP PELB</td>\n","      <td></td>\n","      <td>KV LL PELB</td>\n","      <td>CW</td>\n","      <td>CCW</td>\n","    </tr>\n","    <tr>\n","      <th>Technique</th>\n","      <td>STATIC</td>\n","      <td>STATIC</td>\n","      <td>STATIC</td>\n","      <td>ARC</td>\n","      <td>ARC</td>\n","    </tr>\n","    <tr>\n","      <th>Linac</th>\n","      <td>TR1</td>\n","      <td>TR1</td>\n","      <td>TR1</td>\n","      <td>TR1</td>\n","      <td>TR1</td>\n","    </tr>\n","    <tr>\n","      <th>Gantry</th>\n","      <td>0.0</td>\n","      <td>270.0</td>\n","      <td>90.0</td>\n","      <td>327.3</td>\n","      <td>327.3</td>\n","    </tr>\n","    <tr>\n","      <th>Collimator</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0</td>\n","      <td>330.0</td>\n","    </tr>\n","    <tr>\n","      <th>Couch</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>X</th>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Y</th>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Iso X</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>Iso Y</th>\n","      <td>-0.5</td>\n","      <td>-0.5</td>\n","      <td>-0.5</td>\n","      <td>-0.5</td>\n","      <td>-0.5</td>\n","    </tr>\n","    <tr>\n","      <th>Iso Z</th>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>SAD</th>\n","      <td>100.0</td>\n","      <td>100.0</td>\n","      <td>100.0</td>\n","      <td>100.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>Start SSD</th>\n","      <td>86.4</td>\n","      <td>77.3</td>\n","      <td>77.0</td>\n","      <td>85.5</td>\n","      <td>85.5</td>\n","    </tr>\n","    <tr>\n","      <th>Stop SSD</th>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>85.5</td>\n","      <td>85.5</td>\n","    </tr>\n","    <tr>\n","      <th>Average SSD</th>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>81.5</td>\n","      <td>81.5</td>\n","    </tr>\n","    <tr>\n","      <th>Actual SSD</th>\n","      <td>86.4</td>\n","      <td>77.3</td>\n","      <td>77.0</td>\n","      <td>85.5</td>\n","      <td>85.5</td>\n","    </tr>\n","    <tr>\n","      <th>SFED</th>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>Virtual SAD X</th>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>Virtual SAD Y</th>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        0           1           2      3      4\n","FieldId        KV AP PELB  KV RL PELB  KV LL PELB     CW    CCW\n","FieldName      KV AP PELB              KV LL PELB     CW    CCW\n","Technique          STATIC      STATIC      STATIC    ARC    ARC\n","Linac                 TR1         TR1         TR1    TR1    TR1\n","Gantry                0.0       270.0        90.0  327.3  327.3\n","Collimator            0.0         0.0         0.0   30.0  330.0\n","Couch                 0.0         0.0         0.0    0.0    0.0\n","X                    20.0        20.0        20.0    NaN    NaN\n","Y                    20.0        20.0        20.0    NaN    NaN\n","Iso X                 1.0         1.0         1.0    1.0    1.0\n","Iso Y                -0.5        -0.5        -0.5   -0.5   -0.5\n","Iso Z                 2.0         2.0         2.0    2.0    2.0\n","SAD                 100.0       100.0       100.0  100.0  100.0\n","Start SSD            86.4        77.3        77.0   85.5   85.5\n","Stop SSD                -           -           -   85.5   85.5\n","Average SSD             -           -           -   81.5   81.5\n","Actual SSD           86.4        77.3        77.0   85.5   85.5\n","SFED                    -           -           -      -      -\n","Virtual SAD X           -           -           -      -      -\n","Virtual SAD Y           -           -           -      -      -"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["all_fields_section.read(test_text).T"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Point</th>\n","      <th>X</th>\n","      <th>Y</th>\n","      <th>Z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PELB</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Point  X  Y  Z\n","0  PELB  -  -  -"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["point_location_section.read(test_text)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Field</th>\n","      <th>Point</th>\n","      <th>Dose</th>\n","      <th>SSD</th>\n","      <th>Depth</th>\n","      <th>Effective Depth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Plan</td>\n","      <td>PELB</td>\n","      <td>4500.0</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CW</td>\n","      <td>PELB</td>\n","      <td>89.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CCW</td>\n","      <td>PELB</td>\n","      <td>91.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Field Point    Dose SSD Depth Effective Depth\n","0  Plan  PELB  4500.0                          \n","1    CW  PELB    89.0   -     -               -\n","2   CCW  PELB    91.0   -     -               -"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["point_dose_section.read(test_text)"]},{"cell_type":"markdown","metadata":{},"source":["## Create Dictionary of all Plan Check PrintOut Sections\n","### Combine initial sections into dictionary of dictionaries"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["printout_dict = dict()\n","for pt_sec in all_initial_sections.read(test_text)[0]:\n","    printout_dict.update(pt_sec)"]},{"cell_type":"markdown","metadata":{},"source":["### Add Field data DataFrame to dictionary"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["printout_dict['Fields'] = all_fields_section.read(test_text).T"]},{"cell_type":"markdown","metadata":{},"source":["### Add Point Location data DataFrame to dictionary"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["printout_dict['Point Locations'] = point_location_section.read(test_text)"]},{"cell_type":"markdown","metadata":{},"source":["### Merge all location data into a new DataFrame and add it to the dictionary"]},{"cell_type":"markdown","metadata":{},"source":["#### Get the origin DICOM coordinates\n","- Get the \"Origin X\", \"Origin Y\", \"Origin Z items from the \"Image\" section results.\n","- Return a dictionary with \"X\", \"Y\", \"Z\" keys."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def get_user_origin(printout_dict):\n","    image_dict = printout_dict['Image']\n","    user_origin = {\n","        'User Origin': {'X': image_dict['Origin X'],\n","                        'Y': image_dict['Origin Y'],\n","                        'Z': image_dict['Origin Z']\n","                        }\n","        }\n","    return user_origin"]},{"cell_type":"markdown","metadata":{},"source":["#### Extract Isocentre location from the first field\n","**Note:** This assumes that all fields have the same isocentre."]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def get_isocenter(printout_dict):\n","    field_data = printout_dict['Fields']\n","    fld1 = field_data.iloc[:,0]\n","    isoc = fld1.loc[['Iso X', 'Iso Y', 'Iso Z']]\n","    field_isocentre = {'Isocentre': {\n","        'X': isoc.at['Iso X'],\n","        'Y': isoc.at['Iso Y'],\n","        'Z': isoc.at['Iso Z']}\n","        }\n","    return field_isocentre"]},{"cell_type":"markdown","metadata":{},"source":["#### Format the Reference Point Locations\n","- Add an index with Point#[n]\n","  > Where in is an integer starting with 1\n","- Returns a dictionary of dictionaries, \n","  - where the outer dictionary has the keys:\n","    > \"Point#1\", \"Point#2\", ... \"Point#n\"\n","  \n","  - and the inner dictionary has the keys \n","    > \"X\", \"Y\", \"Z\" "]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def get_point_locations(printout_dict):\n","    point_locations = printout_dict['Point Locations']\n","    pt_idx = [''.join(['Point#', str(idx+1)])\n","                for idx in range(len(point_locations))]\n","    pt_idx_series = pd.Series(pt_idx, name='Point Index')\n","    pt_locs = pd.concat([point_locations,pt_idx_series],axis='columns')\n","    pt_locs.set_index('Point Index', inplace=True)\n","    pt_locations = pt_locs.T.to_dict()\n","    return pt_locations"]},{"cell_type":"markdown","metadata":{},"source":["#### Combine the User Origin, Isocentre and Reference Point Locations into one DataFrame"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def make_locations_table(printout_dict):\n","\n","    locations = get_user_origin(printout_dict)\n","    locations.update(get_point_locations(printout_dict))\n","    locations.update(get_isocenter(printout_dict))\n","\n","    locations_table = pd.DataFrame(locations).T\n","    return locations_table"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["printout_dict['Locations'] = make_locations_table(printout_dict)"]},{"cell_type":"markdown","metadata":{},"source":["# DONE TO HERE"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["dict_keys(['Plan', 'Prescription', 'Image', 'Calculations', 'Warnings', 'Fields', 'Point Locations', 'Locations'])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["printout_dict.keys()"]},{"cell_type":"markdown","metadata":{},"source":["#### Debug\n","`full_printout_section` is not working\n","- break it down into parts to see where it breaks"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["[None]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["full_printout_section.read(test_text)"]},{"cell_type":"markdown","metadata":{},"source":["## save individual section results to a spreadsheet"]},{"cell_type":"markdown","metadata":{},"source":["### select Output File"]},{"cell_type":"raw","metadata":{},"source":["# %% select Output File\n","\n","base_path\n","output_file_path = base_path / 'PlanCheckExample1.xlsx'\n"]},{"cell_type":"markdown","metadata":{},"source":["### Write individual sections to different sheets in the workbook"]},{"cell_type":"raw","metadata":{},"source":["workbook = xw.Book()\n","\n","for data_set_name, data in printout_dict.items():\n","    data_sheet = workbook.sheets.add(data_set_name)\n","    xw.view(data, data_sheet)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.12 ('sectionaryDev')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"890849be4bb9b5be1d044afe42e602ccc6ca20da23c054ee97c8186ec3939c45"}}},"nbformat":4,"nbformat_minor":2}
