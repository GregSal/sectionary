{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Propagation Bug"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Any, Dict, List, Tuple\n",
    "from types import GeneratorType\n",
    "from sections import SourceItem, TriggerEvent\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import text_reader as tp\n",
    "from buffered_iterator import BufferedIterator\n",
    "from sections import Rule, RuleSet, SectionBreak, Section, ProcessingMethods\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dvh_folder = Path.cwd() / r'./References/Text Files/DVH files'\n",
    "demo_dvh_1 = demo_dvh_folder / 'Breast CHWR Relative Dose Relative Volume 1 cGy Step Size.dvh'\n",
    "#demo_dvh_1.exists()\n",
    "#demo_dvh_folder.exists()\n",
    "multi_dvh = demo_dvh_folder / 'Replan1, Replan2, Replan3 Comparison DVH Absolute Dose Relative Volume 1 cGy Step Size.dvh'\n",
    "\n",
    "single_dvh = demo_dvh_folder / 'Single Structure.txt'\n",
    "\n",
    "diff_dvh = demo_dvh_folder / 'EARR Differential Relative Dose Absolute Volume 0.1 cGy Step Size.dvh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_split = partial(str.split, sep=':', maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh_info_section = Section(\n",
    "    name='Information',\n",
    "    start_section=None,\n",
    "    end_section=('Description', 'START', 'Before'),\n",
    "    processor=[info_split, \n",
    "               tp.trim_items, \n",
    "               tp.drop_blanks],\n",
    "    assemble=tp.to_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_split(line: str)->List[str]:\n",
    "    '''Spilt a text line into two parts on ':'.\n",
    "\n",
    "    Spilt a text line into two parts on the first occurrence of ':'.\n",
    "    Remove leading and trailing spaces from each part.\n",
    "    Force the returned list to have length of two even if the text does not \n",
    "    contain a ':'.\n",
    "\n",
    "    Args:\n",
    "        line (str): The test to spilt\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A length-2 list of strings\n",
    "    '''\n",
    "    parts = line.split(sep=':', maxsplit=1)\n",
    "    # Remove leading and trailing spaces from each part\n",
    "    clean_parts = [s.strip() for s in parts]\n",
    "    # If the line is blank return an empty list\n",
    "    if max(len(part) for part in clean_parts) == 0:\n",
    "        clean_parts = []\n",
    "    # Force clean_parts to be a length of 2\n",
    "    elif len(clean_parts) == 1:\n",
    "        clean_parts.append('')\n",
    "    return clean_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_approved_status_rule() -> Rule:\n",
    "    '''If Treatment Approved, Split \"Plan Status\" into 3 lines.\n",
    "\n",
    "    Accepts a supplied line like:\n",
    "    `Plan Status: Treatment Approved Thursday, January 02, 2020 12:55:56 by gsal`,\n",
    "    Extracts and user.\n",
    "    The approval date is the text between event.test_value and ' by'.\n",
    "    The user is the text after ' by'.\n",
    "    Yields three two-item lists.   \n",
    "    A supplied line like:\n",
    "    `Plan Status: Treatment Approved Thursday, January 02, 2020 12:55:56 by gsal`,\n",
    "    Gives:\n",
    "        [['Plan Status', 'Treatment Approved'],\n",
    "            ['Approved on', Thursday, January 02, 2020 12:55:56],\n",
    "            ['Approved by', gsal]\n",
    "    '''    \n",
    "    def approved_status_parse(line, event) -> tp.ProcessedList:\n",
    "        match_results = event.test_value.groupdict()\n",
    "        parsed_lines = [\n",
    "            ['Plan Status', match_results['approval']],\n",
    "            ['Approved on', match_results['date']],\n",
    "            ['Approved by', match_results['user']]\n",
    "            ]\n",
    "        for line in parsed_lines:\n",
    "            yield line\n",
    "\n",
    "    approval_pattern = (\n",
    "        r'.*'                  # Initial text\n",
    "        r'(?P<approval>'       # Beginning of approval capture group\n",
    "        r'Treatment Approved'  # Literal text 'Treatment Approved'\n",
    "        r')'                   # End of approval capture group        \n",
    "        r'\\s*'                 # Possible whitespace\n",
    "        r'(?P<date>.*?)'        # Text containing approval date\n",
    "        r'\\s*'                 # Possible whitespace\n",
    "        r'by'                  # Literal text 'by'\n",
    "        r'\\s*'                 # Possible whitespace\n",
    "        r'(?P<user>.*?)'       # Text containing user (non-greedy)\n",
    "        r'\\s*'                 # Possible trailing whitespace\n",
    "        r'$'                   # end of string\n",
    "        )\n",
    "    re_pattern = re.compile(approval_pattern)\n",
    "    approved_status_rule = Rule(name='approved_status_rule',\n",
    "                                sentinel=re_pattern, \n",
    "                                pass_method= approved_status_parse, \n",
    "                                fail_method='None')\n",
    "    return approved_status_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prescribed Dose Rule\n",
    "def make_prescribed_dose_rule() -> Rule:\n",
    "    '''Split Dose into dose vale and dose unit.\n",
    "    For a line containing:\n",
    "        Total dose [unit]: dose  OR\n",
    "        Prescribed dose [unit]: dose\n",
    "    The line:\n",
    "        Prescribed dose [cGy]: 5000.0\n",
    "    Results in:\n",
    "        ['Prescribed dose', '5000.0'],\n",
    "        ['Prescribed dose unit', 'cGy']\n",
    "    The line:\n",
    "        Total dose [cGy]: not defined\n",
    "    Results in:\n",
    "        ['Prescribed dose', ''],\n",
    "        ['Prescribed dose unit', '']\n",
    "    '''\n",
    "    def parse_prescribed_dose(line, event) -> tp.ProcessedList:\n",
    "        match_results = event.test_value.groupdict()\n",
    "        # Convert numerical dose value to float and \n",
    "        # 'not defined' dose value to np.nan\n",
    "        if match_results['dose'] == 'not defined':\n",
    "            match_results['dose'] = np.nan\n",
    "            match_results['unit'] = ''\n",
    "        else:\n",
    "            match_results['dose'] = float(match_results['dose'])\n",
    "\n",
    "        parsed_lines = [\n",
    "            ['Prescribed dose', match_results['dose']],\n",
    "            ['Prescribed dose unit', match_results['unit']]\n",
    "            ]\n",
    "        for line in parsed_lines:\n",
    "            yield line\n",
    "\n",
    "    prescribed_dose_pattern = (\n",
    "        r'^(Total|Prescribed)'  # Begins with 'Total' OR 'Prescribed'\n",
    "        r'\\s*dose\\s*'           # Literal text 'dose' surrounded by whitespace\n",
    "        r'\\['                   # Unit start delimiter '['\n",
    "        r'(?P<unit>[A-Za-z]+)'  # unit group: text surrounded by []\n",
    "        r'\\]'                   # Unit end delimiter ']'\n",
    "        r'\\s*:\\s*'              # Dose delimiter with possible whitespace\n",
    "        r'(?P<dose>[0-9.]+'     # dose group Number\n",
    "        r'|not defined)'        #\"not defined\" alternative\n",
    "        r'[\\s\\r\\n]*'            # drop trailing whitespace\n",
    "        r'$'                    # end of string\n",
    "        )\n",
    "    re_pattern = re.compile(prescribed_dose_pattern)\n",
    "    dose_rule = Rule(sentinel=re_pattern, name='prescribed_dose_rule',\n",
    "                        pass_method= parse_prescribed_dose, fail_method='None')\n",
    "    return dose_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prescribed Isodose Line Rule\n",
    "def make_prescribed_isodose_rule() -> Rule:\n",
    "    '''Identify Prescribed isodose text lines. and convert them into a\n",
    "    two-item list, with the isodose percentage converted to a number.\n",
    "\n",
    "    For a line containing '% for dose (%): 100.0':\n",
    "    Return:\n",
    "        ['Prescription Isodose', 100.0]\n",
    "    '''\n",
    "    def parse_isodose(line, event) -> tp.ProcessedList:\n",
    "        # Split the line at ':'\n",
    "        parts = line.split(':')\n",
    "        isodose_text = parts[1].strip()\n",
    "        if isodose_text == 'not defined':\n",
    "            isodose = np.nan\n",
    "        else:\n",
    "            isodose = float(isodose_text)\n",
    "        parsed_line = ['Prescription Isodose', isodose]\n",
    "        return parsed_line\n",
    "    prescribed_isodose_rule = Rule(r'% for dose (%)', location='IN',\n",
    "                                   pass_method=parse_isodose,\n",
    "                                   fail_method='None',\n",
    "                                   name='make_prescribed_isodose_rule')\n",
    "    return prescribed_isodose_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan Sum Rule\n",
    "def make_plan_sum_rule() -> Rule:\n",
    "    '''Identify lines starting with Plan sum and convert them into a two-item \n",
    "    list, with the first item being 'Plan' and the second item being the text \n",
    "    after the ':'.\n",
    "    '''\n",
    "    def parse_plan_sum(line, event) -> tp.ProcessedList:\n",
    "        # Split the line at ':'\n",
    "        parts = line.split(':', maxsplit=1)\n",
    "        plan_sum_id = parts[1].strip()\n",
    "        parsed_line = ['Plan', plan_sum_id]\n",
    "        return parsed_line\n",
    "    plan_sum_rule = Rule('Plan sum', location='START',\n",
    "                         pass_method=parse_plan_sum,\n",
    "                         fail_method='None',\n",
    "                         name='make_plan_sum_rule')\n",
    "    return plan_sum_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "plan_rule_set = RuleSet([make_approved_status_rule(),\n",
    "                         make_prescribed_dose_rule(),\n",
    "                         make_prescribed_isodose_rule(),\n",
    "                         make_plan_sum_rule()],\n",
    "                        default=plan_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_info_section = Section(\n",
    "    name='Plan',\n",
    "    start_section=(['Plan:', 'Plan sum:'], 'START', 'Before'),\n",
    "    end_section=('% for dose (%)', 'START', 'After'),\n",
    "    processor=[plan_rule_set],\n",
    "    assemble=tp.to_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_lookup(plan_sections: List[Dict[str, Any]], \n",
    "                context: Dict[str, Any])->Dict[str, Dict[str, Any]]:\n",
    "    '''Build a dictionary of plan information and add it to context.\n",
    "    '''\n",
    "    all_plans = pd.DataFrame(plan for plan in plan_sections if plan)\n",
    "    all_plans.set_index(['Course', 'Plan'], inplace=True)\n",
    "    # Build a dose conversion factor from % to cGy \n",
    "    # This factor may be used on structure dose values and DVH curves\n",
    "    conv = all_plans['Prescribed dose'] / all_plans['Prescription Isodose']\n",
    "    all_plans['DoseConversion'] = conv\n",
    "    # Store the dose information in the context so that later sections can \n",
    "    # access it.\n",
    "    context['PlanLookup'] = all_plans\n",
    "    return all_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plans = Section(\n",
    "    name='All Plans',\n",
    "    start_section=(['Plan:', 'Plan sum:'], 'START', 'Before'),\n",
    "    end_section=('Structure', 'START', 'Before'),\n",
    "    processor=[plan_info_section],\n",
    "    assemble=plan_lookup\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prescribed Dose Rule\n",
    "def parse_dose_data(raw_line: SourceItem, event: TriggerEvent) -> List[Any]:\n",
    "    '''Generate list items obtained from the regular expression match\n",
    "\n",
    "    Creates an iterator over one or two lists.  The first list is build from \n",
    "    the 'label' group of the match results and the 'value' group of the match \n",
    "    results.  If possible, the 'value' group is converted to a float number, if\n",
    "    not it is replaced with `np.nan`.\n",
    "\n",
    "    The second, optional, list is created if the match object contains a 'unit'\n",
    "    group.  If it does the first item in the second group will be the 'label' \n",
    "    group from the first list, with the string ' unit' appended.  The second \n",
    "    item will be the 'unit' group.\n",
    "\n",
    "    Args:\n",
    "        raw_line (SourceItem): The original text line. Not used, but required \n",
    "            in function signature in order to be a valid processing function.\n",
    "        event (TriggerEvent): This function is called by a Rule and event is \n",
    "            the information from the trigger that activated the rule.  Since\n",
    "            the trigger will be a regular expression, `event.test_value` will \n",
    "            be the match object resulting from applying the regular expression.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[List[Any]]: Iterator over one or two lists.  The first list \n",
    "            will be [label, value], the second will be [unit label, unit].\n",
    "    '''\n",
    "    match_results = event.test_value.groupdict()\n",
    "\n",
    "    # Generate first line with Label and Value\n",
    "    # Convert numerical value to float \n",
    "    try:\n",
    "        value = float(match_results['value'].strip())\n",
    "    except ValueError:\n",
    "        value = np.nan\n",
    "    match_results['value'] = value\n",
    "    value_label = match_results['label'].strip()\n",
    "    parsed_lines = [[value_label, value]]\n",
    "\n",
    "    # Generate optional second line with units\n",
    "    units = match_results.get('unit')\n",
    "    if units:\n",
    "        unit_label = value_label + ' unit'\n",
    "        parsed_lines.append([unit_label, units])\n",
    "\n",
    "    # Yield the lines as separate items\n",
    "    for line in parsed_lines:\n",
    "        yield line\n",
    "\n",
    "        \n",
    "def make_dose_data_rule() -> Rule:\n",
    "    '''return a Rule to Parse all Structure Dose lines.\n",
    "\n",
    "    Split dose parameter into label, value and unit if they exists, otherwise \n",
    "    split on the first ':' If the label is a dhv point like: D95.0% [cGy], keep \n",
    "    the units with the label.\n",
    "    \n",
    "    The line:\n",
    "        Volume [cm³]: 38.3\n",
    "    Results in:\n",
    "        ['Volume', 38.3],\n",
    "        ['Volume unit', 'cm³']\n",
    "        \n",
    "    The line:\n",
    "        Approval Status: Approved\n",
    "    Results in:\n",
    "        ['Approval Status', 'Approved']\n",
    "        \n",
    "    The line:\n",
    "        Paddick CI: \n",
    "    Results in:\n",
    "        ['Paddick CI', '']\n",
    "\n",
    "    The line:\n",
    "    \tD95.0% [cGy]: 10.3\n",
    "    Results in:\n",
    "\t    ['D95.0% [cGy]', 10.3]\n",
    "\n",
    "    Returns (Rule): A sectionary Rule that will parse all Structure Dose lines.\n",
    "    '''\n",
    "    dvh_point_pattern = re.compile(\n",
    "        r'^'                 # Start of string\n",
    "        r'(?P<label>'        # Beginning of label group\n",
    "        r'[DV][0-9.]+'       # D or V followed by number\n",
    "        r'(%|c?Gy|cm³)'      # Units for number\n",
    "        r'\\s*'               # Optional spaces\n",
    "        r'\\[(%|c?Gy|cm³)\\]'  # Value units surrounded by square brackets([])\n",
    "        r')'                 # End of label group\n",
    "        r'\\s*:\\s*'           # Value delimiter with possible whitespace\n",
    "        r'(?P<value>'        # Beginning of value group\n",
    "        r'[0-9.]*|N/A'       # value group Number 'N/A' or blank\n",
    "        r')'                 # End of value group\n",
    "        r'\\s*'               # Optional trailing whitespace\n",
    "        r'$'                 # end of string\n",
    "        )\n",
    "\n",
    "    structure_dose_pattern = re.compile(\n",
    "        r'^'              # Start of string\n",
    "        r'(?P<label>'     # Beginning of label group\n",
    "        r'[^[]+'          # Initial parameter label (all text up to '[')\n",
    "        r')'              # End of label group\n",
    "        r'\\['             # Unit start delimiter '['\n",
    "        r'(?P<unit>'      # Beginning of unit group\n",
    "        r'[^\\]]+'         # All text up to ']'\n",
    "        r')'              # End of unit group\n",
    "        r'\\]'             # Unit end delimiter ']'\n",
    "        r'\\s*:\\s*'        # Value delimiter with possible whitespace\n",
    "        r'(?P<value>'     # Beginning of value group\n",
    "        r'[0-9.]*|N/A'    # Number, N/A or nothing\n",
    "        r')'              # End of value group\n",
    "        r'\\s*'            # Optional trailing whitespace\n",
    "        r'$'              # end of string\n",
    "        )\n",
    "    # Rule passes if either one of the two regular expressions are found\n",
    "    dose_rule = Rule(name='make_dose_data_rule', \n",
    "                     sentinel=[dvh_point_pattern, structure_dose_pattern], \n",
    "                     pass_method=parse_dose_data, \n",
    "                     fail_method=plan_split)\n",
    "    return dose_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blank(line: str):\n",
    "    return len(line) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_info_section = Section(\n",
    "    name='Structure',\n",
    "    start_section=('Structure:', 'START', 'Before'),\n",
    "    end_section=(is_blank, None, 'Before'),\n",
    "    processor=[make_dose_data_rule()],\n",
    "    assemble=tp.to_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_parse(line: str) -> List[Tuple[str]]:\n",
    "    '''Split each column header into label and unit.\n",
    "\n",
    "    Accepts a string containing column labels and units.\n",
    "    Returns a list of two-item tuples. The first item is the label\n",
    "    and the second is the units.\n",
    "    A supplied line like:\n",
    "    `Dose [cGy]   Relative dose [%] Ratio of Total Structure Volume [%]`,\n",
    "    Gives:\n",
    "        [('Dose', 'cGy'), \n",
    "         ('Relative dose', '%'),\n",
    "         ('Ratio of Total Structure Volume', '%')\n",
    "         ]\n",
    "\n",
    "    Args:\n",
    "        line (str): Header line for DVH Curve\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str]]: A list of two-item tuples. The first item is \n",
    "        the label and the second is the units. \n",
    "    '''\n",
    "    header_pattern = (\n",
    "        r'\\s*'               # Initial spaces\n",
    "        r'(?P<Label>'        # Beginning of label capture group\n",
    "        r'[A-Za-z /]*'       # Label text (can include spaced and '/') \n",
    "        r')'                 # End of label capture group        \n",
    "        r'\\s*'               # Possible whitespace\n",
    "        r'\\['                # Units start delimiter\n",
    "        r'(?P<Units>[^]]*)'  # Text containing units (all text until ']'\n",
    "        r'\\]'                # Units end delimiter\n",
    "        )\n",
    "    re_pattern = re.compile(header_pattern)\n",
    "    label_list = []\n",
    "    for match in re_pattern.finditer(line):\n",
    "        match_results = match.groupdict()\n",
    "        header = (match_results['Label'].strip(), \n",
    "                  match_results['Units'].strip())\n",
    "        label_list.append(header)\n",
    "    return label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_points(line: str)->List[float]:\n",
    "    return [float(num) for num in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_blanks(lines: List[List[float]]) -> List[List[float]]:\n",
    "    '''Return all non-empty lines\n",
    "    '''\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_header_section = Section(\n",
    "    name='Header',\n",
    "    start_section=('Dose [', 'IN', 'Before'),\n",
    "    end_section=True,\n",
    "    processor=header_parse\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_curve_section = Section(\n",
    "    name='DVH Curve',\n",
    "    start_search=False,\n",
    "    end_section=('Structure:', 'START', 'Before'),\n",
    "    processor=[split_data_points, drop_blanks]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh_dose = Section(\n",
    "    name='DVH Dose',\n",
    "    start_search=('Structure:', 'START', 'Before'),\n",
    "    #end_section=('Structure:', 'START', 'Before'),\n",
    "    processor=[(dose_info_section, \n",
    "                dose_header_section, \n",
    "                dose_curve_section)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(structure_data, unit_columns, index_columns, context):\n",
    "    prescriptions = context['PlanLookup']\n",
    "    # Select the columns that contain units\n",
    "    select_columns = unit_columns + index_columns\n",
    "    col_ref = [col.replace(' unit', '') for col in select_columns]\n",
    "    data_units = structure_data[select_columns].copy()\n",
    "    data_units.columns = col_ref\n",
    "    data_units.set_index(index_columns, inplace=True)\n",
    "\n",
    "    # Create a table of dose units conversion\n",
    "    #  Start with a table of all ones\n",
    "    unit_conversion = pd.DataFrame(data=1.0,\n",
    "                                index=data_units.index, \n",
    "                                columns=data_units.columns)\n",
    "    # Add the correct conversion factor for each plan in the DVH\n",
    "    unit_conversion = unit_conversion.mul(prescriptions['DoseConversion'], \n",
    "                                          axis='index')\n",
    "    # For columns that are not Dose restore the correction factor to 1.0\n",
    "    dose_cols = ['Min Dose', 'Max Dose', 'Mean Dose', \n",
    "                'Modal Dose', 'Median Dose', 'STD']\n",
    "    # For Dose columns that are not in '%', restore the correction factor to 1.0\n",
    "    idx = data_units.isin({col: ['%'] for col in dose_cols})\n",
    "    unit_conversion = unit_conversion.where(idx,1.0)\n",
    "    # Update the units after conversion\n",
    "    data_units = data_units.where(~idx, prescriptions['Prescribed dose unit'], \n",
    "                                  axis=0)\n",
    "    return unit_conversion, data_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_volume(dvh_data, vol_idx, hdr, dt, header_dict, context):\n",
    "    vol_unit = hdr[vol_idx][1]\n",
    "    if vol_unit == '%':    \n",
    "        vol = dt['Structure']['Volume']\n",
    "        dvh_data[:,vol_idx] = dvh_data[:,vol_idx]*vol/100\n",
    "        vol_unit = dt['Structure']['Volume unit']\n",
    "    elif vol_unit == 'cm³ / %':   \n",
    "        plan_idx = header_dict['Course'], header_dict['Plan']\n",
    "        prescriptions = context['PlanLookup']\n",
    "        cnv = prescriptions.at[plan_idx, 'DoseConversion']\n",
    "        dose_unit = prescriptions.at[plan_idx, 'Prescribed dose unit']\n",
    "        dvh_data[:,vol_idx] = dvh_data[:,vol_idx]/cnv\n",
    "        vol_unit = vol_unit.replace('%', dose_unit)\n",
    "    return dvh_data, vol_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_curve(dt, context):\n",
    "    # Convert the list of lists to a 2D numpy array so that columns can be \n",
    "    # extracted easier.\n",
    "    dvh_data = np.array(dt['DVH Curve'])\n",
    "    # Construct an index for the curve\n",
    "    header_dict = {\n",
    "        'Course': dt['Structure']['Course'],\n",
    "        'Plan': dt['Structure']['Plan'],\n",
    "        'Structure': dt['Structure']['Structure']\n",
    "    }\n",
    "    # Get the curve header info to locate the desired data columns.\n",
    "    hdr = dt['Header'][0]\n",
    "\n",
    "    # Locate the dose column in absolute dose units.  \n",
    "    # Exclude columns with a label containing 'dDose' because Delta volume \n",
    "    # columns may also have Gy or cGy in the units.\n",
    "    # Note: This assumes that there there always will be a Dose column in \n",
    "    # absolute units.\n",
    "    dose_idx = [i for i,h in enumerate(hdr) \n",
    "                if ('Gy' in h[1]) & ('dDose' not in h[0])][0]\n",
    "    # Put the dose units (Gy or cGy) into the context dictionary.\n",
    "    context['Dose Unit'] = hdr[dose_idx][1]\n",
    "    \n",
    "    vol_idx = [i for i,h in enumerate(hdr) if 'volume' in h[0].lower()][0]\n",
    "    dvh_data, vol_unit = convert_volume(dvh_data, vol_idx, hdr,\n",
    "                                        dt, header_dict, context)\n",
    "    context['Volume Unit'] = vol_unit\n",
    "    \n",
    "    col_idx = [dose_idx, vol_idx]\n",
    "    curve = pd.DataFrame(dvh_data[:,col_idx], columns = ['Dose', 'Volume'])\n",
    "    curve.set_index('Dose', inplace=True)\n",
    "\n",
    "    struct_idx = [(header_dict['Course'], \n",
    "                   header_dict['Plan'],\n",
    "                   header_dict['Structure'])]\n",
    "    idx_names = ['Course', 'Plan', 'Structure']\n",
    "    curve.columns = pd.MultiIndex.from_tuples(struct_idx, names=idx_names)\n",
    "    return curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sort(label: str)->int:\n",
    "    '''Generate Sort index values for DVH Structure items.\n",
    "\n",
    "    Start with a defined list of columns labels and their desired order.\n",
    "    Then sort DVH dose point labels like *D95.0% [cGy]* or *D98.0% [%]* in\n",
    "    order of increasing dose value. Then sort DVH volume point labels like\n",
    "    *V95.0% [cm³]* in order of increasing volume value. Place any other columns \n",
    "    at the end.\n",
    "\n",
    "    Args:\n",
    "        label (str): A DVH Structure item label.\n",
    "\n",
    "    Returns:\n",
    "        int: The sort order index for the desired column.\n",
    "    '''\n",
    "    # Sort the columns with the following labels in the order listed.\n",
    "    # Even numbers are used here to simplify any future changes.\n",
    "    column_order = {\n",
    "        'Volume': 2,\n",
    "        'Equiv. Sphere Diam.': 4,\n",
    "        'Dose Cover.': 6,\n",
    "        'Sampling Cover.': 8, \n",
    "        'Max Dose': 10, \n",
    "        'Min Dose': 12, \n",
    "        'Mean Dose': 14,\n",
    "        'Median Dose': 16, \n",
    "        'Modal Dose': 18, \n",
    "        'STD': 20,\n",
    "        'Conformity Index': 22,\n",
    "        'Gradient Measure': 24, \n",
    "        'GI': 26, \n",
    "        'ICRU83 HI': 28, \n",
    "        'RTOG CI': 30,     \n",
    "        'Paddick CI': 32, \n",
    "        'Dose Level': 34\n",
    "        }\n",
    "    # If the column label is in the above dictionary return the matching number.\n",
    "    order = column_order.get(label)\n",
    "    if order:\n",
    "        return order\n",
    "    # Look for DVH dose point labels like: D95.0% [cGy]    \n",
    "    dose_match = re.search('D([0-9]+)', label)  \n",
    "    # If found build a sort index number using the dose value + 100.\n",
    "    # This way it will appear after the items in the dictionary, but in order of \n",
    "    # increasing dose value.\n",
    "    if dose_match is not None:\n",
    "        order = 100 + int(dose_match[1])\n",
    "        return order\n",
    "    # Look for DVH volume point labels like: V95.0% [cm³]\n",
    "    vol_match = re.search('V([0-9]+)', label)  \n",
    "    # If found build a sort index number using the volume value + 10000.\n",
    "    # This way it will appear after the dose point labels, but in order of \n",
    "    # increasing volume value.\n",
    "    if vol_match is not None:\n",
    "        order = 10000 + int(vol_match[1])\n",
    "        return order\n",
    "    # For all other labels, return a large value to place them at the end.\n",
    "    return int(1e6)\n",
    "\n",
    "\n",
    "def column_sort(labels: pd.Index)->pd.Index:\n",
    "    '''Generate a sort index for the given DVH Structure index.\n",
    "\n",
    "    Generate the index using the label_sort function.\n",
    "\n",
    "    Args:\n",
    "        labels (pd.Index): The column index from the DVH Structure table.\n",
    "\n",
    "    Returns:\n",
    "        pd.Index: A corresponding sort index.\n",
    "    '''\n",
    "    sort_list = [label_sort(label) for label in labels]    \n",
    "    return pd.Index(sort_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_structure_table(structure_data_list: List[Dict[str, Any]], \n",
    "                          context: Dict[str, Any])->pd.DataFrame:\n",
    "    structure_data = pd.DataFrame(structure_data_list)\n",
    "\n",
    "    index_columns = ['Course', 'Plan', 'Structure']\n",
    "    unit_columns = [col for col in structure_data.columns if 'unit' in col]\n",
    "\n",
    "    structure_table = structure_data.drop(columns=unit_columns)\n",
    "    structure_table.set_index(index_columns, inplace=True)\n",
    "\n",
    "    unit_conversion, data_units = convert_units(structure_data, unit_columns, \n",
    "                                                index_columns, context)\n",
    "    structure_table = structure_table * unit_conversion\n",
    "    structure_table.drop(columns=['Approval Status', 'Dose Level'], \n",
    "                         inplace=True)\n",
    "\n",
    "    structure_table.sort_index(axis='columns', key=column_sort, inplace=True)\n",
    "    return structure_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_curve(dt, context):\n",
    "    # Convert the list of lists to a 2D numpy array so that columns can be \n",
    "    # extracted easier.\n",
    "    dvh_data = np.array(dt['DVH Curve'])\n",
    "    # Construct an index for the curve\n",
    "    header_dict = {\n",
    "        'Course': dt['Structure']['Course'],\n",
    "        'Plan': dt['Structure']['Plan'],\n",
    "        'Structure': dt['Structure']['Structure']\n",
    "    }\n",
    "    # Get the curve header info to locate the desired data columns.\n",
    "    hdr = dt['Header'][0]\n",
    "\n",
    "    # Locate the dose column in absolute dose units.  \n",
    "    # Exclude columns with a label containing 'dDose' because Delta volume \n",
    "    # columns may also have Gy or cGy in the units.\n",
    "    # Note: This assumes that there there always will be a Dose column in \n",
    "    # absolute units.\n",
    "    dose_idx = [i for i,h in enumerate(hdr) \n",
    "                if ('Gy' in h[1]) & ('dDose' not in h[0])][0]\n",
    "    # Put the dose units (Gy or cGy) into the context dictionary.\n",
    "    context['Dose Unit'] = hdr[dose_idx][1]\n",
    "    \n",
    "    vol_idx = [i for i,h in enumerate(hdr) if 'volume' in h[0].lower()][0]\n",
    "    dvh_data, vol_unit = convert_volume(dvh_data, vol_idx, hdr,\n",
    "                                        dt, header_dict, context)\n",
    "    context['Volume Unit'] = vol_unit\n",
    "    \n",
    "    col_idx = [dose_idx, vol_idx]\n",
    "    curve = pd.DataFrame(dvh_data[:,col_idx], columns = ['Dose', 'Volume'])\n",
    "    curve.set_index('Dose', inplace=True)\n",
    "\n",
    "    struct_idx = [(header_dict['Course'], \n",
    "                   header_dict['Plan'],\n",
    "                   header_dict['Structure'])]\n",
    "    idx_names = ['Course', 'Plan', 'Structure']\n",
    "    curve.columns = pd.MultiIndex.from_tuples(struct_idx, names=idx_names)\n",
    "    return curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dvh_tables(combined_data: List[Dict[str, Any]], \n",
    "                     context: Dict[str, Any])->pd.DataFrame:\n",
    "    curve_list = []\n",
    "    structure_data_list = []\n",
    "    for dt in combined_data:\n",
    "        structure_data_list.append(dt['Structure'])\n",
    "        curve = build_curve(dt, context)\n",
    "        curve_list.append(curve)\n",
    "\n",
    "    dose_table = pd.concat(curve_list, axis='columns')\n",
    "    structure_table = build_structure_table(structure_data_list, context)\n",
    "    dvh_tables = {\n",
    "        'StructureTable': structure_table,\n",
    "        'DVH_Curves': dose_table\n",
    "        }\n",
    "    return dvh_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh_dose = Section(\n",
    "    name='DVH Dose',\n",
    "    start_search=('Structure:', 'START', 'Before'),\n",
    "    processor=[(dose_info_section, \n",
    "                dose_header_section, \n",
    "                dose_curve_section)],\n",
    "    assemble=build_dvh_tables\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dvh_info(dvh_section_iter: List[Dict[str,Any]], \n",
    "                 context: Dict[str,Any])->Dict[str,Any]:\n",
    "    # Only one dvh_file_reader in a file \n",
    "    dvh_sections = [ dvh_dict for dvh_dict in dvh_section_iter][0]\n",
    "    dvh_info = dvh_sections['Information']\n",
    "    dvh_info['Dose Unit'] = context['Dose Unit']\n",
    "    dvh_info['Volume Unit'] = context['Volume Unit']\n",
    "    \n",
    "    dvh_tables = {'Plans': context['PlanLookup'],\n",
    "                  'Structures': dvh_sections['DVH Dose']['StructureTable'],\n",
    "                  'DVH_data': dvh_sections['DVH Dose']['DVH_Curves']\n",
    "                  }\n",
    "    return  dvh_info, dvh_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh_file_reader = Section(\n",
    "    name='DVH File',\n",
    "    processor=[(dvh_info_section, \n",
    "                all_plans, \n",
    "                dvh_dose)],\n",
    "    assemble=get_dvh_info\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dvh_text = demo_dvh_1.read_text(encoding='utf_8_sig').splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Patient Name': 'AXIR, CHWR',\n",
       "  'Patient ID': 'TEST CHWR',\n",
       "  'Comment': 'DVHs for one plan',\n",
       "  'Date': 'March 17, 2023 11:40:38 AM',\n",
       "  'Exported by': 'GS MP',\n",
       "  'Type': 'Cumulative Dose Volume Histogram',\n",
       "  'Dose Unit': 'cGy',\n",
       "  'Volume Unit': 'cm³'},\n",
       " {'Plans':             Plan Status  Prescribed dose Prescribed dose unit  \\\n",
       "  Course Plan                                                     \n",
       "  C1     CHWR   Completed           4250.0                  cGy   \n",
       "  \n",
       "               Prescription Isodose  DoseConversion  \n",
       "  Course Plan                                        \n",
       "  C1     CHWR                 100.0            42.5  ,\n",
       "  'Structures':                                Volume  Equiv. Sphere Diam.  Dose Cover.  \\\n",
       "  Course Plan Structure                                                     \n",
       "  C1     CHWR BODY              20449.1                 33.9        100.0   \n",
       "              Cricoid               4.2                  2.0        100.0   \n",
       "              Spinal Canal         16.2                  3.1        100.0   \n",
       "              Scar Wire             0.2                  0.7        100.0   \n",
       "              PTV Nodes           197.9                  7.2        100.0   \n",
       "              Nodes SC             10.2                  2.7        100.0   \n",
       "              Nodes IMC             1.5                  1.4        100.0   \n",
       "              Nodes Axilla III      5.0                  2.1        100.0   \n",
       "              Nodes Axilla II      24.7                  3.6        100.0   \n",
       "              Nodes Axilla I       39.1                  4.2        100.0   \n",
       "              Matchplane           71.0                  5.1        100.0   \n",
       "              Lung R              950.7                 12.2        100.0   \n",
       "              Lung L              737.0                 11.2        100.0   \n",
       "              Lung B             1687.7                 14.8        100.0   \n",
       "              Heart               492.7                  9.8        100.0   \n",
       "              CTV Nodes            70.7                  5.1        100.0   \n",
       "              Baseline             52.4                  4.6        100.0   \n",
       "              Liver              1174.7                 13.1        100.0   \n",
       "  \n",
       "                                Sampling Cover.  Max Dose  Min Dose  Mean Dose  \\\n",
       "  Course Plan Structure                                                          \n",
       "  C1     CHWR BODY                        100.0   4394.50      0.00     263.50   \n",
       "              Cricoid                      99.8     21.25      8.50      12.75   \n",
       "              Spinal Canal                100.0     29.75      4.25      17.00   \n",
       "              Scar Wire                   100.7   3791.00      0.00    1181.50   \n",
       "              PTV Nodes                   100.0   4233.00     17.00    1406.75   \n",
       "              Nodes SC                    100.0    157.25     21.25      42.50   \n",
       "              Nodes IMC                    99.8   4097.00    165.75    3132.25   \n",
       "              Nodes Axilla III            100.1     72.25     42.50      55.25   \n",
       "              Nodes Axilla II             100.0    403.75     63.75     153.00   \n",
       "              Nodes Axilla I              100.0   4143.75    182.75    2898.50   \n",
       "              Matchplane                  100.0   2902.75      0.00     527.00   \n",
       "              Lung R                      100.0   4088.50     17.00     871.25   \n",
       "              Lung L                      100.0     55.25      0.00       8.50   \n",
       "              Lung B                      100.0   4088.50      0.00     493.00   \n",
       "              Heart                       100.0   1423.75      0.00      63.75   \n",
       "              CTV Nodes                   100.0   4143.75     42.50    1704.25   \n",
       "              Baseline                    100.0   4339.25      0.00    2452.25   \n",
       "              Liver                       100.0   2928.25      8.50     114.75   \n",
       "  \n",
       "                                Median Dose  Modal Dose      STD  ...  \\\n",
       "  Course Plan Structure                                           ...   \n",
       "  C1     CHWR BODY                    12.75        0.00   862.75  ...   \n",
       "              Cricoid                 12.75       12.75     0.00  ...   \n",
       "              Spinal Canal            17.00        4.25     8.50  ...   \n",
       "              Scar Wire             1083.75        0.00   799.00  ...   \n",
       "              PTV Nodes              225.25       42.50  1729.75  ...   \n",
       "              Nodes SC                38.25       25.50    21.25  ...   \n",
       "              Nodes IMC             3901.50     4020.50  1372.75  ...   \n",
       "              Nodes Axilla III        55.25       51.00     8.50  ...   \n",
       "              Nodes Axilla II        127.50       93.50    68.00  ...   \n",
       "              Nodes Axilla I        3833.50     4012.00  1513.00  ...   \n",
       "              Matchplane              29.75        0.00   858.50  ...   \n",
       "              Lung R                 165.75       51.00  1283.50  ...   \n",
       "              Lung L                   8.50        0.00     4.25  ...   \n",
       "              Lung B                  46.75        0.00  1054.00  ...   \n",
       "              Heart                   29.75       12.75    76.50  ...   \n",
       "              CTV Nodes              352.75       93.50  1780.75  ...   \n",
       "              Baseline              3527.50        0.00  1789.25  ...   \n",
       "              Liver                   97.75       29.75   106.25  ...   \n",
       "  \n",
       "                                Gradient Measure  GI  ICRU83 HI  RTOG CI  \\\n",
       "  Course Plan Structure                                                    \n",
       "  C1     CHWR BODY                           NaN NaN        NaN      NaN   \n",
       "              Cricoid                        NaN NaN        NaN      NaN   \n",
       "              Spinal Canal                   NaN NaN        NaN      NaN   \n",
       "              Scar Wire                      NaN NaN        NaN      NaN   \n",
       "              PTV Nodes                      NaN NaN        NaN      NaN   \n",
       "              Nodes SC                       NaN NaN        NaN      NaN   \n",
       "              Nodes IMC                      NaN NaN        NaN      NaN   \n",
       "              Nodes Axilla III               NaN NaN        NaN      NaN   \n",
       "              Nodes Axilla II                NaN NaN        NaN      NaN   \n",
       "              Nodes Axilla I                 NaN NaN        NaN      NaN   \n",
       "              Matchplane                     NaN NaN        NaN      NaN   \n",
       "              Lung R                         NaN NaN        NaN      NaN   \n",
       "              Lung L                         NaN NaN        NaN      NaN   \n",
       "              Lung B                         NaN NaN        NaN      NaN   \n",
       "              Heart                          NaN NaN        NaN      NaN   \n",
       "              CTV Nodes                      NaN NaN        NaN      NaN   \n",
       "              Baseline                       NaN NaN        NaN      NaN   \n",
       "              Liver                          NaN NaN        NaN      NaN   \n",
       "  \n",
       "                                Paddick CI  D95.0% [cGy]  D98.0% [%]  \\\n",
       "  Course Plan Structure                                                \n",
       "  C1     CHWR BODY                     NaN           NaN         NaN   \n",
       "              Cricoid                  NaN           NaN         NaN   \n",
       "              Spinal Canal             NaN           NaN         NaN   \n",
       "              Scar Wire                NaN           NaN         NaN   \n",
       "              PTV Nodes                NaN           NaN         NaN   \n",
       "              Nodes SC                 NaN           NaN         NaN   \n",
       "              Nodes IMC                NaN           NaN         NaN   \n",
       "              Nodes Axilla III         NaN           NaN         NaN   \n",
       "              Nodes Axilla II          NaN           NaN         NaN   \n",
       "              Nodes Axilla I           NaN           NaN         NaN   \n",
       "              Matchplane               NaN           NaN         NaN   \n",
       "              Lung R                   NaN           NaN         NaN   \n",
       "              Lung L                   NaN           NaN         NaN   \n",
       "              Lung B                   NaN           NaN         NaN   \n",
       "              Heart                    NaN           NaN         NaN   \n",
       "              CTV Nodes                NaN           NaN         NaN   \n",
       "              Baseline                 NaN           NaN         NaN   \n",
       "              Liver                    NaN           NaN         NaN   \n",
       "  \n",
       "                                D99.0% [cGy]  V95.0% [cm³]  V100.0% [cm³]  \n",
       "  Course Plan Structure                                                    \n",
       "  C1     CHWR BODY                       NaN           NaN            NaN  \n",
       "              Cricoid                    NaN           NaN            NaN  \n",
       "              Spinal Canal               NaN           NaN            NaN  \n",
       "              Scar Wire                  NaN           NaN            NaN  \n",
       "              PTV Nodes                  NaN           NaN            NaN  \n",
       "              Nodes SC                   NaN           NaN            NaN  \n",
       "              Nodes IMC                  NaN           NaN            NaN  \n",
       "              Nodes Axilla III           NaN           NaN            NaN  \n",
       "              Nodes Axilla II            NaN           NaN            NaN  \n",
       "              Nodes Axilla I             NaN           NaN            NaN  \n",
       "              Matchplane                 NaN           NaN            NaN  \n",
       "              Lung R                     NaN           NaN            NaN  \n",
       "              Lung L                     NaN           NaN            NaN  \n",
       "              Lung B                     NaN           NaN            NaN  \n",
       "              Heart                      NaN           NaN            NaN  \n",
       "              CTV Nodes                  NaN           NaN            NaN  \n",
       "              Baseline                   NaN           NaN            NaN  \n",
       "              Liver                      NaN           NaN            NaN  \n",
       "  \n",
       "  [18 rows x 21 columns],\n",
       "  'DVH_data': Course               C1                                                        \\\n",
       "  Plan               CHWR                                                         \n",
       "  Structure          BODY Cricoid Spinal Canal Scar Wire   PTV Nodes   Nodes SC   \n",
       "  Dose                                                                            \n",
       "  0.0        20449.100000     4.2         16.2  0.200000  197.900000  10.200000   \n",
       "  42.5        6045.510577     0.0          0.0  0.192057  179.526172   3.882589   \n",
       "  85.0        4212.719091     0.0          0.0  0.189588  143.680941   0.487524   \n",
       "  127.5       3077.487304     0.0          0.0  0.186312  123.950707   0.028369   \n",
       "  170.0       2469.310621     0.0          0.0  0.182694  111.347643   0.000000   \n",
       "  ...                 ...     ...          ...       ...         ...        ...   \n",
       "  4207.5       153.745331     0.0          0.0  0.000000    0.016353   0.000000   \n",
       "  4250.0        93.274889     0.0          0.0  0.000000    0.000000   0.000000   \n",
       "  4292.5        42.371149     0.0          0.0  0.000000    0.000000   0.000000   \n",
       "  4335.0         8.423557     0.0          0.0  0.000000    0.000000   0.000000   \n",
       "  4377.5         0.423192     0.0          0.0  0.000000    0.000000   0.000000   \n",
       "  \n",
       "  Course                                                               \\\n",
       "  Plan                                                                  \n",
       "  Structure Nodes IMC Nodes Axilla III Nodes Axilla II Nodes Axilla I   \n",
       "  Dose                                                                  \n",
       "  0.0        1.500000         5.000000       24.700000           39.1   \n",
       "  42.5       1.500000         4.974855       24.700000           39.1   \n",
       "  85.0       1.500000         0.000000       22.078515           39.1   \n",
       "  127.5      1.500000         0.000000       12.538930           39.1   \n",
       "  170.0      1.499939         0.000000        7.424005           39.1   \n",
       "  ...             ...              ...             ...            ...   \n",
       "  4207.5     0.000000         0.000000        0.000000            0.0   \n",
       "  4250.0     0.000000         0.000000        0.000000            0.0   \n",
       "  4292.5     0.000000         0.000000        0.000000            0.0   \n",
       "  4335.0     0.000000         0.000000        0.000000            0.0   \n",
       "  4377.5     0.000000         0.000000        0.000000            0.0   \n",
       "  \n",
       "  Course                                                                 \\\n",
       "  Plan                                                                    \n",
       "  Structure Matchplane      Lung R      Lung L       Lung B       Heart   \n",
       "  Dose                                                                    \n",
       "  0.0        71.000000  950.700000  737.000000  1687.700000  492.700000   \n",
       "  42.5       31.785493  863.832640    1.029515   864.809546  197.372664   \n",
       "  85.0       24.654608  610.848518    0.000000   610.812384  126.288371   \n",
       "  127.5      22.132049  523.138837    0.000000   523.107678   77.816545   \n",
       "  170.0      20.945923  468.126581    0.000000   468.098784   38.734152   \n",
       "  ...              ...         ...         ...          ...         ...   \n",
       "  4207.5      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "  4250.0      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "  4292.5      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "  4335.0      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "  4377.5      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "  \n",
       "  Course                                        \n",
       "  Plan                                          \n",
       "  Structure  CTV Nodes   Baseline        Liver  \n",
       "  Dose                                          \n",
       "  0.0        70.700000  52.400000  1174.700000  \n",
       "  42.5       70.676457  37.986018   904.260566  \n",
       "  85.0       62.641119  37.859157   699.472766  \n",
       "  127.5      53.115284  37.771387   367.701070  \n",
       "  170.0      48.010673  37.700228   197.092341  \n",
       "  ...              ...        ...          ...  \n",
       "  4207.5      0.000000   4.084669     0.000000  \n",
       "  4250.0      0.000000   2.356894     0.000000  \n",
       "  4292.5      0.000000   0.681378     0.000000  \n",
       "  4335.0      0.000000   0.000993     0.000000  \n",
       "  4377.5      0.000000   0.000000     0.000000  \n",
       "  \n",
       "  [104 rows x 18 columns]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = {'Dummy': 'test'}\n",
    "dvh_file_reader.read(demo_dvh_text, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Current Section': 'DVH File',\n",
       " 'Status': 'End of Source',\n",
       " 'Dummy': 'test',\n",
       " 'Skipped Lines': [],\n",
       " 'PlanLookup':             Plan Status  Prescribed dose Prescribed dose unit  \\\n",
       " Course Plan                                                     \n",
       " C1     CHWR   Completed           4250.0                  cGy   \n",
       " \n",
       "              Prescription Isodose  DoseConversion  \n",
       " Course Plan                                        \n",
       " C1     CHWR                 100.0            42.5  ,\n",
       " 'Dose Unit': 'cGy',\n",
       " 'Volume Unit': 'cm³'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvh_file_reader.context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Error](Error.png)  When called without supplying context, the assemble function `get_dvh_info` is not receiving context propagated from the section processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Dose Unit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15948\\1743846292.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdvh_file_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdemo_dvh_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\OneDrive - Queen's University\\Python\\Projects\\sectionary package\\src\\sections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, source, start_search, context)\u001b[0m\n\u001b[0;32m   2835\u001b[0m                                          context=context)\n\u001b[0;32m   2836\u001b[0m         \u001b[1;31m# Send the processing generator to the assemble function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2837\u001b[1;33m         \u001b[0msection_assembled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection_processor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2838\u001b[0m         \u001b[1;31m#self.wrap_up(local_context, context)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\OneDrive - Queen's University\\Python\\Projects\\sectionary package\\src\\sections.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(func, item, context)\u001b[0m\n\u001b[0;32m    607\u001b[0m     process_sig = {\n\u001b[0;32m    608\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         }\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15948\\54208847.py\u001b[0m in \u001b[0;36mget_dvh_info\u001b[1;34m(dvh_section_iter, context)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdvh_sections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mdvh_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdvh_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdvh_section_iter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdvh_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdvh_sections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Information'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdvh_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dose Unit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dose Unit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdvh_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volume Unit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volume Unit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Dose Unit'"
     ]
    }
   ],
   "source": [
    "dvh_file_reader.read(demo_dvh_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Error](Error.png)  When called with an empty context dictionary, the assemble function `get_dvh_info` is not receiving context propagated from the section processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Dose Unit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15948\\2723787479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdvh_file_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdemo_dvh_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\OneDrive - Queen's University\\Python\\Projects\\sectionary package\\src\\sections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, source, start_search, context)\u001b[0m\n\u001b[0;32m   2835\u001b[0m                                          context=context)\n\u001b[0;32m   2836\u001b[0m         \u001b[1;31m# Send the processing generator to the assemble function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2837\u001b[1;33m         \u001b[0msection_assembled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection_processor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2838\u001b[0m         \u001b[1;31m#self.wrap_up(local_context, context)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\OneDrive - Queen's University\\Python\\Projects\\sectionary package\\src\\sections.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(func, item, context)\u001b[0m\n\u001b[0;32m    607\u001b[0m     process_sig = {\n\u001b[0;32m    608\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         }\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15948\\54208847.py\u001b[0m in \u001b[0;36mget_dvh_info\u001b[1;34m(dvh_section_iter, context)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdvh_sections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mdvh_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdvh_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdvh_section_iter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdvh_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdvh_sections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Information'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdvh_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dose Unit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dose Unit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdvh_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volume Unit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volume Unit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Dose Unit'"
     ]
    }
   ],
   "source": [
    "context = {}\n",
    "dvh_file_reader.read(demo_dvh_text, context=context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import unittest\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#import pandas as pd\n",
    "#import xlwings as xw\n",
    "\n",
    "from buffered_iterator import BufferedIterator\n",
    "import text_reader as tp\n",
    "from sections import Rule, RuleSet, SectionBreak, ProcessingMethods, Section\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process function that prints the section's context\n",
    "def process_show_context(input_item, context):\n",
    "    '''display the section's context and return the section_item.\n",
    "    '''\n",
    "    print('\\nContext in Processor:')\n",
    "    pprint(context)\n",
    "    return input_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly function that prints the section's context\n",
    "def assembly_show_context(processed_items, context):\n",
    "    '''display the section's context and return the item list.\n",
    "    '''\n",
    "    section_list = [processed_item for processed_item in processed_items]\n",
    "    print('\\nContext in Assembler:')\n",
    "    pprint(context)\n",
    "    print('\\n')\n",
    "    return section_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Function to compare context for two sections.\n",
    "def compare_context(section1, section2):\n",
    "    ctx_template = '{key:16s}:\\t{item1:16s}\\t{item2:16s}'\n",
    "    context_1 = section1.context\n",
    "    context_2 = section2.context\n",
    "    keys_1 = set(context_1.keys())\n",
    "    keys_2 = set(context_2.keys())\n",
    "    all_keys = keys_1 | keys_2\n",
    "    for key in all_keys:\n",
    "        item1 = context_1.get(key, '')\n",
    "        item2 = context_2.get(key, '')\n",
    "        ctx_str = ctx_template.format(key=str(key), item1=str(item1), item2=str(item2))\n",
    "        print(ctx_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context in Assembler:\n",
      "{'AddLine': 'ExtraLine',\n",
      " 'Break': 'End Section',\n",
      " 'Current Section': 'Top Section',\n",
      " 'Event': 'ignored',\n",
      " 'Skipped Lines': [],\n",
      " 'Status': 'Break Triggered'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['StartSection A', 'ExtraLine', 'EndSection A'],\n",
       " ['StartSection B', 'ExtraLine', 'EndSection B']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_to_context(text_item: str, context: Dict[str,Any])->str:\n",
    "    extra_line = context.get('AddLine')\n",
    "    if extra_line: \n",
    "        if 'MidSection' in text_item:\n",
    "            output = extra_line\n",
    "        else: \n",
    "            output = text_item\n",
    "    else:\n",
    "        output = text_item\n",
    "    return output\n",
    "\n",
    "\n",
    "def drop_from_context(processed_text: List[str], \n",
    "                        context: Dict[str,Any])->str:\n",
    "    def line_output(line, extra_line):\n",
    "        return [item for item in line if item not in extra_line]\n",
    "    extra_line = context.get('AddLine', 'None')\n",
    "\n",
    "    output=[]\n",
    "    for line in processed_text:\n",
    "        output.append(line_output(line, extra_line))\n",
    "    return output\n",
    "\n",
    "\n",
    "test_text = [\n",
    "    'Text to be ignored',\n",
    "    'StartSection A',\n",
    "    'MidSection A',\n",
    "    'EndSection A',\n",
    "    'Text between sections',\n",
    "    'StartSection B',\n",
    "    'MidSection B',\n",
    "    'EndSection B',\n",
    "    'More text to be ignored',\n",
    "    ]\n",
    "\n",
    "sub_section = Section(\n",
    "    name='SubSection',\n",
    "    start_section=SectionBreak('StartSection', break_offset='Before',\n",
    "                                name='SubSectionStart'),\n",
    "    end_section=SectionBreak('EndSection', break_offset='After',\n",
    "                                name='SubSectionEnd'),\n",
    "    processor=add_to_context\n",
    "    )\n",
    "\n",
    "full_section = Section(\n",
    "    name='Top Section',\n",
    "    end_section=SectionBreak('ignored', break_offset='Before',\n",
    "                        name='End Section'),\n",
    "    processor=sub_section,\n",
    "    assemble=assembly_show_context\n",
    "    )\n",
    "\n",
    "context = {'AddLine': 'ExtraLine'}\n",
    "\n",
    "read = full_section.read(test_text, context=context)\n",
    "\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['StartSection A', 'EndSection A'], ['StartSection B', 'EndSection B']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_section = Section(\n",
    "    name='Top Section',\n",
    "    end_section=SectionBreak('ignored', break_offset='Before',\n",
    "                        name='End Section'),\n",
    "    processor=sub_section,\n",
    "    assemble=drop_from_context\n",
    "    )\n",
    "\n",
    "context = {'AddLine': 'ExtraLine'}\n",
    "\n",
    "read = full_section.read(test_text, context=context)\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['StartSection A', 'EndSection A'], ['StartSection B', 'EndSection B']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = [\n",
    "    'Text to be ignored',\n",
    "    'StartSection A',\n",
    "    'MidSection A',\n",
    "    'EndSection A',\n",
    "    'Text between sections',\n",
    "    'StartSection B',\n",
    "    'MidSection B',\n",
    "    'EndSection B',\n",
    "    'More text to be ignored',\n",
    "    ]\n",
    "\n",
    "def drop_from_context(processed_text: List[str],\n",
    "                        context: Dict[str,Any])->str:\n",
    "    def line_output(line, drop_line):\n",
    "        return [item for item in line if drop_line not in item]\n",
    "    \n",
    "    drop_line = context.get('DropLine', 'None')\n",
    "    output=[]\n",
    "    for line in processed_text:\n",
    "        output.append(line_output(line, drop_line))\n",
    "    return output\n",
    "\n",
    "sub_section = Section(\n",
    "    name='SubSection',\n",
    "    start_section=SectionBreak('StartSection', break_offset='Before',\n",
    "                                name='SubSectionStart'),\n",
    "    end_section=SectionBreak('EndSection', break_offset='After',\n",
    "                                name='SubSectionEnd')\n",
    "    )\n",
    "full_section = Section(\n",
    "    name='Top Section',\n",
    "    end_section=SectionBreak('ignored', break_offset='Before',\n",
    "                        name='End Section'),\n",
    "    processor=sub_section,\n",
    "    assemble=drop_from_context  # removes MidSection item\n",
    "    )\n",
    "context = {'DropLine': 'MidSection'}\n",
    "read = full_section.read(test_text, context=context)\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_letter(text_item: str)->str:\n",
    "    '''gets the section letter from a line.\n",
    "    '''\n",
    "    if 'Section' in text_item:\n",
    "        section_letter = text_item[-1]\n",
    "    else:\n",
    "        section_letter = ''\n",
    "    return section_letter\n",
    "\n",
    "def update_context(text_item: str, context: Dict[str,Any])->str:\n",
    "    '''Add section letters to a context list.\n",
    "\n",
    "    Looks for a context item 'Sections', with a list value.\n",
    "    If it doesn't find one, it will create one.\n",
    "    The input text_item is returned unchanged.\n",
    "    '''\n",
    "    section_letter = get_section_letter(text_item)\n",
    "    if section_letter:\n",
    "        section_list = context.get('Sections', [])\n",
    "        section_list.append(section_letter)\n",
    "        context['Sections'] = section_list\n",
    "    return text_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context in Assembler:\n",
      "{'Break': 'End Section',\n",
      " 'Current Section': 'Top Section',\n",
      " 'Event': 'ignored',\n",
      " 'Sections': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " 'Skipped Lines': [],\n",
      " 'Status': 'Break Triggered'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['StartSection A', 'MidSection A', 'EndSection A'],\n",
       " ['StartSection B', 'MidSection B', 'EndSection B']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = [\n",
    "    'Text to be ignored',\n",
    "    'StartSection A',\n",
    "    'MidSection A',\n",
    "    'EndSection A',\n",
    "    'Text between sections',\n",
    "    'StartSection B',\n",
    "    'MidSection B',\n",
    "    'EndSection B',\n",
    "    'More text to be ignored',\n",
    "    ]\n",
    "\n",
    "sub_section = Section(\n",
    "    name='SubSection',\n",
    "    start_section=SectionBreak('StartSection', break_offset='Before',\n",
    "                                name='SubSectionStart'),\n",
    "    end_section=SectionBreak('EndSection', break_offset='After',\n",
    "                                name='SubSectionEnd'),\n",
    "    processor=update_context\n",
    "    )\n",
    "full_section = Section(\n",
    "    name='Top Section',\n",
    "    end_section=SectionBreak('ignored', break_offset='Before',\n",
    "                        name='End Section'),\n",
    "    processor=sub_section,\n",
    "    assemble=assembly_show_context  # removes MidSection item\n",
    "    )\n",
    "context = {'Sections': []}\n",
    "read = full_section.read(test_text, context=context)\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Current Section': 'SubSection',\n",
       " 'Status': 'End of Source',\n",
       " 'Sections': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
       " 'Event': 'StartSection',\n",
       " 'Break': 'SubSectionStart',\n",
       " 'Skipped Lines': ['Text between sections']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_section.context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sectionaryDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
