{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Sectionary package was originally designed to deal with text data files containing different sections of data in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "#import read_dvh_file\n",
    "import text_reader as tp\n",
    "from sections import Rule, RuleSet, ProcessingMethods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Standard Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Useful Third Party Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Sectionary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#sys.path.append(r'../src/sectionary') \n",
    "\n",
    "import text_reader as tp\n",
    "from sections import Rule, RuleSet, SectionBreak, ProcessingMethods, Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 4.0, 8.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple_cascading_iterators\n",
    "def ml(x): return x*10\n",
    "def dv(x): return x/5\n",
    "\n",
    "def skip_odd(num_list):\n",
    "    for i in num_list:\n",
    "        if i % 2 == 0:\n",
    "            yield i\n",
    "\n",
    "source = range(5)\n",
    "method_set = ProcessingMethods([skip_odd, ml, dv])\n",
    "test_output = method_set.read(source, {})\n",
    "\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Part 1', 'Part 2a, Part 2b']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_parser\n",
    "test_text = 'Part 1,\"Part 2a, Part 2b\"'\n",
    "expected_output = [['Part 1', 'Part 2a, Part 2b']]\n",
    "test_parser = tp.define_csv_parser(name='Default csv')\n",
    "test_output = [row for row in test_parser(test_text)]\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Export Version:', '1'],\n",
       " ['================'],\n",
       " [],\n",
       " ['IMSure Version:', '3.7.2'],\n",
       " ['Exported Date:', '03.09.2020  14:20'],\n",
       " ['User:', 'Superuser'],\n",
       " ['Patient:', '____, ----'],\n",
       " ['Patient ID:', '0123456']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default_csv_parser\n",
    "test_text = [\n",
    "    'Export Version:,1',\n",
    "    '================',\n",
    "    '',\n",
    "    'IMSure Version:,3.7.2',\n",
    "    'Exported Date:,03.09.2020  14:20',\n",
    "    'User:,Superuser',\n",
    "    'Patient:,\"____, ----\"',\n",
    "    'Patient ID:,0123456',\n",
    "    ]\n",
    "expected_output = [\n",
    "    ['Export Version:', '1'],\n",
    "    ['================'],\n",
    "    [],\n",
    "    ['IMSure Version:', '3.7.2'],\n",
    "    ['Exported Date:', '03.09.2020  14:20'],\n",
    "    ['User:', 'Superuser'],\n",
    "    ['Patient:', '____, ----'],\n",
    "    ['Patient ID:', '0123456']\n",
    "    ]\n",
    "test_parser = tp.define_csv_parser(name='Default')\n",
    "test_iter = (test_parser(line) for line in test_text)\n",
    "test_output = [row for row in chain.from_iterable(test_iter)]\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Patient Name', '____, ____'],\n",
       " ['Patient ID', '1234567'],\n",
       " ['Comment', 'DVHs for multiple plans and plan sums'],\n",
       " ['Date', 'Friday, January 17, 2020 09', '45', '07'],\n",
       " ['Exported by', 'gsal'],\n",
       " ['Type', 'Cumulative Dose Volume Histogram'],\n",
       " ['Description', 'The cumulative DVH displays the percentage'],\n",
       " ['or volume (absolute) of structures that receive a dose'],\n",
       " ['equal to or greater than a given dose.'],\n",
       " ['Plan sum', 'Plan Sum'],\n",
       " ['Course', 'PLAN SUM'],\n",
       " ['Prescribed dose [cGy]', 'not defined'],\n",
       " ['% for dose (%)', 'not defined']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_csv_parser\n",
    "test_text = [\n",
    "    'Patient Name:     ____, ____',\n",
    "    'Patient ID:   1234567',\n",
    "    'Comment: DVHs for multiple plans and plan sums',\n",
    "    'Date: Friday, January 17, 2020 09:45:07',\n",
    "    'Exported by:    gsal',\n",
    "    'Type: Cumulative Dose Volume Histogram',\n",
    "    'Description:The cumulative DVH displays the percentage',\n",
    "    'or volume (absolute) of structures that receive a dose',\n",
    "    'equal to or greater than a given dose.',\n",
    "    'Plan sum: Plan Sum',\n",
    "    'Course: PLAN SUM',\n",
    "    'Prescribed dose [cGy]: not defined',\n",
    "    '% for dose (%): not defined'\n",
    "    ]\n",
    "expected_output = [\n",
    "    ['Patient Name', '____, ____'],\n",
    "    ['Patient ID', '1234567'],\n",
    "    ['Comment', 'DVHs for multiple plans and plan sums'],\n",
    "    ['Date', 'Friday, January 17, 2020 09', '45', '07'],\n",
    "    ['Exported by', 'gsal'],\n",
    "    ['Type', 'Cumulative Dose Volume Histogram'],\n",
    "    ['Description', 'The cumulative DVH displays the percentage'],\n",
    "    ['or volume (absolute) of structures that receive a dose'],\n",
    "    ['equal to or greater than a given dose.'],\n",
    "    ['Plan sum', 'Plan Sum'],\n",
    "    ['Course', 'PLAN SUM'],\n",
    "    ['Prescribed dose [cGy]', 'not defined'],\n",
    "    ['% for dose (%)', 'not defined'],\n",
    "    ]\n",
    "test_parser = tp.define_csv_parser('dvh_info', delimiter=':',\n",
    "                                    skipinitialspace=True)\n",
    "test_iter = (test_parser(line) for line in test_text)\n",
    "test_output = [row for row in chain.from_iterable(test_iter)]\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prescribed Dose Rule\n",
    "def make_prescribed_dose_rule() -> Rule:\n",
    "    def parse_prescribed_dose(line, event) -> tp.ProcessedList:\n",
    "        '''Split \"Prescribed dose [cGy]\" into 2 lines.\n",
    "\n",
    "        Return two rows for a line containing:\n",
    "            Prescribed dose [unit]: dose\n",
    "        Gives:\n",
    "            [['Prescribed dose', 'dose'],\n",
    "            ['Prescribed dose unit', 'unit']],\n",
    "        The line:\n",
    "            Prescribed dose [unit]: not defined\n",
    "        Results in:\n",
    "            [['Prescribed dose', '5000.0'],\n",
    "             ['Prescribed dose unit', 'cGy']]\n",
    "        '''\n",
    "        match_results = event.test_value.groupdict()\n",
    "        if match_results['dose'] == 'not defined':\n",
    "            match_results['dose'] = ''\n",
    "            match_results['unit'] = ''\n",
    "\n",
    "        parsed_lines = [\n",
    "            ['Prescribed dose', match_results['dose']],\n",
    "            ['Prescribed dose unit', match_results['unit']]\n",
    "            ]\n",
    "        for line in parsed_lines:\n",
    "            yield line\n",
    "\n",
    "    prescribed_dose_pattern = (\n",
    "        r'^Prescribed dose\\s*'  # Begins with Prescribed dose\n",
    "        r'\\['                   # Unit start delimiter\n",
    "        r'(?P<unit>[A-Za-z]+)'  # unit group: text surrounded by []\n",
    "        r'\\]'                   # Unit end delimiter\n",
    "        r'\\s*:\\s*'              # Dose delimiter with possible whitespace\n",
    "        r'(?P<dose>[0-9.]+'     # dose group Number\n",
    "        r'|not defined)'        #\"not defined\" alternative\n",
    "        r'[\\s\\r\\n]*'            # drop trailing whitespace\n",
    "        r'$'                    # end of string\n",
    "        )\n",
    "    re_pattern = re.compile(prescribed_dose_pattern)\n",
    "    dose_rule = Rule(sentinel=re_pattern, name='prescribed_dose_rule',\n",
    "                        pass_method= parse_prescribed_dose, fail_method='None')\n",
    "    return dose_rule\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Prescribed dose', ''],\n",
       " ['Prescribed dose unit', ''],\n",
       " ['Prescribed dose', '5000.0'],\n",
       " ['Prescribed dose unit', 'cGy']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse_prescribed_dose_rule\n",
    "test_text = [\n",
    "    'Prescribed dose [cGy]: not defined',\n",
    "    '% for dose (%): not defined',\n",
    "    'Prescribed dose [cGy]: 5000.0',\n",
    "    '% for dose (%): 100.0'\n",
    "    ]\n",
    "expected_output = [\n",
    "    ['Prescribed dose', ''],\n",
    "    ['Prescribed dose unit', ''],\n",
    "    ['Prescribed dose', '5000.0'],\n",
    "    ['Prescribed dose unit', 'cGy'],\n",
    "    ]\n",
    "\n",
    "dose_rule = make_prescribed_dose_rule()\n",
    "test_output = list()\n",
    "for line in test_text:\n",
    "    result = dose_rule(line)\n",
    "    line_output = [p_line for p_line in result]\n",
    "    if dose_rule.event.test_passed:\n",
    "        test_output.extend(line_output)\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date_parse_rule() -> Rule:\n",
    "    def date_parse(line: str) -> tp.ProcessedList:\n",
    "        '''If Date,don't split beyond first :.'''\n",
    "        parsed_line = line.split(':', maxsplit=1)\n",
    "        return parsed_line\n",
    "\n",
    "    date_rule = Rule('Date', location='START', name='date_rule',\n",
    "                        pass_method=date_parse, fail_method='None')\n",
    "    return date_rule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Date', ' Friday, January 17, 2020 09:45:07']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_parse_rule(self):\n",
    "test_text = [\n",
    "    'Date: Friday, January 17, 2020 09:45:07',\n",
    "    'Exported by: gsal'\n",
    "    ]\n",
    "expected_output = [\n",
    "    ['Date', ' Friday, January 17, 2020 09:45:07']\n",
    "    ]\n",
    "date_rule = make_date_parse_rule()\n",
    "test_output = list()\n",
    "for line in test_text:\n",
    "    result = date_rule.apply(line)\n",
    "    if date_rule.event.test_passed:\n",
    "        test_output.append(result)\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approved Status\n",
    "def make_approved_status_rule() -> Rule:\n",
    "    '''If Treatment Approved, Split \"Plan Status\" into 3 lines:\n",
    "        Plan Status\n",
    "        Approved on\n",
    "        Approved by\n",
    "        '''\n",
    "    def approved_status_parse(line, event) -> tp.ProcessedList:\n",
    "        '''If Treatment Approved, Split \"Plan Status\" into 3 lines:\n",
    "\n",
    "        Return three rows for a line containing \"Treatment Approved\"\n",
    "            Prescribed dose [unit]: dose\n",
    "        Gives:\n",
    "            [['Plan Status', 'Treatment Approved'],\n",
    "             ['Approved on', date],\n",
    "             ['Approved by', person]\n",
    "        '''\n",
    "        idx1 = line.find(event.test_value)\n",
    "        idx2 = idx1 + len(event.test_value)\n",
    "        idx3 = line.find(' by')\n",
    "        idx4 = idx3 + 4\n",
    "        parsed_lines = [\n",
    "            ['Plan Status', line[idx1:idx2]],\n",
    "            ['Approved on', line[idx2+1:idx3]],\n",
    "            ['Approved by', line[idx4:]]\n",
    "            ]\n",
    "        for line in parsed_lines:\n",
    "            yield line\n",
    "\n",
    "    approved_status_rule = Rule('Treatment Approved', location='IN',\n",
    "                                   pass_method=approved_status_parse,\n",
    "                                   fail_method='None',\n",
    "                                   name='approved_status_rule')\n",
    "    return approved_status_rule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Plan Status', 'Treatment Approved'],\n",
       " ['Approved on', 'Thursday, January 02, 2020 12:55:56'],\n",
       " ['Approved by', 'gsal']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approved_status_rule\n",
    "test_text = [\n",
    "    'Plan: PARR',\n",
    "    ('Plan Status: Treatment Approved Thursday, '\n",
    "        'January 02, 2020 12:55:56 by gsal'),\n",
    "    'Plan: PARR2-50Gy',\n",
    "    'Plan Status: Unapproved'\n",
    "    ]\n",
    "expected_output = [\n",
    "    ['Plan Status', 'Treatment Approved'],\n",
    "    ['Approved on', 'Thursday, January 02, 2020 12:55:56'],\n",
    "    ['Approved by', 'gsal']\n",
    "    ]\n",
    "\n",
    "approved_status_rule = make_approved_status_rule()\n",
    "test_output = list()\n",
    "for line in test_text:\n",
    "    result = approved_status_rule.apply(line)\n",
    "    if approved_status_rule.event.test_passed:\n",
    "        line_output = [p_line for p_line in result]\n",
    "        test_output.extend(line_output)\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prescribed Dose Rule\n",
    "def make_prescribed_dose_rule() -> Rule:\n",
    "    def parse_prescribed_dose(line, event) -> tp.ProcessedList:\n",
    "        '''Split \"Prescribed dose [cGy]\" into 2 lines.\n",
    "\n",
    "        Return two rows for a line containing:\n",
    "            Prescribed dose [unit]: dose\n",
    "        Gives:\n",
    "            [['Prescribed dose', 'dose'],\n",
    "            ['Prescribed dose unit', 'unit']],\n",
    "        The line:\n",
    "            Prescribed dose [unit]: not defined\n",
    "        Results in:\n",
    "            [['Prescribed dose', '5000.0'],\n",
    "             ['Prescribed dose unit', 'cGy']]\n",
    "        '''\n",
    "        match_results = event.test_value.groupdict()\n",
    "        if match_results['dose'] == 'not defined':\n",
    "            match_results['dose'] = ''\n",
    "            match_results['unit'] = ''\n",
    "\n",
    "        parsed_lines = [\n",
    "            ['Prescribed dose', match_results['dose']],\n",
    "            ['Prescribed dose unit', match_results['unit']]\n",
    "            ]\n",
    "        for line in parsed_lines:\n",
    "            yield line\n",
    "\n",
    "    prescribed_dose_pattern = (\n",
    "        r'^Prescribed dose\\s*'  # Begins with Prescribed dose\n",
    "        r'\\['                   # Unit start delimiter\n",
    "        r'(?P<unit>[A-Za-z]+)'  # unit group: text surrounded by []\n",
    "        r'\\]'                   # Unit end delimiter\n",
    "        r'\\s*:\\s*'              # Dose delimiter with possible whitespace\n",
    "        r'(?P<dose>[0-9.]+'     # dose group Number\n",
    "        r'|not defined)'        #\"not defined\" alternative\n",
    "        r'[\\s\\r\\n]*'            # drop trailing whitespace\n",
    "        r'$'                    # end of string\n",
    "        )\n",
    "    re_pattern = re.compile(prescribed_dose_pattern)\n",
    "    dose_rule = Rule(sentinel=re_pattern, name='prescribed_dose_rule',\n",
    "                        pass_method= parse_prescribed_dose, fail_method='None')\n",
    "    return dose_rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Patient Name', '____, ____'],\n",
       " ['Patient ID', '1234567'],\n",
       " ['Comment', 'DVHs for multiple plans and plan sums'],\n",
       " ['Date', 'Friday, January 17, 2020 09:45:07'],\n",
       " ['Exported by', 'gsal'],\n",
       " ['Type', 'Cumulative Dose Volume Histogram'],\n",
       " ['Description', 'The cumulative DVH displays the percentage'],\n",
       " ['or volume (absolute) of structures that receive a dose'],\n",
       " ['equal to or greater than a given dose.'],\n",
       " [],\n",
       " ['Plan sum', 'Plan Sum'],\n",
       " ['Course', 'PLAN SUM'],\n",
       " ['Prescribed dose', ''],\n",
       " ['Prescribed dose unit', ''],\n",
       " ['% for dose (%)', 'not defined'],\n",
       " [],\n",
       " ['Plan', 'PARR'],\n",
       " ['Course', 'C1'],\n",
       " ['Plan Status', 'Treatment Approved'],\n",
       " ['Approved on', 'Thursday, January 02, 2020 12:55:56'],\n",
       " ['Approved by', 'gsal'],\n",
       " ['Prescribed dose', '5000.0'],\n",
       " ['Prescribed dose unit', 'cGy'],\n",
       " ['% for dose (%)', '100.0']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dvh_line_parser\n",
    "test_text = [\n",
    "    'Patient Name: ____, ____',\n",
    "    'Patient ID:   1234567',\n",
    "    'Comment:      DVHs for multiple plans and plan sums',\n",
    "    'Date:Friday, January 17, 2020 09:45:07',\n",
    "    'Exported by:  gsal',\n",
    "    'Type:         Cumulative Dose Volume Histogram',\n",
    "    'Description:  The cumulative DVH displays the percentage',\n",
    "    'or volume (absolute) of structures that receive a dose',\n",
    "    '        equal to or greater than a given dose.',\n",
    "    '',\n",
    "    'Plan sum: Plan Sum',\n",
    "    'Course: PLAN SUM',\n",
    "    'Prescribed dose [cGy]: not defined',\n",
    "    '% for dose (%): not defined',\n",
    "    '',\n",
    "    'Plan: PARR',\n",
    "    'Course: C1',\n",
    "    ('Plan Status: Treatment Approved Thursday, '\n",
    "    'January 02, 2020 12:55:56 by gsal'),\n",
    "    'Prescribed dose [cGy]: 5000.0',\n",
    "    '% for dose (%): 100.0'\n",
    "    ]\n",
    "expected_output = [\n",
    "    ['Patient Name', '____, ____'],\n",
    "    ['Patient ID', '1234567'],\n",
    "    ['Comment', 'DVHs for multiple plans and plan sums'],\n",
    "    ['Date', 'Friday, January 17, 2020 09:45:07'],\n",
    "    ['Exported by', 'gsal'],\n",
    "    ['Type', 'Cumulative Dose Volume Histogram'],\n",
    "    ['Description', 'The cumulative DVH displays the percentage'],\n",
    "    ['or volume (absolute) of structures that receive a dose'],\n",
    "    ['equal to or greater than a given dose.'],\n",
    "    [],\n",
    "    ['Plan sum', 'Plan Sum'],\n",
    "    ['Course', 'PLAN SUM'],\n",
    "    ['Prescribed dose', ''],\n",
    "    ['Prescribed dose unit', ''],\n",
    "    ['% for dose (%)', 'not defined'],\n",
    "    [],\n",
    "    ['Plan', 'PARR'],\n",
    "    ['Course', 'C1'],\n",
    "    ['Plan Status', 'Treatment Approved'],\n",
    "    ['Approved on', 'Thursday, January 02, 2020 12:55:56'],\n",
    "    ['Approved by', 'gsal'],\n",
    "    ['Prescribed dose', '5000.0'],\n",
    "    ['Prescribed dose unit', 'cGy'],\n",
    "    ['% for dose (%)', '100.0']\n",
    "    ]\n",
    "\n",
    "default_parser = tp.define_csv_parser('dvh_info', delimiter=':',\n",
    "                                        skipinitialspace=True)\n",
    "parsing_rules = [\n",
    "    make_prescribed_dose_rule(),\n",
    "    make_date_parse_rule(),\n",
    "    make_approved_status_rule()\n",
    "    ]\n",
    "\n",
    "test_parser = RuleSet(parsing_rules, default=default_parser)\n",
    "test_output = list()\n",
    "for line in test_text:\n",
    "    test_output.extend(test_parser(line, {}))\n",
    "test_output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Width Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part 1', 'Part 2', 'Part 2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniform_width_parser\n",
    "parser_constructor = tp.FixedWidthParser(widths=6,number=3)\n",
    "parser = parser_constructor.parse\n",
    "line = 'Part 1Part 2Part 2'\n",
    "test_output = parser(line)\n",
    "\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part 1', 'Part 2Part 2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single_break_parser\n",
    "parser_constructor = tp.FixedWidthParser(widths=6)\n",
    "parser = parser_constructor.parse\n",
    "line = 'Part 1Part 2Part 2'\n",
    "test_output = parser(line)\n",
    "\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part 1', 'Part 2a', 'Part 3ab']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#varied_width_parser\n",
    "parser_constructor = tp.FixedWidthParser(widths=[6,7,8])\n",
    "parser = parser_constructor.parse\n",
    "line = 'Part 1Part 2aPart 3ab'\n",
    "test_output = parser(line)\n",
    "\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part 1', 'Part 2a', 'Part 3ab', 'Remainder']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# position_parser\n",
    "expected_output = ['Part 1', 'Part 2a', 'Part 3ab', 'Remainder']\n",
    "parser_constructor = tp.FixedWidthParser(locations=[6,13,21])\n",
    "parser = parser_constructor.parse\n",
    "line = 'Part 1Part 2aPart 3abRemainder'\n",
    "test_output = parser(line)\n",
    "\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part 1Part 2aPart 3ab']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty_parser\n",
    "parser_constructor = tp.FixedWidthParser()\n",
    "parser = parser_constructor.parse\n",
    "line = 'Part 1Part 2aPart 3ab'\n",
    "test_output = parser(line)\n",
    "\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  2  3\n",
       "1  4  5  6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Frame Output\n",
    "\n",
    "# single_header_dataframe\n",
    "test_text = [\n",
    "    ['A', 'B', 'C'],\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "    ]\n",
    "expected_output = pd.DataFrame({'A': [1,4],'B': [2,5],'C':[3,6]})\n",
    "output = tp.to_dataframe(test_text, header=True)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split a text string into parts.\n",
    "- The `delimiter=';'` argument tells it to split the string on \";\"s.\n",
    "- The `skipinitialspace=True` argument tells it to strip leading spaces from the\n",
    " text.\n",
    "\n",
    " For example:\n",
    " |Text|Becomes|\n",
    " |----|-------|\n",
    " |`'       Course;C1'`|`['Course', 'C1']`]|\n",
    " |`'Intent;1_PRIMARY'`|`['Intent', '1_PRIMARY']`]|\n",
    " |`'Plan Id;PELB FB'`|`['Plan Id', 'PELB FB']`]|\n",
    " |`'Technique;'`|`['Technique']`]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_parse = tp.define_csv_parser(\n",
    "    delimiter=';',\n",
    "    skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a list of two-item lists to a dictionary.\n",
    "- First item in the sub-list is the key.  The second item is the value.\n",
    "- `default_value=None` will cause one-item sub-lists to be dropped.\n",
    "\n",
    " For example the text:\n",
    " ```[\n",
    "    ['Course', 'C1'],\n",
    "    ['Intent', '1_PRIMARY'],\n",
    "    ['Plan Id', 'PELB FB',\n",
    "    ['Technique']\n",
    "    ]```\n",
    "\n",
    "becomes:\n",
    "```{\n",
    "    'Course': 'C1',\n",
    "    'Intent': '1_PRIMARY',\n",
    "    'Plan Id': 'PELB FB'\n",
    "    }```\n",
    "\n",
    "*Note: * `['Technique']` is dropped because it is a single-item list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "trim_dict = partial(tp.to_dict, default_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Any\n",
    "def make_section_dict(parsed_text: List[Tuple[str]], context: Dict[str, Any]):\n",
    "    section_data = tr.to_dict(parsed_text, default_value=None)\n",
    "    name = context['Current Section']\n",
    "    section_dict = {name: section_data}\n",
    "    return section_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify strings containing \"Warning\" text.\n",
    "- a regular expression is used to identify the \"Warning\" text:\n",
    "    - `'(?P<Num>[0-9]+)[. ]+'` Looks for one or more digits followed by a \".\" \n",
    "    and/or spaces.  This is assigned as the \"Num\" group.\n",
    "    - `'WARNING[: ]*'`  The word \"WARNING\", followed by optional \":\" \n",
    "    and/or spaces \n",
    "    - `'(?P<Warning>.*$)'`  The warning text is then the remainder of the \n",
    "    string. This is assigned as the \"Warning\" group.\n",
    "\n",
    "If a match is found returns a *two*-item list: \n",
    "`[\"Num\" group, \"Warning\" group]`.<br>\n",
    "If a match is **not** found returns a *one*-item list: `[Original Text]`.\n",
    "\n",
    "For example:\n",
    "> `'1. WARNING: Plan target volume is different than plan primary reference\n",
    " point volume.'`\n",
    "\n",
    " Returns:\n",
    "> `['1', 'Plan target volume is different than plan primary reference\n",
    " point volume.']`\n",
    "\n",
    "And\n",
    "> `'PhotonAlg; AAA_15606_Golden_Beam'`\n",
    "\n",
    "Returns:\n",
    "> `['PhotonAlg; AAA_15606_Golden_Beam']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warning(text_line):\n",
    "    warning_pattern = re.compile(\n",
    "        '(?P<Num>[0-9]+)'   # Warning index as Num group\n",
    "        '[. ]+'             # delimiter and space\n",
    "        'WARNING'           # warning text\n",
    "        '[: ]*'             # delimiter and space\n",
    "        '(?P<Warning>.*$)'  # remaining text in line as Warning group\n",
    "        )\n",
    "    warning_match = warning_pattern.search(text_line)\n",
    "    if warning_match:\n",
    "        indexer = warning_match.group('Num')\n",
    "        warning_text = warning_match.group('Warning')\n",
    "        warning_output = [f'Warning{indexer}', warning_text]\n",
    "    else:\n",
    "        warning_output = [text_line]\n",
    "    return warning_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the User origin text line.\n",
    "- The text is expected to have the form of three numbers with 'cm' units \n",
    "contained in brackets.  For example:\n",
    "> `(-1.26cm, 9.95cm, -4.70cm)`\n",
    "- A regular expression is used to parse the \"User Origin\" text:\n",
    "    - `'[^(]+.'` Everything up to and including the first bracket.\n",
    "    - `'(?P<X>[0-9.-]+)'`  The X number group. \n",
    "    - `'[ cm,]*'`  'cm' units, spaces and comma \n",
    "    - `'(?P<Y>[0-9.-]+)'`  The Y number group.\n",
    "    - `'[ cm,]*'`  'cm' units, spaces and comma \n",
    "    - `'(?P<Z>[0-9.-]+)'`  The Z number group.\n",
    "    - `'[ cm,)]*'`  'cm' units, spaces, comma  and end bracket\n",
    "\n",
    "If a match is found, returns four output items, each containing a \n",
    "two-item list:\n",
    "> `[`<br>\n",
    "    `['User Origin', `*The original text line after the '='*`],`<br>\n",
    "    `['Origin X', `*The matched 'X' group*`],`<br>\n",
    "    `['Origin Y', `*The matched 'Y' group*`],`<br>\n",
    "    `['Origin Z', `*The matched 'Z' group*`]`<br>\n",
    "    `]`\n",
    "\n",
    "If a match is **not** found, returns a list containing the original text string \n",
    "split on \";\"s.\n",
    "\n",
    "For example:\n",
    "> `'User Origin;User origin DICOM offset = (-1.26cm, 9.95cm, -4.70cm)'`\n",
    "\n",
    " Returns:\n",
    "> `[`<br>\n",
    "    `['User Origin', '(-1.26cm, 9.95cm, -4.70cm)'],`<br>\n",
    "    `['Origin X', -1.26],`<br>\n",
    "    `['Origin Y', 9.95],`<br>\n",
    "    `['Origin Z', -4.70]`<br>\n",
    "    `]`\n",
    "\n",
    "And\n",
    "> `'PhotonAlg; AAA_15606_Golden_Beam'`\n",
    "\n",
    "Returns:\n",
    "> `['PhotonAlg', 'AAA_15606_Golden_Beam']`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origin(text_line):\n",
    "    origin_pattern = re.compile(\n",
    "        '[^(]+.'           # Everything up to and including the first bracket\n",
    "        '(?P<X>[0-9.-]+)'  # X number group\n",
    "        '[ cm,]*'          # Unit, space and comma\n",
    "        '(?P<Y>[0-9.-]+)'  # Y number group\n",
    "        '[ cm,]*'          # Unit, space and comma\n",
    "        '(?P<Z>[0-9.-]+)'  # Z number group\n",
    "        '[ cm,)]*'         # Unit, space, comma and end bracket\n",
    "        )\n",
    "    origin_match = origin_pattern.search(text_line)\n",
    "    if origin_match:\n",
    "        origin_str = text_line.split('=')[1].strip()\n",
    "        origin = [\n",
    "            ['User Origin', origin_str],\n",
    "            ['Origin X', origin_match.group('X')],\n",
    "            ['Origin Y', origin_match.group('Y')],\n",
    "            ['Origin Z', origin_match.group('Z')]\n",
    "            ]\n",
    "    else:\n",
    "        origin = [text_line.split(';')]\n",
    "    for row in origin:\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the gantry text line.\n",
    "- The text is expected to have the form of three numbers with 'cm' units \n",
    "contained in brackets. <br>\n",
    "For example:\n",
    "    - `Gantry;0.0 deg to - deg` \n",
    "    <br> or <br>\n",
    "    - `Gantry;181.0 degCW to 179.0 deg`\n",
    "\n",
    "- A regular expression is used to parse the gantry text:\n",
    "    - `'(?P<GantryStart>[0-9.-]+)'` gantry start angle, assigned to \n",
    "    \"GantryStart\".\n",
    "    - `'[ degtoCCW]*'`  Unit, space direction and \"to\" (not captured). \n",
    "    - `'(?P<GantryEnd>[0-9.-]+)'`  Gantry end angle, assigned to \n",
    "    \"GantryEnd\".\n",
    "    - `'[ deg]*'`  'deg' units and space  (not captured).\n",
    "    - `'[ cm,]*'`  'cm' units, spaces and comma \n",
    "\n",
    "If a match is found, returns either one or three output items, each containing a \n",
    "two-item list.<br>\n",
    "> If *GantryEnd* contains `'-'`  (meaning gantry doesn't move), returns:<br>\n",
    "    >> `[['Gantry', `*GantryStart*`]]`\n",
    "\n",
    "> Otherwise (moving gantry), returns:<br>\n",
    "    >> `[`<br>\n",
    "    >> `['Gantry', `*GantryStart*`],`<br>\n",
    "    >> `['GantryStart', `*GantryStart*`],`<br>\n",
    "    >> `['GantryEnd', `*GantryEnd*`],`<br>\n",
    "    >> `]`\n",
    "                \n",
    "If a match is **not** found returns a list containing the original text string \n",
    "split on \";\"s.\n",
    "\n",
    "For example:\n",
    "> `Gantry;0.0 deg to - deg`\n",
    "\n",
    " Returns:\n",
    "> `[['Gantry', '0.0']]`\n",
    "\n",
    "Or\n",
    "> `Gantry;181.0 degCW to 179.0 deg`\n",
    "\n",
    " Returns:\n",
    "> `[`<br>\n",
    "> `['Gantry', '181.0'],`<br>\n",
    "> `['GantryStart', '181.0'],`<br>\n",
    "> `['GantryEnd', '179.0'],`<br>\n",
    "> `]`\n",
    "\n",
    "And\n",
    "> `'PhotonAlg; AAA_15606_Golden_Beam'`\n",
    "\n",
    "Returns:\n",
    "> `['PhotonAlg', 'AAA_15606_Golden_Beam']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gantry(text_line):\n",
    "    gantry_pattern = re.compile(\n",
    "        '(?P<GantryStart>[0-9.-]+)'  # gantry start group\n",
    "        '[ degtoCCW]*'               # Unit, space direction and \"to\"\n",
    "        '(?P<GantryEnd>[0-9.-]+)'    # gantry start group\n",
    "        '[ deg]*'                    # Unit and space\n",
    "        )\n",
    "    gantry_match = gantry_pattern.search(text_line)\n",
    "    if gantry_match:\n",
    "        gantry_start = gantry_match.group('GantryStart')\n",
    "        gantry_end = gantry_match.group('GantryEnd')\n",
    "        if '-' in gantry_end:\n",
    "            gantry = [\n",
    "                ['Gantry', gantry_start]\n",
    "                ]\n",
    "        else:\n",
    "            gantry = [\n",
    "                ['Gantry', gantry_start],\n",
    "                ['GantryStart', gantry_start],\n",
    "                ['GantryEnd', gantry_end],\n",
    "                ]\n",
    "    else:\n",
    "        gantry = [text_line.split(';')]\n",
    "    for row in gantry:\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabel *\"No Field Normalization\"*\n",
    "Replace lines with text: \n",
    "> *'NO_ISQLAW_NORM'*\n",
    "\n",
    "with processed output:\n",
    "> `norm_line = ['Norm Method', 'No Field Normalization']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_norm(text_line):\n",
    "    if 'NO_ISQLAW_NORM' in text_line:\n",
    "        norm_line = ['Norm Method', 'No Field Normalization']\n",
    "    return norm_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop units from numeric data\n",
    "\n",
    "- A regular expression is used to extract the value portion of a string tha contains a number with units.\n",
    "-   - `'^\\s*'` beginning of string and leading whitespace.\n",
    "    - `'(?P<value>[-+]?\\d+[.]?\\d*)'`  The value group containing optional initial\n",
    "        sign and decimal place with numbers before and/or after.\n",
    "    - `'[ cm,]*'`  'cm' units, spaces and comma \n",
    "    - `'(?P<Y>[0-9.-]+)'`  The Y number group.\n",
    "    - `'\\s*'`  Optional whitespace between value and units.\n",
    "    - `'(?P<unit>[^\\s]*)'`  The units group, which does not contain spaces.\n",
    "    - `'\\s*$'`  Trailing whitespace and end of string\n",
    "\n",
    "\n",
    "\n",
    "If a match is found, returns the value group as a float otherwise return the original text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "def drop_units(text: str) -> Union[float, str]:\n",
    "    number_value_pattern = re.compile(\n",
    "        # beginning of string and leading whitespace\n",
    "        r'^\\s*'                \n",
    "        # value group contains optional initial sign and decimal place with \n",
    "        # number before and/or after.\n",
    "        r'(?P<value>[-+]?\\d+[.]?\\d*)'    \n",
    "        r'\\s*'              # Optional whitespace between value and units\n",
    "        r'(?P<unit>[^\\s]*)' # units do not contain spaces\n",
    "        r'\\s*'              # drop trailing whitespace\n",
    "        r'$'                # end of string\n",
    "        )\n",
    "    find_num = number_value_pattern.search(text)\n",
    "    if find_num:\n",
    "        value, unit = find_num.groups()\n",
    "        return float(value)\n",
    "    return text\n",
    "\n",
    "\n",
    "def numeric_values(text_row: Tuple[str]) -> Tuple[str, float]:\n",
    "    try:\n",
    "        label, text_value = text_row\n",
    "    except ValueError:\n",
    "        return text_row\n",
    "    numeric_value = drop_units(text_value)\n",
    "    return (label, numeric_value)\n",
    "\n",
    "\n",
    "def numeric_values_list(text_list: List[str]) -> List[Union[str, float]]:\n",
    "    converted_list = [drop_units(text_item) for text_item in text_list]\n",
    "    return converted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_file = Path.cwd() / 'examples' / 'test_DIR_Data.txt'\n",
    "dir_text = test_file.read_text().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pattern = tp.build_date_re(compile_re=False)\n",
    "file_listing_pt = re.compile(\n",
    "    f'{date_pattern}'  # Insert date pattern\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<size>'        # beginning of size string group\n",
    "    '[0-9]+'           # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    ' '                # Single space\n",
    "    '(?P<filename>'    # beginning of filename string group\n",
    "    '.*'               # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    '$'                # end of string\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Width Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part of a directory listing is formatted into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column index\n",
      "0000000000111111111122222222223333333333444444444455555555556666666666\n",
      "0123456789012345678901234567890123456789012345678901234567890123456789\n",
      "2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "2016-04-21  01:06 PM              3491 xcopy.txt\n"
     ]
    }
   ],
   "source": [
    "print('column index')\n",
    "print(''.join(str(i)*10 for i in range(7)))\n",
    "print(''.join(str(i) for i in range(10))*7)\n",
    "#print(''.join(divider))\n",
    "print(dir_text[7])\n",
    "print(dir_text[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "column_breaks=[11, 20, 29, 38]\n",
    "\n",
    "divider_list = ['.']*70\n",
    "for brk in column_breaks:\n",
    "    divider_list[brk] = '|'\n",
    "divider = ''.join(divider_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column breaks\n",
      "...........|........|........|........|...............................\n",
      "2021-12-27  03:33 PM    <DIR>          ..\n",
      "2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "2016-02-25  09:59 PM                 3 TestFile1.txt\n",
      "2016-02-15  06:46 PM                 7 TestFile2.rtf\n",
      "2016-02-15  06:47 PM                 0 TestFile3.docx\n",
      "2016-04-21  01:06 PM              3491 xcopy.txt\n",
      "...........|........|........|........|...............................\n"
     ]
    }
   ],
   "source": [
    "print('column breaks')\n",
    "#print(''.join(str(i)*10 for i in range(7)))\n",
    "#print(''.join(str(i) for i in range(10))*7)\n",
    "print(divider)\n",
    "\n",
    "for line in dir_text[6:13]:\n",
    "    print(line)\n",
    "    \n",
    "print(divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Part', ' 1'], ['Part', ' 2a'], ['Part', ' 2b']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['Part 1', 'Part 2a', 'Part 2b']\n",
    "b = tp.FixedWidthParser([4,3])\n",
    "[item for item in b.parser(a)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part', ' 2a']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.parse(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-04-21  01:06 PM', '          ', '    3491 ', 'xcopy.txt']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tp.FixedWidthParser(locations=[20,30,39])\n",
    "a.parse(dir_text[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object FixedWidthParser.parser at 0x0000025D080A47B0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tp.define_fixed_width_parser(locations=[20,30,39])\n",
    "b(dir_text[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2021-12-27  05:27 PM', '    <DIR> ', '         ', 'Dir2']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(b(dir_text[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def dir_name_split(dir_line):\n",
    "    output_dict = {'Folder Name': dir_line.rsplit('\\\\', 1)[1]}\n",
    "    return output_dict\n",
    "def file_count_split(dir_line):\n",
    "    output_dict = {'Number of Files': dir_line.strip().split(' ', 1)[0]}\n",
    "    return output_dict\n",
    "def get_subfolder_name(dir_line):\n",
    "    output_dict = {'Subdirectory': dir_line[36:]}\n",
    "    return output_dict\n",
    "def get_file_name(dir_line):\n",
    "    output_dict = {'File': dir_line[36:]}\n",
    "    return output_dict\n",
    "\n",
    "# Define Rules\n",
    "dir_name_rule = Rule('Directory of', pass_method=dir_name_split)\n",
    "subfolder_rule = Rule('<DIR>', pass_method=get_subfolder_name)\n",
    "file_count_rule = Rule('File(s)', pass_method=file_count_split)\n",
    "\n",
    "#Define Rule Set\n",
    "dir_process = RuleSet([dir_name_rule, subfolder_rule, file_count_rule], \n",
    "                      default=get_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Volume in drive C is Windows\n",
      "\t  Volume Serial Number is DAE7-D5BA\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\n",
      "\t \n",
      "\t 2021-12-27  03:33 PM    <DIR>          .\n",
      "\t 2021-12-27  03:33 PM    <DIR>          ..\n",
      "\t 2021-12-27  04:03 PM    <DIR>          Dir1\n",
      "\t 2021-12-27  05:27 PM    <DIR>          Dir2\n",
      "\t 2016-02-25  09:59 PM                 3 TestFile1.txt\n",
      "\t 2016-02-15  06:46 PM                 7 TestFile2.rtf\n",
      "\t 2016-02-15  06:47 PM                 0 TestFile3.docx\n",
      "\t 2016-04-21  01:06 PM              3491 xcopy.txt\n",
      "\t                4 File(s)           3501 bytes\n",
      "\t \n",
      "\t  Directory of c:\\users\\...\\Test Dir Structure\\Dir1\n",
      "\t \n",
      "\t 2021-12-27  04:03 PM    <DIR>          .\n",
      "\t 2021-12-27  04:03 PM    <DIR>          ..\n",
      "\t 2016-02-15  06:48 PM                 0 File in Dir One.txt\n"
     ]
    }
   ],
   "source": [
    "for line in dir_text[0:20]:\n",
    "    print('\\t', line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sectionaryDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "890849be4bb9b5be1d044afe42e602ccc6ca20da23c054ee97c8186ec3939c45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
