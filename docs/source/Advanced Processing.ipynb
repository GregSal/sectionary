{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Processing\n",
    "In this tutorial we introduce some more advanced tools for section processing.\n",
    "\n",
    "1. Processing using a generator function\n",
    "2. Rules and Rule Sets\n",
    "3. Regular expression for processing text\n",
    "4. The FixedWidth and csv Parsing tools\n",
    "5. Making use of the Context dictionary\n",
    "    1. Setting context values when calling Section.read\n",
    "    2. Accessing default context values\n",
    "6. Passing other parameters to the processing methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Generator Functions\n",
    "\n",
    "A Process applied to a Source (a sequence of SourceItems) results in\n",
    "a sequence of ProcessedItems.  The relation between SourceItems and\n",
    "ProcessedItems is not necessarily 1:1.\n",
    "   1 SourceItem ≠1 ProcessedItem;\n",
    "      • 1 SourceItem → 1 ProcessedItem\n",
    "      • 1 SourceItem → 2+ ProcessedItems\n",
    "      • 2+ SourceItems → 1 ProcessedItem\n",
    "\n",
    "Generator functions are used when multiple input items are\n",
    "required to generate an output item, or when one SourceItem results in\n",
    "multiple ProcessedItems. \n",
    "\n",
    "In general, regular functions are used when there\n",
    "is a one-to-one correspondence between input item and output item.  \n",
    "\n",
    "ProcessedItems = Union[ProcessedItem, Generator[ProcessedItem]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Source and Section item counting.\n",
    "\n",
    "Process method should track the number of Source lines used for each processed line\n",
    "\n",
    "Processor creates sequence of source.item_count for each output item\n",
    "- Len(section.item_count) = # processed items\n",
    "- section.item_count[-1] = # source items (includes skipped source items)\n",
    "- Property item_count returns len(self._item_count)\n",
    "- Property source_item_count returns self._item_count[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Imports\n",
    "\n",
    "from pprint import pprint\n",
    "import random\n",
    "from buffered_iterator import BufferedIterator\n",
    "\n",
    "from sections import SectionBreak, Section\n",
    "from sections import Rule, RuleSet, ProcessingMethods\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Processing Functions\n",
    "def pairs(source):\n",
    "    '''Convert a sequence of items into a sequence of item pairs\n",
    "\n",
    "    Successive items are combined into length 2 tuples.\n",
    "\n",
    "    Args:\n",
    "        source (Sequence): any sequence of hashable items\n",
    "\n",
    "    Yields:\n",
    "        Tuple[Any]: Successive items combined into length 2 tuples.\n",
    "    '''\n",
    "    for item in source:\n",
    "        yield tuple([item, next(source)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def n_split(source):\n",
    "    '''Extract numbers from stings of comma separated integers.\n",
    "\n",
    "    Number are extracted by splitting on the commas.  Spaces are ignored.\n",
    "\n",
    "    Args:\n",
    "        source (Sequence[str]): A sequence of stings composed of comma separated\n",
    "            integers. e.g. ['0, 1', '2, 3', '4, 5' ...]\n",
    "\n",
    "    Yields:\n",
    "        int: Integer values extracted from the strings.\n",
    "    '''\n",
    "    for item in source:\n",
    "        nums = [int(num_s.strip()) for num_s in item.split(',')]\n",
    "        yield from nums\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def odd_nums(source):\n",
    "    '''Yield Odd items\n",
    "    Args:\n",
    "        source (Sequence[int]): A sequence of integers\n",
    "\n",
    "    Yields:\n",
    "        int: odd integers from the source\n",
    "    '''\n",
    "    for item in source:\n",
    "        if int(item)%2 == 1:\n",
    "            yield item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buffer_size = 5\n",
    "num_items = 10\n",
    "\n",
    "str_source = BufferedIterator(\n",
    "    (str(i) for i in range(num_items)), \n",
    "    buffer_size=buffer_size\n",
    "    )\n",
    "\n",
    "int_source = BufferedIterator(\n",
    "    (i for i in range(num_items)),\n",
    "    buffer_size=buffer_size\n",
    "    )\n",
    "\n",
    "pairs_source = BufferedIterator(\n",
    "    [f'{a}, {b}' for a, b in zip(range(0, num_items * 2, 2),\n",
    "                                 range(1, num_items * 2, 2))],\n",
    "    buffer_size=buffer_size\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-to-1 match\n",
    "    * range(n) as source\n",
    "    * processor just returns item\n",
    "    * for each section item:\n",
    "    * source.item_count = item = section.source_item_count\n",
    "    * source.item_count = section.item_count\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "section_1_1 = Section(section_name='1-to-1 match')\n",
    "for item in section_1_1.process(int_source):\n",
    "    print(item)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-to-1 match\n",
    "    * `range(n)` as source\n",
    "    * processor converts 2 successive source items into tuple of length 2.\n",
    "    * for each section item:\n",
    "        * item = (source.item_count-2, source.item_count-1)\n",
    "        * source.item_count = section.source_item_count\n",
    "        * source.item_count = section.item_count * 2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_2_1 = Section(section_name='2-to-1 match',\n",
    "                        processor=[pairs])\n",
    "for item in section_2_1.process(int_source):\n",
    "    print(item)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-to-2 match\n",
    "    * Numerical pairs as source:\n",
    "        `['0, 1', '2, 3', '4, 5'` $\\cdots$`]`\n",
    "    * processor converts 1 source item into 2 output lines\n",
    "    * for each source item:\n",
    "        * `nums = [int(num_s.strip()) for num_s in item.split(',')]`<br>\n",
    "        * `section item 1 = nums[0]`,<br>\n",
    "        * `section item 2 = nums[1]`\n",
    "    * source.item_count = (section.item_count + 1) // 2\n",
    "    * section.source_item_count = section.source_index[-1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "section_1_2 = Section(section_name='1-to-2 match',\n",
    "                        processor=[n_split])\n",
    "for item in section_1_2.process(pairs_source):\n",
    "    print(item)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip First Source Item\n",
    "    * (str(i) for i in range(n)) as source\n",
    "    * start_section='1', offset='Before'\n",
    "    * processor returns int(item)\n",
    "    * for each section item:\n",
    "        * source.item_count = item\n",
    "        * source.item_count = section.source.item_count\n",
    "        * source.item_count = section.item_count\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "section_skip_0 = Section(\n",
    "    section_name='Skipped First Source Item',\n",
    "    start_section=SectionBreak('1', break_offset='Before')\n",
    "    )\n",
    "for item in section_skip_0.process(str_source):\n",
    "    print(item)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip First 2 Source Items\n",
    "    * (str(i) for i in range(n)) as source\n",
    "    * start_section='1', offset='After'\n",
    "    * processor returns int(item)\n",
    "    * for each section item:\n",
    "        * source.item_count = item + 1\n",
    "        * source.item_count = section.source_item_count\n",
    "        * source.item_count = section.item_count + 2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_skip_2 = Section(\n",
    "    section_name='Skipped First Source Item',\n",
    "    start_section=SectionBreak('1', break_offset='After')\n",
    "    )\n",
    "for item in section_skip_2.process(str_source):\n",
    "    print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't Count Dropped Items\n",
    "    * range(n) as source\n",
    "    * processor drops even items and yields odd items\n",
    "    * for each section item:\n",
    "        * item + 1 = source.item_count\n",
    "        * source.item_count = section.source_item_count\n",
    "        * source.item_count = section.item_count * 2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_odd = Section(\n",
    "    section_name='Odd Numbers',\n",
    "    processor=[odd_nums]\n",
    "    )\n",
    "for item in section_odd.process(int_source):\n",
    "    print(item)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed Section Item Count\n",
    "     (str(i) for i in range(n)) as source\n",
    "     processor drops even items and yields odd items\n",
    "     after section.read(source):\n",
    "        * source.item_count = section.source_item_count\n",
    "        * section.source_item_count = section.item_count = n * 2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_odd = Section(\n",
    "    section_name='Odd Numbers',\n",
    "    processor=[odd_nums]\n",
    "    )\n",
    "section_odd.read(int_source)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial Source Completed Section\n",
    "    * (str(i) for i in range(n)) as source\n",
    "    * Random start_section and end_section\n",
    "    * after section.read(source):\n",
    "        * source.item_count = section.source_item_count\n",
    "        * source.item_count = end_num\n",
    "        * section.item_count = end_num - start_num\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_num = random.randint(1, num_items-2)\n",
    "end_num = random.randint(start_num + 1, num_items)\n",
    "part_section = Section(\n",
    "    section_name='Partial Source Section',\n",
    "    start_section=str(start_num),\n",
    "    end_section=str(end_num)\n",
    "    )\n",
    "part_section.read(str_source)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed Section With End Before\n",
    "    * `(str(i) for i in range(n))` as source\n",
    "    * end_section='2', offset='Before'\n",
    "    * after section.read(source):\n",
    "        * source.item_count = section.source_item_count\n",
    "        * source.item_count = section.item_count = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_end_before = Section(\n",
    "    section_name='End Before',\n",
    "    end_section=SectionBreak('2', break_offset='Before')\n",
    "    )\n",
    "\n",
    "section_end_before.read(str_source)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed Section With End After\n",
    "    * `(str(i) for i in range(n))` as source\n",
    "    * end_section='2', offset='After'\n",
    "    * after section.read(source):\n",
    "        * source.item_count = section.source_item_count\n",
    "        * source.item_count = section.item_count = 3\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_end_before = Section(\n",
    "    section_name='End Before',\n",
    "    end_section=SectionBreak('2', break_offset='After')\n",
    "    )\n",
    "\n",
    "item_list = section_end_before.read(str_source)\n",
    "source_count = str_source.item_count\n",
    "source_item_count = section_end_before.source_item_count\n",
    "item_count = section_end_before.item_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Processing\n",
    "\n",
    "Once identified, a section's content can be *processed* before being returned.\n",
    "Automatic processing of the items in a section's content is specified with the \n",
    "*processor* argument in the *Section* definition. \n",
    "\n",
    "The *processor* argument takes a list of functions, *Rules*, or *RuleSets*. If \n",
    "the processor argument is not given or is `None` the items in the section are \n",
    "returned as-is.  *Rules* and *RuleSets* will be discussed in the next section.\n",
    "\n",
    "Processor functions have one required positional argument, the item to be \n",
    "processed.  In addition, the function may contain a second positional argument,\n",
    "a *context* dictionary.  The *context* dictionary will be discussed in a more\n",
    "detail in a later section.  Additional keyword arguments may also be included.  \n",
    "If the keyword matches with a key in the section's *context*, The corresponding \n",
    "*context* value will be supplied.  Otherwise the keyword argument will be \n",
    "ignored.\n",
    "\n",
    "The functions will be applied in list order with the input of the function being \n",
    "the output from the previous function.  This means that the expected input type \n",
    "of a processor function should be able to handle all possible output types from \n",
    "the previous function in the list.\n",
    "\n",
    "Processor functions may also be generator functions, in which case the required \n",
    "positional argument is the sequence to iterate over.  This can be useful if the \n",
    "processing involves skipping items or merging of multiple items.  Examples of \n",
    "this will be given in a separate tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Processing functions should accept one the following argument sets:\n",
    "    func(item)\n",
    "    func(item, ** context)\n",
    "    func(item, context)\n",
    "    func(item, [other(s),] ** context)\n",
    "\n",
    "\n",
    "Custom function\n",
    "- First argument is the item to be processed\n",
    "- Optional second argument is the Section's *Context* dictionary.\n",
    "- keyword arguments can be used to accept specific items from the Section's \n",
    "*Context* dictionary, provided there is a trailing **kwarks argument to catch \n",
    "the remainder of the Section's *Context* dictionary.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Processing functions should accept one the following argument sets:\n",
    "    func(item)\n",
    "    func(item, ** context)\n",
    "    func(item, context)\n",
    "    func(item, [other(s),] ** context)\n",
    "\n",
    "\n",
    "Custom function\n",
    "- First argument is the item to be processed\n",
    "- Optional second argument is the Section's *Context* dictionary.\n",
    "- keyword arguments can be used to accept specific items from the Section's \n",
    "*Context* dictionary, provided there is a trailing **kwarks argument to catch \n",
    "the remainder of the Section's *Context* dictionary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing instruction(s) can be a ProcessingMethods\n",
    "instance, or one of / a list of:\n",
    "    Rule,\n",
    "    RuleSet,\n",
    "    section,\n",
    "    list of sections,\n",
    "    Any function with an appropriate call signature:\n",
    "        func(items: SourceItem),\n",
    "        func(items: SourceItem, context: ContextType),\n",
    "        func(items: SourceItem, **kwargs: Any)\n",
    "\n",
    "        Both regular functions and generator functions are\n",
    "        accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing with a generator function\n",
    "\n",
    "In a simple processor function the input is a single item from the section and\n",
    "the output is one \"item\" for each \"input item\".\n",
    "\n",
    "The relation between individual input (section) items and the resulting \n",
    "processed items is not necessarily 1:1. A single input item could be broken up \n",
    "into multiple processed items, or conversely, multiple section items could be \n",
    "converted into one processed item:\n",
    "\n",
    "    \t  • 1 SourceItem → 1 ProcessedItem\n",
    "    \t  • 1 SourceItem → 2+ ProcessedItems\n",
    "    \t  • 2+ SourceItems → 1 ProcessedItem\n",
    "\n",
    "In general, regular functions are only used when there is a one-to-one \n",
    "correspondence between input item and output item.  Generator functions are used \n",
    "when multiple input items are required to generate a processed item, or when one \n",
    "input item results in multiple processed items.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule and RuleSets\n",
    "Instead of having one function `process_directory()` that manages all possible \n",
    "text lines in the section, the function can be broken down into parts by \n",
    "defining *Rules*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules\n",
    "Rules define an action to take on an item depending on the result of a test.\n",
    "\n",
    "A *Rule* definition has two parts:\n",
    "1. Trigger:\n",
    "   > Defines the test to be applied to the source item\n",
    "   > Trigger related arguments:\n",
    "   > - sentinel\n",
    "   >   - For string items, sentinel can be a string or compiled regular expression.\n",
    "   > - location\n",
    "   >   - A sentinel modifier that applies to str or re.Pattern types of sentinels. One of  ['IN', 'START', 'END', 'FULL', None]. Default is None, which is treated as 'IN'\n",
    "\n",
    "2. Action\n",
    "   > Defines the actions to take depending on the Trigger outcome.\n",
    "   > Action related arguments:\n",
    "   > - pass_method\n",
    "   > - fail_method\n",
    "   >\n",
    "   > Both take functions, or the name of standard actions to be implemented if the test passes or fails respectively.\n",
    "   >\n",
    "   > The pass_method and fail_method functions can be simple process functions, with one positional argument and additional keyword arguments. The functions can also contain a second positional argument *event* which allows the function to access information about the test results.  This is particularly useful when the sentinel is a regular expression.\n",
    "   >\n",
    "   > pass_method and fail_method can also be a string with the name of one of the standard actions.  The most common are:\n",
    "   > - 'Original': return the item being.\n",
    "   > - 'None': return None\n",
    "   > - 'Blank': return ''  (an empty string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RuleSets\n",
    "RuleSets combine related Rules to provide multiple choices for actions.\n",
    "RuleSets\n",
    "    are used when the function that should be applied to the SourceItem(s)\n",
    "    depends on the result of one or more tests (Triggers).  Individual Rules can\n",
    "    be used when only a single Trigger is required (by using both the Pass and\n",
    "    Fail methods of the Rule) or to modify some of the SourceItems while leaving\n",
    "    others unchanged (by setting the Fail method to 'Original').  For Rules or\n",
    "    RuleSets it is important that the output is of the same type regardless of\n",
    "    whether the Trigger(s) pass or fail.\n",
    "\n",
    "- A Rule Set takes A sequence of Rules and a default method.\n",
    "- Each Rule in the sequence will be applied to the input until One of the rules triggers. At that point The sequence ends.  \n",
    "- If no Rule triggers then the default method is applied.  \n",
    "- Each of the Rules (and the default) should expect the same input type and should produce the same output type.  \n",
    "- The default_method can be any valid process function or standard action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Triggers*, *TriggerEvent*, *Rules* and *RuleSets* will be covered in more detail in a separate tutorial.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex based processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#%% Regex Parsing patterns\n",
    "# File Count and summary:\n",
    "     #          1 File(s)          59904 bytes\n",
    "     #         23 Dir(s)     63927545856 bytes free\n",
    "folder_summary_pt = re.compile(\n",
    "    '(?P<files>'       # beginning of files string group\n",
    "    '[0-9]+'           # Integer number of files\n",
    "    ')'                # end of files string group\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<type>'        # beginning of type string group\n",
    "    'File|Dir'         # \"File\" or \" Dir\" text\n",
    "    ')'                # end of type string group\n",
    "    '\\\\(s\\\\)'          # \"(s)\" text\n",
    "    '[ ]+'             # Arbitrary number of spaces\n",
    "    '(?P<size>'        # beginning of size string group\n",
    "    '[0-9]+'           # Integer size of folder\n",
    "    ')'                # end of size string group\n",
    "    ' bytes'           # \"bytes\" text\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = Path.cwd() / 'examples' / 'test_DIR_Data.txt'\n",
    "dir_text = test_file.read_text().splitlines()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sectionaryDev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "890849be4bb9b5be1d044afe42e602ccc6ca20da23c054ee97c8186ec3939c45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
